#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass amsbook
\begin_preamble
\usepackage{etoolbox}% http://ctan.org/pkg/etoolbox
\makeatletter
\let\old@start@align\start@align
\def\start@align{\setcounter{equation}{0}\old@start@align}
\makeatother
\allowdisplaybreaks
\newref{cor}{name=corollary~}
\newref{exa}{name=example~}
\usepackage{thmtools}
\declaretheoremstyle[
spaceabove=6pt, spacebelow=6pt,
headfont=\normalfont\bfseries,
notefont=\mdseries, notebraces={(}{)},
bodyfont=\normalfont,
postheadspace=1em,
headpunct={.},
qed=$\blacktriangleleft$,
numbered=no
]{solstyle}
\declaretheorem[style=solstyle]{solution}
\usepackage{hyperref}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
theorems-chap
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "linkcolor=blue, citecolor=blue, urlcolor=blue, plainpages=false, pdfstartview=XYZ, pdfpagelabels"
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Math 503, Spring 2015
\end_layout

\begin_layout Author
Lecture Notes
\end_layout

\begin_layout Email
\begin_inset CommandInset href
LatexCommand href
name "sdw62@georgetown.edu"
target "sdw62@georgetown.edu"
type "mailto:"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter
Background material
\end_layout

\begin_layout Section
Univariate transformations
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 have cdf 
\begin_inset Formula $F_{X}\left(x\right)$
\end_inset

, let 
\begin_inset Formula $Y=g\left(X\right)$
\end_inset

, let 
\begin_inset Formula $\mathcal{X}=\left\{ x:f_{X}\left(x\right)>0\right\} $
\end_inset

, and let 
\begin_inset Formula $\mathcal{Y}=\left\{ y:y=g\left(x\right),x\in\mathcal{X}\right\} $
\end_inset

.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
If 
\begin_inset Formula $g$
\end_inset

 is an increasing function on 
\begin_inset Formula $\mathcal{X}$
\end_inset

, 
\begin_inset Formula $F_{Y}\left(y\right)=F_{X}\left(g^{-1}\left(y\right)\right)$
\end_inset

 for 
\begin_inset Formula $y\in\mathcal{Y}$
\end_inset

.
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $g$
\end_inset

 is a decreasing function on 
\begin_inset Formula $\mathcal{X}$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

 is a continuous random variable, 
\begin_inset Formula $F_{Y}\left(y\right)=1-F_{X}\left(g^{-1}\left(y\right)\right)$
\end_inset

 for 
\begin_inset Formula $y\in\mathcal{Y}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Theorem
(This is Theorem 2.1.3 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:cdf-of-function-of-rv"

\end_inset


\end_layout

\begin_layout Proof
[proof goes here]
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 have pdf 
\begin_inset Formula $f_{X}\left(x\right)$
\end_inset

 and let 
\begin_inset Formula $Y=g\left(X\right)$
\end_inset

, where 
\begin_inset Formula $g$
\end_inset

 is a monotone function.
 Let 
\begin_inset Formula $\mathcal{X}=\left\{ x:f_{X}\left(x\right)>0\right\} $
\end_inset

 and let 
\begin_inset Formula $\mathcal{Y}=\left\{ y:y=g\left(x\right),x\in\mathcal{X}\right\} $
\end_inset

.
 Suppose that 
\begin_inset Formula $f_{X}\left(x\right)$
\end_inset

 is continuous on 
\begin_inset Formula $\mathcal{X}$
\end_inset

 and that 
\begin_inset Formula $g^{-1}\left(y\right)$
\end_inset

 has a continuous derivative on 
\begin_inset Formula $\mathcal{Y}$
\end_inset

.
 Then the pdf of 
\begin_inset Formula $Y$
\end_inset

 is given by
\begin_inset Formula 
\[
f_{Y}\left(y\right)=\begin{cases}
f_{X}\left(g^{-1}\left(y\right)\right)\left|\dfrac{\mbox{d}}{\mbox{d}y}g^{-1}\left(y\right)\right|, & y\in\mathcal{Y}\\
0, & \mbox{otherwise}
\end{cases}.
\]

\end_inset

(This is Theorem 2.1.5 from Casella & Berger.)
\end_layout

\begin_deeper
\begin_layout Proof
From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:cdf-of-function-of-rv"

\end_inset

 and applying the chain rule, we have
\begin_inset Formula 
\begin{flalign*}
f_{Y}\left(y\right) & =\dfrac{\mbox{d}}{\mbox{d}y}F_{Y}\left(y\right)\\
 & =f_{X}\left(g^{-1}\left(y\right)\right)\dfrac{\mbox{d}}{\mbox{d}y}g^{-1}\left(y\right)
\end{flalign*}

\end_inset

in the case that 
\begin_inset Formula $g$
\end_inset

 is increasing and
\begin_inset Formula 
\begin{flalign*}
f_{Y}\left(y\right) & =\dfrac{\mbox{d}}{\mbox{d}y}F_{Y}\left(y\right)\\
 & =0-f_{X}\left(g^{-1}\left(y\right)\right)\dfrac{\mbox{d}}{\mbox{d}y}g^{-1}\left(y\right)\\
 & =-f_{X}\left(g^{-1}\left(y\right)\right)\dfrac{\mbox{d}}{\mbox{d}y}g^{-1}\left(y\right)
\end{flalign*}

\end_inset

in the case that 
\begin_inset Formula $g$
\end_inset

 is decreasing, which can be expressed concisely as in the theorem.
\end_layout

\end_deeper
\begin_layout Section
Order statistics
\end_layout

\begin_layout Standard
The order statistics of a random sample 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 are the sample values placed in ascending order.
 They are denoted by 
\begin_inset Formula $X_{\left(1\right)},\ldots,X_{\left(n\right)}$
\end_inset

.
 The order statistics are random variables that satisfy 
\begin_inset Formula $X_{\left(1\right)}\leq\ldots\leq X_{\left(n\right)}$
\end_inset

, and in particular, 
\begin_inset Formula $X_{\left(1\right)}=\underset{1\leq i\leq n}{\min}X_{i}$
\end_inset

 and 
\begin_inset Formula $X_{\left(n\right)}=\underset{1\leq i\leq n}{\max}X_{i}$
\end_inset

.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from a discrete distribution with pmf 
\begin_inset Formula $f_{X}\left(x_{i}\right)=p_{i}$
\end_inset

, where 
\begin_inset Formula $x_{1}<x_{2}<\cdots$
\end_inset

 are the possible values of 
\begin_inset Formula $X$
\end_inset

 in ascending order.
 Define 
\begin_inset Formula 
\begin{flalign*}
P_{0} & =0\\
P_{1} & =p_{1}\\
P_{2} & =p_{1}+p_{2}\\
 & \vdots\\
P_{i} & =p_{1}+p_{2}+\cdots+p_{i}\\
 & \vdots
\end{flalign*}

\end_inset

Let 
\begin_inset Formula $X_{\left(1\right)},\ldots,X_{\left(n\right)}$
\end_inset

 denote the order statistics from the sample.
 Then
\begin_inset Formula 
\[
P\left(\left\{ X_{\left(j\right)}\leq x_{i}\right\} \right)=\sum_{k=j}^{n}\binom{n}{k}P_{i}^{k}\left(1-P_{i}\right)^{n-k}
\]

\end_inset

and
\begin_inset Formula 
\[
P\left(\left\{ X_{\left(j\right)}=x_{i}\right\} \right)=\sum_{k=j}^{n}\binom{n}{k}\left[P_{i}^{k}\left(1-P_{i}\right)^{n-k}-P_{i-1}^{k}\left(1-P_{i-1}\right)^{n-k}\right].
\]

\end_inset

(This is Theorem 5.4.3 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:order-stat-discrete"

\end_inset


\end_layout

\begin_layout Proof
[add the proof]
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X_{\left(1\right)},\ldots,X_{\left(n\right)}$
\end_inset

 denote the order statistics of a random sample, 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

, from a continuous population with cdf 
\begin_inset Formula $F_{X}\left(x\right)$
\end_inset

 and pdf 
\begin_inset Formula $f_{X}\left(x\right)$
\end_inset

.
 Then the pdf of 
\begin_inset Formula $X_{\left(j\right)}$
\end_inset

 is
\begin_inset Formula 
\[
f_{X_{\left(j\right)}}\left(x\right)=\frac{n!}{\left(j-1\right)!\left(n-j\right)!}f_{X}\left(x\right)\left[F_{X}\left(x\right)\right]^{j-1}\left[1-F_{X}\left(x\right)\right]^{n-j}.
\]

\end_inset

(This is Theorem 5.4.4 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:order-stat-continuous"

\end_inset


\end_layout

\begin_layout Proof
[add the proof]
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X_{\left(1\right)},\ldots,X_{\left(n\right)}$
\end_inset

 denote the order statistics of a random sample, 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

, from a continuous population with cdf 
\begin_inset Formula $F_{X}\left(x\right)$
\end_inset

 and pdf 
\begin_inset Formula $f_{X}\left(x\right)$
\end_inset

.
 Then the joint pdf of 
\begin_inset Formula $X_{\left(i\right)}$
\end_inset

 and 
\begin_inset Formula $X_{\left(j\right)}$
\end_inset

, 
\begin_inset Formula $1\leq i<j\leq n$
\end_inset

, is
\begin_inset Formula 
\begin{flalign*}
f_{X_{\left(i\right)},X_{\left(j\right)}}\left(u,v\right) & =\frac{n!}{\left(i-1\right)!\left(j-1-i\right)!\left(n-j\right)!}f_{X}\left(u\right)f_{X}\left(v\right)\left[F_{X}\left(u\right)\right]^{i-1}\left[F_{X}\left(v\right)-F_{X}\left(u\right)\right]^{j-1-i}\left[1-F_{X}\left(v\right)\right]^{n-j}
\end{flalign*}

\end_inset

for 
\begin_inset Formula $-\infty<u<v<\infty$
\end_inset

.
 (This is Theorem 5.4.6 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:order-stat-joint-pdf"

\end_inset


\end_layout

\begin_layout Proof
[add the proof]
\end_layout

\begin_layout Chapter
Common families of distributions
\end_layout

\begin_layout Section
Exponential families
\end_layout

\begin_layout Standard
A family of pdfs (or pmfs) indexed by a parameter 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is called a 
\begin_inset Formula $k$
\end_inset

-parameter exponential family if it can be expressed as 
\begin_inset Formula 
\[
f\left(x|\boldsymbol{\theta}\right)=h\left(x\right)c\left(\boldsymbol{\theta}\right)\exp\left\{ \sum_{j=1}^{k}\omega_{j}\left(\boldsymbol{\theta}\right)t_{j}\left(x\right)\right\} 
\]

\end_inset

where 
\begin_inset Formula $h\left(x\right)\geq0$
\end_inset

, 
\begin_inset Formula $c\left(\boldsymbol{\theta}\right)\geq0$
\end_inset

, 
\begin_inset Formula $t_{1}\left(x\right),\ldots,t_{k}\left(x\right)$
\end_inset

 are real-valued functions of 
\begin_inset Formula $x$
\end_inset

, and 
\begin_inset Formula $\omega_{1}\left(\boldsymbol{\theta}\right),\ldots,\omega_{k}\left(\boldsymbol{\theta}\right)$
\end_inset

 are real-valued functions of the possibly vector-valued parameter 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 I.e., 
\begin_inset Formula $f\left(x|\boldsymbol{\theta}\right)$
\end_inset

 can be expressed in three parts: a part that depends only on the random
 variable(s), a part that depends only on the parameter(s), and a part that
 depends on both the random variable(s) and the parameter(s).
 Most of the parametric models you have studied in Math-501 are exponential
 families, e.g., normal, gamma, beta, binomial, negative binomial, Poisson,
 and multinomial.
 The uniform distribution is not an exponential family (see example 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Example:-uniform-random"

\end_inset

 below).
\begin_inset CommandInset label
LatexCommand label
name "sec:defn-exp-family"

\end_inset


\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Logistic regression]
\end_layout

\end_inset

For 
\begin_inset Formula $y_{1},y_{2},\ldots,y_{n}$
\end_inset

, let 
\begin_inset Formula $y_{i}\sim Bernoulli\left(p\right)$
\end_inset

, i.e., 
\begin_inset Formula 
\[
y_{i}=\begin{cases}
0, & \mbox{if no event}\\
1, & \mbox{if event.}
\end{cases}
\]

\end_inset

Then the logistic regression model is
\begin_inset Formula 
\[
\log\left(\frac{p}{1-p}\right)=\beta_{0}+\beta_{1}X_{1}+\ldots+\beta_{k}X_{k}
\]

\end_inset

where 
\begin_inset Formula $\log\left(p/\left(1-p\right)\right)$
\end_inset

 is called the logit link.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Binomial random variables]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim B\left(n,p\right)$
\end_inset

, where 
\begin_inset Formula $p\in\left(0,1\right)$
\end_inset

.
 Recall that 
\begin_inset Formula $X$
\end_inset

 represents the number of successes in 
\begin_inset Formula $n$
\end_inset

 i.i.d.
 Bernoulli trials and its pmf is given by 
\begin_inset Formula 
\begin{flalign*}
f\left(x|p\right) & =\binom{n}{x}p^{x}\left(1-p\right)^{n-x}
\end{flalign*}

\end_inset

for 
\begin_inset Formula $x=0,1,\ldots,n$
\end_inset

 and 
\begin_inset Formula $f\left(x|p\right)=0$
\end_inset

 otherwise.
 Express 
\begin_inset Formula $f\left(x|p\right)$
\end_inset

 in exponential family form.
\begin_inset CommandInset label
LatexCommand label
name "exa:exp-family-binomial"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{flalign*}
f\left(x|p\right) & =\binom{n}{x}p^{x}\left(1-p\right)^{n-x}\\
 & =\binom{n}{x}p^{x}\left(1-p\right)^{n}\left(1-p\right)^{-x}\\
 & =\binom{n}{x}\left(1-p\right)^{n}\left(\frac{p^{x}}{\left(1-p\right)^{x}}\right)\\
 & =\binom{n}{x}\left(1-p\right)^{n}\left(\frac{p}{1-p}\right)^{x}\\
 & =\binom{n}{x}\left(1-p\right)^{n}\exp\left\{ \log\left(\frac{p}{1-p}\right)^{x}\right\} \\
 & =\underbrace{\binom{n}{x}}_{h\left(x\right)}\underbrace{\left(1-p\right)^{n}}_{c\left(p\right)}\exp\left\{ \underbrace{x}_{t_{1}\left(x\right)}\underbrace{\log\left(\frac{p}{1-p}\right)}_{\omega_{1}\left(p\right)}\right\} 
\end{flalign*}

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Poisson random variables]
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sub:exp-family-poisson"

\end_inset

Let 
\begin_inset Formula $X\sim P\left(\lambda\right)$
\end_inset

, where 
\begin_inset Formula $\lambda>0$
\end_inset

.
 Recall that 
\begin_inset Formula $X$
\end_inset

 represents the frequency with which a specified event occurs given some
 fixed dimension, such as space or time, and its pmf is given by
\begin_inset Formula 
\[
f\left(x|\lambda\right)=\frac{e^{-\lambda}\lambda^{x}}{x!}
\]

\end_inset

for 
\begin_inset Formula $x=0,1,2,\ldots$
\end_inset

 and 
\begin_inset Formula $f\left(x|\lambda\right)=0$
\end_inset

 otherwise.
 Express 
\begin_inset Formula $f\left(x|\lambda\right)$
\end_inset

 in exponential family form.
\begin_inset Formula 
\begin{flalign*}
f\left(x|\lambda\right) & =\frac{e^{-\lambda}\lambda^{x}}{x!}\\
 & =\frac{1}{x!}e^{-\lambda}\exp\left\{ \log\left(\lambda^{x}\right)\right\} \\
 & =\frac{1}{x!}e^{-\lambda}\exp\left\{ x\log\lambda\right\} 
\end{flalign*}

\end_inset

Then, we have 
\begin_inset Formula $h\left(x\right)=1/x!$
\end_inset

, 
\begin_inset Formula $c\left(\lambda\right)=e^{-\lambda}$
\end_inset

, 
\begin_inset Formula $t_{1}\left(x\right)=x$
\end_inset

, and 
\begin_inset Formula $\omega_{1}\left(\lambda\right)=\log\lambda$
\end_inset

.
 In a Poisson regression, we have 
\begin_inset Formula $\log\left(\lambda\right)=\beta_{0}+\beta_{1}X_{1}+\ldots+\beta_{k}X_{k}$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Normal random variables]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim N\left(\mu,\sigma^{2}\right)$
\end_inset

, where 
\begin_inset Formula $\mu\in\mathbb{R}$
\end_inset

 and 
\begin_inset Formula $\sigma>0$
\end_inset

.
 A pdf for 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f\left(x|\mu,\sigma^{2}\right) & =\frac{1}{\sqrt{2\pi}\sigma}\exp\left\{ -\frac{\left(x-\mu\right)^{2}}{2\sigma^{2}}\right\} 
\end{flalign*}

\end_inset

for 
\begin_inset Formula $x\in\mathbb{R}$
\end_inset

.
 Express 
\begin_inset Formula $f\left(x|\mu,\sigma^{2}\right)$
\end_inset

 in exponential family form.
\begin_inset CommandInset label
LatexCommand label
name "exa:exp-family-normal"

\end_inset


\end_layout

\begin_layout Example
Suppose 
\begin_inset Formula $\sigma$
\end_inset

 is known.
\begin_inset Formula 
\begin{flalign*}
f\left(x|\mu\right) & =\frac{1}{\sqrt{2\pi}\sigma}\exp\left\{ -\frac{x^{2}-2\mu x+\mu^{2}}{2\sigma^{2}}\right\} \\
 & =\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left\{ -\frac{x^{2}}{2\sigma^{2}}\right\} \exp\left\{ -\frac{\mu^{2}}{2\sigma^{2}}\right\} \exp\left\{ -\frac{-2\mu x}{2\sigma^{2}}\right\} \\
 & =\underbrace{\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left\{ -\frac{x^{2}}{2\sigma^{2}}\right\} }_{h\left(x\right)}\underbrace{\exp\left\{ -\frac{\mu^{2}}{2\sigma^{2}}\right\} }_{c\left(\mu\right)}\exp\left\{ \underbrace{\frac{\mu}{\sigma^{2}}}_{\omega_{1}\left(\mu\right)}\cdot\underbrace{x}_{t_{1}\left(x\right)}\right\} 
\end{flalign*}

\end_inset

Suppose 
\begin_inset Formula $\sigma$
\end_inset

 is unknown.
\begin_inset Formula 
\begin{flalign*}
f\left(x|\mu,\sigma^{2}\right) & =\frac{1}{\sqrt{2\pi}\sigma}\exp\left\{ -\frac{\left(x-\mu\right)^{2}}{2\sigma^{2}}\right\} \\
 & =\frac{1}{\sqrt{2\pi}}\left(\sigma^{2}\right)^{-1/2}\exp\left\{ -\frac{x^{2}-2\mu x+\mu^{2}}{2\sigma^{2}}\right\} \\
 & =\frac{1}{\sqrt{2\pi}}\exp\left\{ \log\left(\sigma^{2}\right)^{-1/2}\right\} \exp\left\{ -\frac{x^{2}-2\mu x}{2\sigma^{2}}\right\} \exp\left\{ -\frac{\mu^{2}}{2\sigma^{2}}\right\} \\
 & =\underbrace{\frac{1}{\sqrt{2\pi}}}_{h\left(x\right)}\underbrace{\exp\left\{ -\frac{\mu^{2}}{2\sigma^{2}}-\frac{1}{2}\log\sigma^{2}\right\} }_{c\left(\mu,\sigma^{2}\right)}\exp\left\{ \underbrace{\frac{1}{\sigma^{2}}}_{\omega_{1}\left(\mu,\sigma^{2}\right)}\cdot\underbrace{\left(-\frac{x^{2}}{2}\right)}_{t_{1}\left(x\right)}+\underbrace{\frac{\mu}{\sigma^{2}}}_{\omega_{2}\left(\mu,\sigma^{2}\right)}\cdot\underbrace{x}_{t_{2}\left(x\right)}\right\} 
\end{flalign*}

\end_inset

Thus, in the case that 
\begin_inset Formula $\sigma$
\end_inset

 is unknown, 
\begin_inset Formula $f\left(x|\mu,\sigma^{2}\right)$
\end_inset

 is a two-parameter exponential family, i.e., we have 
\begin_inset Formula $k=2$
\end_inset

 for 
\begin_inset Formula $\sum_{j=1}^{k}\omega_{j}\left(\theta\right)t_{j}\left(x\right)$
\end_inset

.
\end_layout

\begin_layout Definition
The 
\shape italic
indicator function
\shape default
 of a set 
\begin_inset Formula $A$
\end_inset

, most often denoted by 
\begin_inset Formula $I_{A}\left(x\right)$
\end_inset

, is the function
\begin_inset Formula 
\[
I_{A}\left(x\right)=\begin{cases}
1, & x\in A\\
0, & x\notin A
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Uniform random variables]
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sub:Example:-uniform-random"

\end_inset

Let 
\begin_inset Formula $X\sim U\left(0,\theta\right)$
\end_inset

, where 
\begin_inset Formula $\theta>0$
\end_inset

.
 A pdf for 
\begin_inset Formula $X$
\end_inset

 is given by 
\begin_inset Formula 
\begin{flalign*}
f\left(x|\theta\right) & =\frac{1}{\theta-0}\\
 & =\frac{1}{\theta}
\end{flalign*}

\end_inset

for 
\begin_inset Formula $0<x<\theta$
\end_inset

.
 Express 
\begin_inset Formula $f\left(x|\theta\right)$
\end_inset

 in exponential family form, if possible.
 Let 
\begin_inset Formula $A=\left\{ x:x\in\left(0,\theta\right)\right\} $
\end_inset

 and let 
\begin_inset Formula $I_{A}$
\end_inset

 be the indicator function of 
\begin_inset Formula $A$
\end_inset

, i.e.,
\begin_inset Formula 
\[
I_{A}\left(x\right)=\begin{cases}
1, & \mbox{if }x\in A\\
0, & \mbox{if }x\notin A
\end{cases}.
\]

\end_inset

Then, we can write 
\begin_inset Formula $f\left(x|\theta\right)$
\end_inset

 as
\begin_inset Formula 
\begin{flalign*}
f\left(x|\theta\right) & =\frac{1}{\theta}I_{A}\left(x\right)\\
 & =\frac{1}{\theta}I_{\left(0,\theta\right)}\left(x\right).
\end{flalign*}

\end_inset

Notice that 
\begin_inset Formula $I_{\left(0,\theta\right)}\left(x\right)$
\end_inset

 is not a function of 
\begin_inset Formula $x$
\end_inset

 exclusively, not a function of 
\begin_inset Formula $\theta$
\end_inset

 exclusively, and cannot be written as an exponential.
 Because the entire pdf must be incorporated into 
\begin_inset Formula $h\left(x\right)$
\end_inset

, 
\begin_inset Formula $c\left(\theta\right)$
\end_inset

, 
\begin_inset Formula $t_{j}\left(x\right)$
\end_inset

, and 
\begin_inset Formula $\omega_{j}\left(\theta\right)$
\end_inset

, it follows that the familiy of pdfs given by 
\begin_inset Formula $f\left(x|\theta\right)$
\end_inset

 is not an exponential family.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Three-parameter exponential family distribution]
\end_layout

\end_inset

Consider the family of distributions with densities
\begin_inset Formula 
\begin{flalign*}
f\left(x|\theta\right) & =\frac{2}{\Gamma\left(1/4\right)}\exp\left[-\left(x-\theta\right)^{4}\right]
\end{flalign*}

\end_inset

for 
\begin_inset Formula $x\in\mathbb{R}$
\end_inset

.
 Express 
\begin_inset Formula $f\left(x|\theta\right)$
\end_inset

 in exponential family form.
\begin_inset CommandInset label
LatexCommand label
name "exa:3-param-exp-family"

\end_inset


\end_layout

\begin_layout Example
Recall that the binomial theorem states that
\begin_inset Formula 
\begin{flalign*}
\left(x+y\right)^{n} & =\sum_{k=0}^{n}\binom{n}{k}x^{k}y^{n-k},
\end{flalign*}

\end_inset

so we have
\begin_inset Formula 
\begin{flalign*}
f\left(x|\theta\right) & =\frac{2}{\Gamma\left(1/4\right)}\exp\left[-\left(x-\theta\right)^{4}\right]\\
 & =\frac{2}{\Gamma\left(1/4\right)}\exp\left\{ -\sum_{k=0}^{4}\binom{4}{k}x^{k}\left(-\theta\right)^{4-k}\right\} \\
 & =\frac{2}{\Gamma\left(1/4\right)}\exp\left\{ -\left[\binom{4}{0}x^{0}\left(-\theta\right)^{4}+\binom{4}{1}x\left(-\theta\right)^{3}+\binom{4}{2}x^{2}\left(-\theta\right)^{2}+\binom{4}{3}x^{3}\left(-\theta\right)+\binom{4}{4}x^{4}\left(-\theta\right)^{0}\right]\right\} \\
 & =\frac{2}{\Gamma\left(1/4\right)}\exp\left\{ -\left[1\cdot1\cdot\theta^{4}-4x\theta^{3}+6x^{2}\theta^{2}-4x^{3}\theta+1\cdot x^{4}\cdot1\right]\right\} \\
 & =\underbrace{\frac{2}{\Gamma\left(1/4\right)}\exp\left\{ -x^{4}\right\} }_{h\left(x\right)}\underbrace{\exp\left\{ -\theta^{4}\right\} }_{c\left(\theta\right)}\exp\left\{ \underbrace{4x^{3}}_{t_{1}\left(x\right)}\underbrace{\theta}_{\omega_{1}\left(\theta\right)}\underbrace{-6x^{2}}_{t_{2}\left(x\right)}\underbrace{\theta^{2}}_{\omega_{2}\left(\theta\right)}+\underbrace{4x}_{t_{3}\left(x\right)}\underbrace{\theta^{3}}_{\omega_{3}\left(\theta\right)}\right\} .
\end{flalign*}

\end_inset


\end_layout

\begin_layout Theorem
Random samples from 
\begin_inset Formula $k$
\end_inset

-parameter exponential families have joint distributions which are 
\begin_inset Formula $k$
\end_inset

-parameter exponential families.
\end_layout

\begin_layout Proof
Suppose that a random variable 
\begin_inset Formula $X$
\end_inset

 has a pdf 
\begin_inset Formula $f\left(x|\theta\right)$
\end_inset

, and that 
\begin_inset Formula $X_{1},X_{2},\ldots,X_{n}$
\end_inset

 is a random sample from a population having the distribution of 
\begin_inset Formula $X$
\end_inset

.
 It follows that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are independent and identically distributed, and that each 
\begin_inset Formula $X_{i}$
\end_inset

 has the same cdf as 
\begin_inset Formula $X$
\end_inset

, and therefore that 
\begin_inset Formula $f\left(x|\theta\right)$
\end_inset

 is a pdf for each 
\begin_inset Formula $X_{i}$
\end_inset

.
 Then, the joint pdf of the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign}
f\left(x_{1},x_{2},\ldots,x_{n}|\theta\right) & =\prod_{i=1}^{n}f\left(x_{i}|\theta\right)\label{eq:joint-distr-proof-step-1}\\
 & =\prod_{i=1}^{n}\left[h\left(x_{i}\right)c\left(\theta\right)\exp\left\{ \sum_{j=1}^{k}t_{j}\left(x_{i}\right)\omega_{j}\left(\theta\right)\right\} \right]\label{eq:joint-distr-proof-step-2}\\
 & =\left[\prod_{i=1}^{n}h\left(x_{i}\right)\right]\left[c\left(\theta\right)\right]^{n}\exp\left\{ \sum_{j=1}^{k}\sum_{i=1}^{n}t_{j}\left(x_{i}\right)\omega_{j}\left(\theta\right)\right\} \label{eq:joint-distr-proof-step-3}
\end{flalign}

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:joint-distr-proof-step-1"

\end_inset

 follows because the joint pdf of independent random variables is the product
 of their marginal pdfs.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:joint-distr-proof-step-2"

\end_inset

 follows because we are given that the pdf of 
\begin_inset Formula $X$
\end_inset

 is part of a 
\begin_inset Formula $k$
\end_inset

-parameter exponential family, so it can be written in that form.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:joint-distr-proof-step-3"

\end_inset

 follows from algebra, and because the product of exponentials is an exponential
 raised to the sum of the individual powers, e.g., 
\begin_inset Formula $e^{x_{1}}\cdot e^{x_{2}}=e^{x_{1}+x_{2}}$
\end_inset

.
 Then, let 
\begin_inset Formula 
\begin{flalign*}
h^{*}\left(x\right) & =\prod_{i=1}^{n}h\left(x_{i}\right)\\
c^{*}\left(\theta\right) & =\left[c\left(\theta\right)\right]^{n},
\end{flalign*}

\end_inset

so that we have
\begin_inset Formula 
\begin{flalign*}
f\left(x_{1},x_{2},\ldots,x_{n}|\theta\right) & =\left[\prod_{i=1}^{n}h\left(x_{i}\right)\right]\left[c\left(\theta\right)\right]^{n}\exp\left\{ \sum_{j=1}^{k}\sum_{i=1}^{n}t_{j}\left(x_{i}\right)\omega_{j}\left(\theta\right)\right\} \\
 & =h^{*}\left(x\right)c^{*}\left(\theta\right)\exp\left\{ \sum_{j=1}^{k}\left(\omega_{j}\left(\theta\right)\sum_{i=1}^{n}t_{j}\left(x_{i}\right)\right)\right\} .
\end{flalign*}

\end_inset

Now, let 
\begin_inset Formula 
\begin{flalign*}
T_{j}\left(x\right) & =\sum_{i=1}^{n}t_{j}\left(x_{i}\right),
\end{flalign*}

\end_inset

so that 
\begin_inset Formula 
\begin{flalign*}
f\left(x_{1},x_{2},\ldots,x_{n}|\theta\right) & =h^{*}\left(x\right)c^{*}\left(\theta\right)\exp\left\{ \sum_{j=1}^{k}\omega_{j}\left(\theta\right)T_{j}\left(x\right)\right\} .
\end{flalign*}

\end_inset

Thus, the joint pdf 
\begin_inset Formula $f\left(x_{1},x_{2},\ldots,x_{n}|\theta\right)$
\end_inset

 is a 
\begin_inset Formula $k$
\end_inset

-parameter exponential family.
\end_layout

\begin_layout Subsection
Natural parameters
\begin_inset CommandInset label
LatexCommand label
name "sec:Natural-parameters"

\end_inset


\end_layout

\begin_layout Standard
An exponential family is sometimes reparametrized as
\begin_inset Formula 
\begin{flalign*}
f\left(x|\eta\right) & =h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{j=1}^{k}\eta_{j}t_{j}\left(x\right)\right),
\end{flalign*}

\end_inset

where the natural parameters are defined by 
\begin_inset Formula $\eta_{j}=\omega_{j}\left(\theta\right)$
\end_inset

 and the natural parameter space is
\begin_inset Formula 
\[
\left\{ \eta=\left(\eta_{1},\ldots,\eta_{k}\right):\int h\left(x\right)\exp\left\{ \sum_{j=1}^{k}\eta_{j}t_{j}\left(x\right)\right\} \mbox{d}x<\infty\right\} 
\]

\end_inset

so that 
\begin_inset Formula 
\begin{flalign*}
c^{*}\left(\eta\right) & =\frac{1}{\int h\left(x\right)\exp\left\{ \sum_{j=1}^{k}\eta_{j}t_{j}\left(x\right)\mbox{d}x\right\} },
\end{flalign*}

\end_inset

which ensures that the pdf integrates to 1.
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Binomial random variables]
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sub:natural-param-binomial"

\end_inset

Let 
\begin_inset Formula $X\sim B\left(n,p\right)$
\end_inset

.
 From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:exp-family-binomial"

\end_inset

, the pmf of 
\begin_inset Formula $X$
\end_inset

 can be written as 
\begin_inset Formula 
\begin{flalign*}
f\left(x|p\right) & =\binom{n}{x}\left(1-p\right)^{n}\exp\left\{ x\log\left(\frac{p}{1-p}\right)\right\} ,
\end{flalign*}

\end_inset

where 
\begin_inset Formula $k=1$
\end_inset

 and 
\begin_inset Formula 
\begin{flalign*}
\omega_{1}\left(p\right) & =\log\frac{p}{1-p}.
\end{flalign*}

\end_inset

Then, let 
\begin_inset Formula $\eta=\omega_{1}\left(p\right)$
\end_inset

, so that
\begin_inset Formula 
\begin{flalign*}
\eta & =\log\frac{p}{1-p}\\
e^{\eta} & =\exp\left(\log\frac{p}{1-p}\right)\\
e^{\eta} & =\frac{p}{1-p}\\
p & =e^{\eta}\left(1-p\right)\\
p & =e^{\eta}-e^{\eta}p\\
e^{\eta} & =p\left(1+e^{\eta}\right)\\
p & =\frac{e^{\eta}}{1+e^{\eta}}.
\end{flalign*}

\end_inset

Then, we have
\begin_inset Formula 
\begin{flalign*}
c\left(p\right) & =\left(1-p\right)^{n}\\
c\left(\eta\right) & =\left(1-\frac{e^{\eta}}{1+e^{\eta}}\right)^{n}\\
 & =\left(\frac{1}{1+e^{\eta}}\right)^{n}
\end{flalign*}

\end_inset

and 
\begin_inset Formula 
\begin{flalign*}
f\left(x|\eta\right) & =\binom{n}{x}\left(\frac{1}{1+e^{\eta}}\right)^{n}\exp\left(x\eta\right).
\end{flalign*}

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Poisson random variables]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim P\left(\lambda\right)$
\end_inset

.
 From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:exp-family-poisson"

\end_inset

, the pmf of 
\begin_inset Formula $X$
\end_inset

 can be written as 
\begin_inset Formula 
\begin{flalign*}
f\left(x|\lambda\right) & =\frac{1}{x!}e^{-\lambda}\exp\left\{ x\log\lambda\right\} ,
\end{flalign*}

\end_inset

where 
\begin_inset Formula $k=1$
\end_inset

 and
\begin_inset Formula 
\begin{flalign*}
\omega_{1}\left(\lambda\right) & =\log\lambda.
\end{flalign*}

\end_inset

Then, let 
\begin_inset Formula $\eta=\omega_{1}\left(\lambda\right)$
\end_inset

, so that
\begin_inset Formula 
\begin{flalign*}
\eta & =\log\lambda\\
e^{\eta} & =\exp\left(\log\lambda\right)\\
e^{\eta} & =\lambda.
\end{flalign*}

\end_inset

Then, we have
\begin_inset Formula 
\begin{flalign*}
c\left(\lambda\right) & =e^{-\lambda}\\
c\left(\eta\right) & =\exp\left(-e^{\eta}\right)
\end{flalign*}

\end_inset

and
\begin_inset Formula 
\begin{flalign*}
f\left(x|\eta\right) & =\frac{1}{x!}\exp\left(-e^{\eta}\right)\exp\left(x\eta\right).
\end{flalign*}

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Bernoulli random variables]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim Bernoulli\left(p\right)$
\end_inset

, i.e., 
\begin_inset Formula $X\sim B\left(1,p\right)$
\end_inset

.
 From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:natural-param-binomial"

\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
f\left(x|\eta\right) & =\binom{n}{x}\left(\frac{1}{1+e^{\eta}}\right)^{n}\exp\left(x\eta\right).
\end{flalign*}

\end_inset

With 
\begin_inset Formula $n=1$
\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
f\left(x|\eta\right) & =\binom{1}{x}\left(\frac{1}{1+e^{\eta}}\right)\exp\left(x\eta\right)\\
 & =1\cdot\left(\frac{1}{1+e^{\eta}}\right)\exp\left(x\eta\right)\\
 & =\frac{1}{1+e^{\eta}}\exp\left(x\eta\right).
\end{flalign*}

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Normal random variables]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim N\left(\mu,\sigma^{2}\right)$
\end_inset

, where 
\begin_inset Formula $\sigma>0$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 is unknown.
 From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:exp-family-normal"

\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
f\left(x|\mu,\sigma^{2}\right) & =\frac{1}{\sqrt{2\pi}}\exp\left\{ -\frac{\mu^{2}}{2\sigma^{2}}-\frac{1}{2}\log\sigma^{2}\right\} \exp\left\{ -x^{2}\frac{1}{2\sigma^{2}}+x\frac{\mu}{\sigma^{2}}\right\} .
\end{flalign*}

\end_inset

Then, let 
\begin_inset Formula $\eta_{1}=\omega_{1}\left(\mu,\sigma^{2}\right)$
\end_inset

, so that
\begin_inset Formula 
\begin{flalign*}
\eta_{1} & =\frac{1}{\sigma^{2}}\\
\sigma^{2}\eta_{1} & =1\\
\sigma^{2} & =\frac{1}{\eta_{1}}
\end{flalign*}

\end_inset

and let 
\begin_inset Formula $\eta_{2}=\omega_{2}\left(\mu,\sigma^{2}\right)$
\end_inset

, so that
\begin_inset Formula 
\begin{flalign*}
\eta_{2} & =\frac{\mu}{\sigma^{2}}\\
\mu & =\sigma^{2}\eta_{2}\\
 & =\frac{\eta_{2}}{\eta_{1}}.
\end{flalign*}

\end_inset

Then, we have
\begin_inset Formula 
\begin{flalign*}
c\left(\mu,\sigma^{2}\right) & =\exp\left\{ -\frac{\mu^{2}}{2\sigma^{2}}-\frac{1}{2}\log\sigma^{2}\right\} \\
c^{*}\left(\eta_{1},\eta_{2}\right) & =\exp\left\{ -\frac{\left(\frac{\eta_{2}}{\eta_{1}}\right)^{2}}{2\left(\frac{1}{\eta_{1}}\right)}-\frac{1}{2}\log\frac{1}{\eta_{1}}\right\} \\
 & =\exp\left\{ -\frac{\frac{\eta_{2}^{2}}{\eta_{1}^{2}}}{\frac{2}{\eta_{1}}}-\frac{1}{2}\log\frac{1}{\eta_{1}}\right\} \\
 & =\exp\left\{ -\frac{\eta_{2}^{2}}{2\eta_{1}}+\log\left(\frac{1}{\eta_{1}}\right)^{-1/2}\right\} \\
 & =\exp\left\{ -\frac{\eta_{2}^{2}}{2\eta_{1}}+\log\left(\left(\eta_{1}\right)^{-1}\right)^{-1/2}\right\} \\
 & =\exp\left\{ -\frac{\eta_{2}^{2}}{2\eta_{1}}+\log\sqrt{\eta_{1}}\right\} 
\end{flalign*}

\end_inset

and
\begin_inset Formula 
\begin{flalign*}
f\left(x|\eta_{1},\eta_{2}\right) & =\frac{1}{\sqrt{2\pi}}\exp\left\{ -\frac{\eta_{2}^{2}}{2\eta_{1}}+\log\sqrt{\eta_{1}}\right\} \exp\left\{ -\frac{\eta_{1}x^{2}}{2}+\eta_{2}x\right\} .
\end{flalign*}

\end_inset


\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 have density in an exponential family.
 Then,
\begin_inset Formula 
\begin{flalign}
\mbox{E}\left(t_{j}\left(X\right)\right) & =-\frac{\partial}{\partial\eta_{j}}\log c^{*}\left(\eta\right),\label{eq:expected-val-exp-family}\\
\mbox{Var}\left(t_{j}\left(X\right)\right) & =-\frac{\partial^{2}}{\partial\eta_{j}^{2}}\log c^{*}\left(\eta\right),
\end{flalign}

\end_inset

and the moment-generating function for 
\begin_inset Formula $\left(X_{1},\ldots,X_{k}\right)$
\end_inset

 is
\begin_inset Formula 
\begin{flalign*}
M_{\left(X_{1},\ldots,X_{k}\right)}\left(s_{1},\ldots,s_{k}\right) & =\mbox{E}\left[e^{\sum_{j=1}^{k}s_{j}x_{j}}\right].
\end{flalign*}

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "thm:expected-value-exp-family"

\end_inset


\end_layout

\begin_layout Proof
We begin with the pdf of an exponential family.
\begin_inset Formula 
\begin{flalign}
1 & =\int f\left(x|\theta\right)\mbox{d}x\label{eq:expected-val-proof-step-1}\\
 & =\int h\left(x\right)c\left(\theta\right)\exp\left(\sum_{i=1}^{k}\omega_{i}\left(\theta\right)t_{i}\left(x\right)\right)\mbox{d}x\label{eq:expected-val-proof-step-2}\\
 & =\int h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{i=1}^{k}\eta_{i}t_{i}\left(x\right)\right)\mbox{d}x\label{eq:expected-val-proof-step-3}\\
\frac{\partial}{\partial\eta_{j}}1 & =\frac{\partial}{\partial\eta_{j}}\int h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{i=1}^{k}\eta_{i}t_{i}\left(x\right)\right)\mbox{d}x\label{eq:expected-val-proof-step-4}\\
0 & =\int\frac{\partial}{\partial\eta_{j}}\left[h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{i=1}^{k}\eta_{i}t_{i}\left(x\right)\right)\right]\mbox{d}x\label{eq:expected-val-proof-step-5}\\
 & =\int h\left(x\right)\frac{\partial}{\partial\eta_{j}}\left(c^{*}\left(\eta\right)\right)\exp\left(\sum_{i=1}^{k}\eta_{i}t_{i}\left(x\right)\right)\mbox{d}x\label{eq:expected-val-proof-step-6}\\
 & \quad+\int h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{i=1}^{k}\eta_{i}t_{i}\left(x\right)\right)\left(\sum_{i=1}^{k}\frac{\partial}{\partial\eta_{j}}\left(\eta_{i}t_{i}\left(x\right)\right)\right)\mbox{d}x\nonumber \\
 & =\int h\left(x\right)\frac{\partial}{\partial\eta_{j}}\left(\log c^{*}\left(\eta\right)\right)c^{*}\left(\eta\right)\exp\left(\sum_{i=1}^{k}\eta_{i}t_{i}\left(x\right)\right)\mbox{d}x\label{eq:expected-val-proof-step-7}\\
 & \quad+\mbox{E}\left(\sum_{i=1}^{k}\frac{\partial}{\partial\eta_{j}}\left(\eta_{i}t_{i}\left(x\right)\right)\right)\nonumber \\
 & =\frac{\partial}{\partial\eta_{j}}\left(\log c^{*}\left(\eta\right)\right)\int h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{i=1}^{k}\eta_{i}t_{i}\left(x\right)\right)\mbox{d}x\label{eq:expected-val-proof-step-8}\\
 & \quad+\mbox{E}\left(\sum_{i=1}^{k}\frac{\partial}{\partial\eta_{j}}\left(\eta_{i}t_{i}\left(x\right)\right)\right)\nonumber \\
 & =\frac{\partial}{\partial\eta_{j}}\left(\log c^{*}\left(\eta\right)\right)\cdot1+\mbox{E}\left(\sum_{i=1}^{k}\frac{\partial}{\partial\eta_{j}}\left(\eta_{i}t_{i}\left(x\right)\right)\right)\label{eq:expected-val-proof-step-9}\\
-\frac{\partial}{\partial\eta_{j}}\log c^{*}\left(\eta\right) & =\mbox{E}\left(\frac{\partial}{\partial\eta_{j}}\eta_{1}t_{1}\left(x\right)+\ldots+\frac{\partial}{\partial\eta_{j}}\eta_{j}t_{j}\left(x\right)+\ldots+\frac{\partial}{\partial\eta_{j}}\eta_{k}t_{k}\left(x\right)\right)\label{eq:expected-val-proof-step-10}\\
 & =\mbox{E}\left(0\cdot t_{1}\left(x\right)+\ldots+1\cdot t_{j}\left(x\right)+\ldots+0\cdot t_{k}\left(x\right)\right)\label{eq:expected-val-proof-step-11}\\
 & =\mbox{E}\left(t_{j}\left(x\right)\right)\label{eq:expected-val-proof-step-12}
\end{flalign}

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-1"

\end_inset

 follows from the definition of a pdf.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-2"

\end_inset

 follows by expressing 
\begin_inset Formula $f\left(x|\theta\right)$
\end_inset

 in exponential family form.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-3"

\end_inset

 follows from the natural reparameterization of 
\begin_inset Formula $f\left(x|\theta\right)$
\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-4"

\end_inset

 follows by taking the derivative of both sides of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-3"

\end_inset

 with respect to 
\begin_inset Formula $\eta_{j}$
\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-5"

\end_inset

 follows from interchanging differentiation and integration.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-6"

\end_inset

 follows from the product rule and the chain rule.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-7"

\end_inset

 follows from the fact that 
\begin_inset Formula $g'\left(x\right)=g\left(x\right)\frac{\partial}{\partial x}\log\left(g\left(x\right)\right)$
\end_inset

 and the definition of expected value.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-8"

\end_inset

 follows because we are integrating with respect to 
\begin_inset Formula $x$
\end_inset

, so we may treat functions of 
\begin_inset Formula $\eta$
\end_inset

 exclusively as constant.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-9"

\end_inset

 follows because the pdf 
\begin_inset Formula $f\left(x|\eta\right)$
\end_inset

 integrates to 1.
 We rearrange terms and expand the sum to write 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-10"

\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-proof-step-11"

\end_inset

 follows because the derivative of 
\begin_inset Formula $\eta_{i}$
\end_inset

 with respect to 
\begin_inset Formula $\eta_{j}$
\end_inset

 is equal to zero for 
\begin_inset Formula $i\neq j$
\end_inset

 and is equal to 1 in the case where 
\begin_inset Formula $i=j$
\end_inset

.
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Expected value of a binomial random variable]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim B\left(n,p\right)$
\end_inset

.
 We will find the expected value of 
\begin_inset Formula $X$
\end_inset

 by applying 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:expected-value-exp-family"

\end_inset

.
 From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:natural-param-binomial"

\end_inset

, the pmf of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f\left(x|\eta\right) & =\binom{n}{x}\left(\frac{1}{1+e^{\eta}}\right)^{n}\exp\left(x\eta\right),
\end{flalign*}

\end_inset

where 
\begin_inset Formula $\eta=\log\left(p/\left(1-p\right)\right)$
\end_inset

, so that 
\begin_inset Formula $p=1/\left(1+e^{\eta}\right)$
\end_inset

.
 From the general form of a natural parameterization, we have 
\begin_inset Formula $k=1$
\end_inset

, 
\begin_inset Formula $t\left(x\right)=x$
\end_inset

, and 
\begin_inset Formula $c^{*}\left(\eta\right)=\left(1/\left(1+e^{\eta}\right)\right)^{n}$
\end_inset

.
 Then, we have 
\begin_inset Formula 
\begin{flalign*}
\mbox{E}\left(X\right) & =\mbox{E}\left(t\left(X\right)\right)\\
 & =-\frac{\partial}{\partial\eta}\log\left(\frac{1}{1+e^{\eta}}\right)^{n}\\
 & =-\frac{\partial}{\partial\eta}\log\left(1+e^{\eta}\right)^{-n}\\
 & =-\frac{\partial}{\partial\eta}\left(-n\log\left(1+e^{\eta}\right)\right)\\
 & =n\frac{\partial}{\partial\eta}\log\left(1+e^{\eta}\right)\\
 & =n\frac{e^{\eta}}{1+e^{\eta}}\\
 & =np.
\end{flalign*}

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $X$
\end_inset

 has a 
\begin_inset Formula $k$
\end_inset

-parameter exponential family distribution indexed by the natural parameters,
 then for any 
\begin_inset Formula $\eta$
\end_inset

 on the interior of the natural parameter space, the mgf of 
\begin_inset Formula $\left(t_{1}\left(X\right),\ldots,t_{k}\left(X\right)\right)$
\end_inset

 exists and is given by 
\begin_inset Formula 
\begin{flalign*}
M_{\left(t_{1}\left(X\right),\ldots,t_{k}\left(X\right)\right)}\left(s_{1},\ldots,s_{k}\right) & =\frac{C^{*}\left(\eta\right)}{C^{*}\left(\eta+s\right)}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $\eta+s$
\end_inset

 is the vector 
\begin_inset Formula $\left(\eta_{1}+s_{1},\ldots,\eta_{k}+s_{k}\right)$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "thm:mgf-natural-param"

\end_inset


\end_layout

\begin_layout Proof
Suppose that 
\begin_inset Formula $X$
\end_inset

 is a 
\begin_inset Formula $k$
\end_inset

-parameter exponential family distribution indexed by the natural parameters.
 Then, from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sec:Natural-parameters"

\end_inset

, it has a pdf given by
\begin_inset Formula 
\begin{flalign*}
f\left(x|\eta\right) & =h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{j=1}^{k}\eta_{j}t_{j}\left(x\right)\right).
\end{flalign*}

\end_inset

Then, we have
\begin_inset Formula 
\begin{flalign}
M_{\left(t_{1}\left(X\right),\ldots,t_{k}\left(X\right)\right)}\left(s_{1},\ldots,s_{k}\right) & =\mbox{E}\left[e^{\sum_{j=1}^{k}s_{j}t_{j}\left(x\right)}\right]\label{eq:mgf-proof-step-1}\\
 & =\int\exp\left(\sum_{j=1}^{k}s_{j}t_{j}\left(x\right)\right)h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{j=1}^{k}\eta_{j}t_{j}\left(x\right)\right)\mbox{d}x\label{eq:mgf-proof-step-2}\\
 & =\int h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{j=1}^{k}\left(s_{j}+\eta_{j}\right)t_{j}\left(x\right)\right)\mbox{d}x\label{eq:mgf-proof-step-3}\\
 & =\frac{c^{*}\left(\eta+s\right)}{c^{*}\left(\eta+s\right)}\int h\left(x\right)c^{*}\left(\eta\right)\exp\left(\sum_{j=1}^{k}\left(s_{j}+\eta_{j}\right)t_{j}\left(x\right)\right)\mbox{d}x\label{eq:mgf-proof-step-4}\\
 & =\frac{c^{*}\left(\eta\right)}{c^{*}\left(\eta+s\right)}\int h\left(x\right)c^{*}\left(\eta+s\right)\exp\left(\sum_{j=1}^{k}\left(s_{j}+\eta_{j}\right)t_{j}\left(x\right)\right)\mbox{d}x\label{eq:mgf-proof-step-5}\\
 & =\frac{c^{*}\left(\eta\right)}{c^{*}\left(\eta+s\right)}\cdot1\label{eq:mgf-proof-step-6}\\
 & =\frac{c^{*}\left(\eta\right)}{c^{*}\left(\eta+s\right)}.
\end{flalign}

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mgf-proof-step-1"

\end_inset

 follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:expected-value-exp-family"

\end_inset

 with 
\begin_inset Formula $X_{i}$
\end_inset

 replaced by 
\begin_inset Formula $t_{i}\left(X\right)$
\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mgf-proof-step-2"

\end_inset

 follows from the definition of expected value (of a function of a random
 variable, i.e., 
\begin_inset Formula $\mbox{E}\left(g\left(X\right)\right)$
\end_inset

).
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mgf-proof-step-3"

\end_inset

 follows from algebra.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mgf-proof-step-4"

\end_inset

 follows from multiplying by 
\begin_inset Formula $1=c^{*}\left(\eta+s\right)/c^{*}\left(\eta+s\right)$
\end_inset

.
 We rearrange terms to write 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mgf-proof-step-5"

\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mgf-proof-step-6"

\end_inset

 follows because the integral in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:mgf-proof-step-5"

\end_inset

 is the pdf of 
\begin_inset Formula $X$
\end_inset

 with parameter 
\begin_inset Formula $\eta+s$
\end_inset

, i.e., 
\begin_inset Formula $f\left(x|\eta+s\right)$
\end_inset

 and therefore integrates to 1.
\end_layout

\begin_layout Definition
A 
\shape italic
curved exponential family
\shape default
 is a family of densities of the form given in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sec:defn-exp-family"

\end_inset

 for which the dimension of the vector 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is equal to 
\begin_inset Formula $d<k$
\end_inset

, where 
\begin_inset Formula $k$
\end_inset

 is the number of terms in the sum in the exponent.
 If 
\begin_inset Formula $d=k$
\end_inset

, the family is a 
\shape italic
full exponential family
\shape default
.
\end_layout

\begin_layout Section
Location and scale families
\end_layout

\begin_layout Standard
Location families, scale families, and location-scale families are constructed
 by specifying a single pdf, 
\begin_inset Formula $f\left(x\right)$
\end_inset

, called the standard pdf for the family.
 Then, all other pdfs in the family are generated by transforming the standard
 pdf in a prescribed way.
\end_layout

\begin_layout Subsection
Location families
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $f\left(x\right)$
\end_inset

 be any pdf.
 Then, the family of pdfs indexed by 
\begin_inset Formula $\mu$
\end_inset

, 
\begin_inset Formula $f\left(x-\mu\right)$
\end_inset

, is called the 
\shape italic
location family
\shape default
 with respect to the standard pdf 
\begin_inset Formula $f$
\end_inset

, and 
\begin_inset Formula $\mu$
\end_inset

 is called the l
\shape italic
ocation parameter
\shape default
.
\end_layout

\begin_layout Standard
E.g., 
\begin_inset Formula $f\left(x\right)\sim N\left(0,1^{2}\right)$
\end_inset

, 
\begin_inset Formula $N\left(\mu,1^{2}\right)$
\end_inset

 is a location family.
 The location parameter 
\begin_inset Formula $\mu$
\end_inset

 simply shifts the pdf 
\begin_inset Formula $f\left(x\right)$
\end_inset

 so that the shape of the graph is unchanged but the point on the graph
 that was above 
\begin_inset Formula $x=0$
\end_inset

 under 
\begin_inset Formula $f\left(x\right)$
\end_inset

 is above 
\begin_inset Formula $x=\mu$
\end_inset

 for 
\begin_inset Formula $f\left(x-\mu\right)$
\end_inset

, thus
\begin_inset Formula 
\begin{flalign*}
P\left(\left\{ -1\leq X\leq2|X\sim f\left(x\right)\right\} \right) & =P\left(\left\{ \mu-1\leq X\leq\mu+2|X\sim f\left(x-\mu\right)\right\} \right).
\end{flalign*}

\end_inset

Figure 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ref{fig:ex-of-location-normal}
\end_layout

\end_inset

 shows the normal distribution with 
\begin_inset Formula $\sigma^{2}=1^{2}$
\end_inset

 and 
\begin_inset Formula $\mu=0$
\end_inset

, 
\begin_inset Formula $\mu=2$
\end_inset

, and 
\begin_inset Formula $\mu=-2$
\end_inset

 in red, blue, and green, respectively.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<ex-of-location-normal, echo=FALSE, fig.height=2, fig.width=3, fig.align='center',
 fig.pos='h', fig.cap='example of a normal location family'>>=
\end_layout

\begin_layout Plain Layout

x <- seq(-5,5,length=1000)
\end_layout

\begin_layout Plain Layout

par(mar=c(2,2,0.2,2))
\end_layout

\begin_layout Plain Layout

plot(x,dnorm(x, mean=0, sd=1), type="l", col="blue", ylab="f(x)", cex.lab=0.75,
 cex.axis=0.75, yaxt="n")
\end_layout

\begin_layout Plain Layout

lines(x,dnorm(x, mean=2, sd=1), type="l", col="red")
\end_layout

\begin_layout Plain Layout

lines(x,dnorm(x, mean=-2, sd=1), type="l", col="green")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Scale families
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $f\left(x\right)$
\end_inset

 be any pdf.
 Then, for any 
\begin_inset Formula $\sigma>0$
\end_inset

, the family of pdfs 
\begin_inset Formula $\left(1/\sigma\right)f\left(x/\sigma\right)$
\end_inset

, indexed by the parameter 
\begin_inset Formula $\sigma$
\end_inset

, is called the 
\shape italic
scale family
\shape default
 with standard pdf 
\begin_inset Formula $f\left(x\right)$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 is called the 
\shape italic
scale parameter
\shape default
 of the family.
\end_layout

\begin_layout Standard
E.g., 
\begin_inset Formula $f\left(x\right)\sim N\left(0,1^{2}\right)$
\end_inset

, 
\begin_inset Formula $N\left(0,\sigma^{2}\right)$
\end_inset

 is a scale family.
 The effect of introducing the scale parameter 
\begin_inset Formula $\sigma$
\end_inset

 is either to stretch (
\begin_inset Formula $\sigma>1$
\end_inset

) or to contract (
\begin_inset Formula $\sigma<1$
\end_inset

) the graph of 
\begin_inset Formula $f\left(x\right)$
\end_inset

 while still maintaining the same basic shape of the graph.
 Figure 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ref{fig:ex-of-scale-normal}
\end_layout

\end_inset

 shows the normal distribution with 
\begin_inset Formula $\mu=0$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}=1^{2}$
\end_inset

, 
\begin_inset Formula $\sigma^{2}=0.75^{2}$
\end_inset

, and 
\begin_inset Formula $\sigma^{2}=1.5^{2}$
\end_inset

 in red, blue, and green, respectively.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<ex-of-scale-normal, echo=FALSE, fig.height=2, fig.width=3, fig.align='center',
 fig.pos='h', fig.cap='example of a normal scale family'>>=
\end_layout

\begin_layout Plain Layout

x <- seq(-5,5,length=1000)
\end_layout

\begin_layout Plain Layout

par(mar=c(2,2,0.2,2))
\end_layout

\begin_layout Plain Layout

plot(x,dnorm(x, mean=0, sd=0.75), type="l", col="blue", ylab="f(x)", cex.lab=0.75,
 cex.axis=0.75, yaxt="n")
\end_layout

\begin_layout Plain Layout

lines(x,dnorm(x, mean=0, sd=1), type="l", col="red")
\end_layout

\begin_layout Plain Layout

lines(x,dnorm(x, mean=0, sd=1.5), type="l", col="green")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Location-scale families
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $f\left(x\right)$
\end_inset

 be any pdf.
 Then, for any 
\begin_inset Formula $-\infty<\mu<\infty$
\end_inset

 and any 
\begin_inset Formula $\sigma>0$
\end_inset

, the family of pdfs 
\begin_inset Formula $\left(1/\sigma\right)f\left(\left(x-\mu\right)/\sigma\right)$
\end_inset

 is called the location-scale family with standard pdf 
\begin_inset Formula $f\left(x\right)$
\end_inset

.
 
\begin_inset Formula $\mu$
\end_inset

 is called the location parameter and 
\begin_inset Formula $\sigma$
\end_inset

 is called the scale parameter.
 E.g., 
\begin_inset Formula $f\left(x\right)\sim N\left(0,1^{2}\right)$
\end_inset

, 
\begin_inset Formula $N\left(\mu,\sigma^{2}\right)$
\end_inset

 is a location-scale family.
 The effect of introducing both the location and scale parameters is to
 stretch/contract the graph with the scale parameter and shift the graph
 with the location parameter.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $f\left(x\right)$
\end_inset

 be any pdf.
 Let 
\begin_inset Formula $\mu$
\end_inset

 be any real number, and let 
\begin_inset Formula $\sigma$
\end_inset

 be any positive real number.
 Then 
\begin_inset Formula $X$
\end_inset

 is a random variable with pdf 
\begin_inset Formula $\left(1/\sigma\right)f\left(\left(x-\mu\right)/\sigma\right)$
\end_inset

 if and only if there exists a random variable 
\begin_inset Formula $Z$
\end_inset

 with pdf 
\begin_inset Formula $f\left(z\right)$
\end_inset

 and 
\begin_inset Formula $X=\sigma Z+\mu$
\end_inset

.
 (This is Theorem 3.5.6 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:location-scale-family"

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $X\sim\left(1/\sigma\right)f\left(\left(x-\mu\right)/\sigma\right)$
\end_inset

.
 Then, we have
\begin_inset Formula 
\begin{flalign}
F\left(x\right) & =P\left(\left\{ X\leq x\right\} \right)\label{eq:loc-scale-family-proof-step-1}\\
 & =\int_{-\infty}^{x}\frac{1}{\sigma}f\left(\frac{t-\mu}{\sigma}\right)\mbox{d}t\label{eq:loc-scale-family-proof-step-2}\\
 & =\int_{-\infty}^{\left(x-\mu\right)/\sigma}\frac{1}{\sigma}f\left(z\right)\sigma\mbox{d}z\label{eq:loc-scale-family-proof-step-3}\\
 & =\int_{-\infty}^{\left(x-\mu\right)/\sigma}f\left(z\right)\mbox{d}z\label{eq:loc-scale-family-proof-step-4}\\
 & =P\left(Z\leq\frac{x-\mu}{\sigma}\right)\label{eq:loc-scale-family-proof-step-5}\\
 & =P\left(\sigma Z+\mu\leq x\right).\label{eq:loc-scale-family-proof-step-6}
\end{flalign}

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:loc-scale-family-proof-step-1"

\end_inset

 is the definition of a cdf.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:loc-scale-family-proof-step-2"

\end_inset

 follows from the definition of a pdf.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:loc-scale-family-proof-step-3"

\end_inset

 follows from making the substitution 
\begin_inset Formula $z=\left(t-\mu\right)/\sigma$
\end_inset

, so that 
\begin_inset Formula $\mbox{d}t=\sigma\mbox{d}z$
\end_inset

, 
\begin_inset Formula $f\left(z\right)$
\end_inset

 is a pdf for 
\begin_inset Formula $Z$
\end_inset

, and the upper limit of integration is 
\begin_inset Formula $z\left(x\right)=\left(x-\mu\right)/\sigma$
\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:loc-scale-family-proof-step-4"

\end_inset

 follows from algebra.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:loc-scale-family-proof-step-5"

\end_inset

 follows from the definition of a pdf, and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:loc-scale-family-proof-step-6"

\end_inset

 follows from algebra.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $Z$
\end_inset

 be a random variable with pdf 
\begin_inset Formula $f\left(z\right)$
\end_inset

.
 Suppose 
\begin_inset Formula $\mbox{E}\left(Z\right)$
\end_inset

 and 
\begin_inset Formula $\mbox{Var}\left(Z\right)$
\end_inset

 exist.
 If 
\begin_inset Formula $X$
\end_inset

 is a random variable with pdf 
\begin_inset Formula $\left(1/\sigma\right)f\left(\left(x-\mu\right)/\sigma\right)$
\end_inset

, then 
\begin_inset Formula $\mbox{E}\left(X\right)=\sigma\mbox{E}\left(Z\right)+\mu$
\end_inset

, and 
\begin_inset Formula $\mbox{Var}\left(X\right)=\sigma^{2}\mbox{Var}\left(Z\right)$
\end_inset

.
 (This is Theorem 3.5.7 from Casella and Berger; the version in the lecture
 slides is a slight restatement.)
\end_layout

\begin_layout Proof
By 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:location-scale-family"

\end_inset

, there is a random variable 
\begin_inset Formula $Z^{*}$
\end_inset

 with pdf 
\begin_inset Formula $f\left(z\right)$
\end_inset

 and 
\begin_inset Formula $X=\sigma Z^{*}+\mu$
\end_inset

.
 So 
\begin_inset Formula 
\begin{flalign}
\mbox{E}\left(X\right) & =\mbox{E}\left(\sigma Z^{*}+\mu\right)\label{eq:expected-val-loc-scale-step-1}\\
 & =\mbox{E}\left(\sigma Z^{*}\right)+\mbox{E}\left(\mu\right)\label{eq:expected-val-loc-scale-step-2}\\
 & =\sigma\mbox{E}\left(Z^{*}\right)+\mu\label{eq:expected-val-loc-scale-step-3}\\
 & =\sigma\int z\cdot f\left(z\right)\mbox{d}z+\mu\label{eq:expected-val-loc-scale-step-4}\\
 & =\sigma\mbox{E}\left(Z\right)+\mu.\label{eq:expected-val-loc-scale-step-5}
\end{flalign}

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-loc-scale-step-1"

\end_inset

 follows by substituting for 
\begin_inset Formula $X$
\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-loc-scale-step-2"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-loc-scale-step-3"

\end_inset

 follow from the linearity of expected value.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-loc-scale-step-4"

\end_inset

 follows from the definition of expected value and because 
\begin_inset Formula $Z^{*}$
\end_inset

 has the same pdf 
\begin_inset Formula $f\left(z\right)$
\end_inset

 as 
\begin_inset Formula $Z$
\end_inset

, which is a consequence of 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:location-scale-family"

\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expected-val-loc-scale-step-5"

\end_inset

 follows from the definition of expected value.
 Q.E.D.
 Then, 
\begin_inset Formula 
\begin{flalign}
\mbox{Var}\left(X\right) & =\mbox{Var}\left(\sigma Z^{*}+\mu\right)\label{eq:variance-loc-scale-step-1}\\
 & =\mbox{E}\left(\left(\sigma Z^{*}+\mu\right)-\mbox{E}\left(\sigma Z^{*}+\mu\right)\right)^{2}\label{eq:variance-loc-scale-step-2}\\
 & =\mbox{E}\left(\sigma Z^{*}+\mu-\left(\sigma\mbox{E}\left(Z^{*}\right)+\mu\right)\right)^{2}\label{eq:variance-loc-scale-step-3}\\
 & =\mbox{E}\left(\sigma Z^{*}+\mu-\sigma\mbox{E}\left(Z^{*}\right)-\mu\right)^{2}\label{eq:variance-loc-scale-step-4}\\
 & =\mbox{E}\left(\sigma\left(Z^{*}-\mbox{E}\left(Z^{*}\right)\right)\right)^{2}\label{eq:variance-loc-scale-step-5}\\
 & =\left(\sigma\mbox{E}\left(Z^{*}-\mbox{E}\left(Z^{*}\right)\right)\right)^{2}\label{eq:variance-loc-scale-step-6}\\
 & =\sigma^{2}\mbox{E}\left(Z^{*}-\mbox{E}\left(Z^{*}\right)\right)^{2}\label{eq:variance-loc-scale-step-7}\\
 & =\sigma^{2}\mbox{Var}\left(Z^{*}\right)\label{eq:variance-loc-scale-step-8}\\
 & =\sigma^{2}\mbox{Var}\left(Z\right)\label{eq:variance-loc-scale-step-9}
\end{flalign}

\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-1"

\end_inset

 follows by substituting for 
\begin_inset Formula $X$
\end_inset

.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-2"

\end_inset

 follows from the definition of variance.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-3"

\end_inset

 follows from the linearity of expected value.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-4"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-5"

\end_inset

 follow from algebra.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-6"

\end_inset

 follows from the linearity of expected value.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-7"

\end_inset

 follows from algebra.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-8"

\end_inset

 follows from the definition of variance.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:variance-loc-scale-step-9"

\end_inset

 follows because 
\begin_inset Formula $Z^{*}$
\end_inset

 has the same pdf as 
\begin_inset Formula $Z$
\end_inset

.
\end_layout

\begin_layout Chapter
Principles of data reduction
\end_layout

\begin_layout Section
Sufficiency
\end_layout

\begin_layout Standard
The concept of sufficiency attempts to find a statistic 
\begin_inset Formula $T\left(X_{1},\ldots,X_{n}\right)$
\end_inset

 that contains all the information in the sample about the model parameter
 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Definition
A 
\shape italic
statistic
\shape default
 is a function 
\begin_inset Formula $T\left(X\right)$
\end_inset

 of the data, such as mean, variance, max, or min.
 
\begin_inset Formula $T\left(X\right)$
\end_inset

 is a random variable.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Definition
An 
\shape italic
estimate
\shape default
 is a statistic that is intended to be close to a parameter.
\end_layout

\begin_layout Subsection
Data reduction
\end_layout

\begin_layout Standard
Any statistic 
\begin_inset Formula $T\left(X\right)$
\end_inset

 defines a form of data reduction or data summary.
 An investigator who uses only the observed value of the statistic rather
 than the entire observed sample 
\series bold

\begin_inset Formula $\mathbf{X}$
\end_inset


\series default
 will treat as equal two samples 
\series bold

\begin_inset Formula $\mathbf{X}$
\end_inset


\series default
 and 
\series bold

\begin_inset Formula $\mathbf{Y}$
\end_inset


\series default
 that satisfy 
\begin_inset Formula $T\left(x\right)=T\left(y\right)$
\end_inset

 even though the actual sample values may be different in some ways.
 Data reduction in terms of a particular statistic can be thought of as
 a partition of the sample space 
\begin_inset Formula $\mathcal{X}$
\end_inset

 of 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

.
 
\begin_inset Formula $T\left(X\right)$
\end_inset

 reduces the data by partitioning the sample space into sets 
\begin_inset Formula $A_{t}$
\end_inset

, 
\begin_inset Formula $t\in\mathcal{T}$
\end_inset

, defined by 
\begin_inset Formula $A_{t}=\left\{ x:T\left(x\right)=t\right\} $
\end_inset

 where 
\begin_inset Formula $\mathcal{T}=\left\{ t:t=T\left(x\right)\right\} $
\end_inset

 for some 
\begin_inset Formula $x\in\mathcal{X}$
\end_inset

.
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Waiting time]
\end_layout

\end_inset

Suppose that 
\begin_inset Formula $X$
\end_inset

 represents waiting time, e.g., for a bus.
 We first collect data 
\begin_inset Formula $x_{1},\ldots,x_{n}$
\end_inset

.
 Suppose that we wish to find the mean waiting time 
\begin_inset Formula $\overline{x}=\left(1/n\right)\sum_{i=1}^{n}x_{i}$
\end_inset

, i.e., 
\begin_inset Formula $T\left(X\right)=\overline{x}$
\end_inset

.
 We calculate 
\begin_inset Formula $\overline{x}=8.32$
\end_inset

.
 Then, all sets of 
\begin_inset Formula $x_{1},\ldots,x_{n}$
\end_inset

 that give 
\begin_inset Formula $\overline{x}=8.32$
\end_inset

 are a partition of the sample space.
 Many points in the sample space have this same mean, and we can consider
 them as belonging to the set 
\begin_inset Formula $\left\{ \left(x_{1},\ldots,x_{n}\right):\overline{x}=8.32\right\} $
\end_inset

, which is also the hyperplane 
\begin_inset Formula $x_{1}+\cdots+x_{n}=\left(8.32\right)n$
\end_inset

.
 In this case, the sample mean 
\begin_inset Formula $\overline{X}$
\end_inset

 (or any statistic 
\begin_inset Formula $T\left(X\right)$
\end_inset

) partitions the sample space into a collection of sets.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sampling from a binomial distribution]
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sub:example-sampling-binom"

\end_inset

Let 
\begin_inset Formula $X\sim B\left(3,p\right)$
\end_inset

, where 
\begin_inset Formula $p\in\left(0,1\right)$
\end_inset

.
 Then, 
\begin_inset Formula $X$
\end_inset

 represents the number of successes in 3 trials of a random experiment.
 Suppose that we draw a sample of size 2, so that the sample space consists
 of
\begin_inset Formula 
\[
\left\{ \left(0,0\right),\left(0,1\right),\left(0,2\right),\left(0,3\right),\left(1,1\right),\left(1,2\right),\left(1,3\right),\left(2,2\right),\left(2,3\right),\left(3,3\right)\right\} .
\]

\end_inset

Let 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 be the maximum of the sample, i.e., 
\begin_inset Formula $T\left(\mathbf{X}\right)=\max\left(X_{1},X_{2}\right)$
\end_inset

.
 Then, 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 reduces the data by partitioning the sample space into sets 
\begin_inset Formula $A_{t}$
\end_inset

 with 
\begin_inset Formula $\mathcal{T}=\left\{ 0,1,2,3\right\} $
\end_inset

, i.e., 
\begin_inset Formula 
\begin{flalign*}
A_{0} & =\left\{ \left(0,0\right)\right\} \\
A_{1} & =\left\{ \left(0,1\right),\left(1,2\right)\right\} \\
A_{2} & =\left\{ \left(0,2\right),\left(1,2\right),\left(2,2\right)\right\} \\
A_{3} & =\left\{ \left(0,3\right),\left(1,3\right),\left(2,3\right),\left(3,3\right)\right\} .
\end{flalign*}

\end_inset


\end_layout

\begin_layout Subsection
Sufficiency principle
\end_layout

\begin_layout Definition
A statistic 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a 
\shape italic
sufficient statistic
\shape default
 for 
\begin_inset Formula $\theta$
\end_inset

 if the conditional distribution of the sample 
\begin_inset Formula $\mathbf{X}$
\end_inset

 given the value of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 does not depend on 
\begin_inset Formula $\theta$
\end_inset

, i.e., if 
\begin_inset Formula $P\left(\mathbf{X}|T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right)$
\end_inset

 does not depend on 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Standard
A sufficient statistic for a parameter 
\begin_inset Formula $\theta$
\end_inset

 contains all information that is in the data about 
\begin_inset Formula $\theta$
\end_inset

.
 I.e., given the value of 
\begin_inset Formula $T$
\end_inset

, the sufficient statistic, we can gain no more knowledge about 
\begin_inset Formula $\theta$
\end_inset

 from knowing more about the probability distribution of 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

.
 If 
\begin_inset Formula $\mathbf{X}$
\end_inset

 and 
\begin_inset Formula $\mathbf{X}$
\end_inset

 are two samples and 
\begin_inset Formula $T\left(\mathbf{X}\right)=T\left(\mathbf{Y}\right)$
\end_inset

, then inference about 
\begin_inset Formula $\theta$
\end_inset

 should be the same whether 
\begin_inset Formula $\mathbf{X=x}$
\end_inset

 is observed or 
\begin_inset Formula $\mathbf{Y=\mathbf{y}}$
\end_inset

 is observed.
 Note that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 must be a one-to-one function to be a sufficient statistic.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $p\left(\mathbf{x}|\theta\right)$
\end_inset

 is the joint pdf or pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 and 
\begin_inset Formula $q\left(T\left(\mathbf{x}\right)|\theta\right)$
\end_inset

 is the pdf or pmf of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

, then 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

 if, for every 
\begin_inset Formula $\mathbf{x}$
\end_inset

 in the sample space, the ratio 
\begin_inset Formula $p\left(\mathbf{x}|\theta\right)/q\left(T\left(\mathbf{x}|\theta\right)\right)$
\end_inset

 is constant as a function of 
\begin_inset Formula $\theta$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "thm:suff-stat-ratio"

\end_inset


\end_layout

\begin_layout Proof
By definition, if 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

, then 
\begin_inset Formula $P\left(\mathbf{X}|T\left(\mathbf{X}\right)\right)$
\end_inset

 does not depend on 
\begin_inset Formula $\theta$
\end_inset

 .
 
\begin_inset Formula 
\begin{flalign}
P\left(\mathbf{X}|T\left(\mathbf{X}\right)\right) & =P\left(\left\{ \mathbf{X}=\mathbf{x}\right\} |\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)\\
 & =\frac{P\left(\left(\left\{ X_{1}=x_{1}\right\} \cap\cdots\cap\left\{ X_{n}=x_{n}\right\} \right)\cap\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)}{P\left(\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)}\\
 & =\frac{P\left(\left\{ X_{1}=x_{1}\right\} \cap\cdots\cap\left\{ X_{n}=x_{n}\right\} \right)}{P\left(\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)}\\
 & =\frac{p\left(\mathbf{x}|\theta\right)}{q\left(T\left(\mathbf{x}|\theta\right)\right)}
\end{flalign}

\end_inset

(1) is simply an expansion of the notation.
 (2) follows from the definition of conditional probability.
 (3) follows because 
\begin_inset Formula $\left\{ \mathbf{X}=\mathbf{x}\right\} $
\end_inset

 is a subset of 
\begin_inset Formula $\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} $
\end_inset

, and if we have two sets 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 such that 
\begin_inset Formula $A\subset B$
\end_inset

, then 
\begin_inset Formula $A\cap B=A$
\end_inset

, so that 
\begin_inset Formula $P\left(A\cap B\right)=P\left(A\right)$
\end_inset

.
 (4) follows from setting 
\begin_inset Formula $p\left(\mathbf{x}|\theta\right)$
\end_inset

 equal to the numerator, which is the joint pdf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

, and setting 
\begin_inset Formula $q\left(T\left(\mathbf{X}|\theta\right)\right)$
\end_inset

 equal to the denominator, which is the pdf of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

.
 Then, if 
\begin_inset Formula $p\left(\mathbf{x}|\theta\right)/q\left(T\left(\mathbf{x}|\theta\right)\right)$
\end_inset

 is constant as a function of 
\begin_inset Formula $\theta$
\end_inset

, i.e., does not depend on 
\begin_inset Formula $\theta$
\end_inset

, then 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sampling from a binomial distribution]
\end_layout

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 be as in example 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:example-sampling-binom"

\end_inset

.
 If 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

, show it, and if not, explain why not.
 We have 
\begin_inset Formula $\mathbf{X}=X_{1},X_{2}$
\end_inset

, where the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are independent and identically distributed because 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is a random sample (by assumption).
 Then, each 
\begin_inset Formula $X_{i}$
\end_inset

 has the same pmf as 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
p_{X}\left(x\right) & =P\left(\left\{ X=x\right\} \right)\\
 & =\binom{3}{x}p^{x}\left(1-p\right)^{3-x}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left\{ 0,1,2,3\right\} $
\end_inset

 and 
\begin_inset Formula $p_{X}\left(x\right)=0$
\end_inset

 otherwise, so that the joint pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{\mathbf{X}}\left(\mathbf{x}\right) & =P\left(\left\{ \mathbf{X}=\mathbf{x}\right\} \right)\\
 & =P\left(\left\{ X_{1}=x_{1}\right\} \cap\left\{ X_{2}=x_{2}\right\} \right)\\
 & =P\left(\left\{ X_{1}=x_{1}\right\} \right)\cdot P\left(\left\{ X_{2}=x_{2}\right\} \right)\\
 & =\prod_{i=1}^{2}p_{X}\left(x_{i}\right)
\end{flalign*}

\end_inset

Each 
\begin_inset Formula $X_{i}$
\end_inset

 also has the same cdf as 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
F_{X}\left(t\right) & =P\left(\left\{ X\leq t\right\} \right)\\
 & =\sum_{k=0}^{t}p_{X}\left(k\right).
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $T\left(\mathbf{X}\right)=\max\left(X_{1},X_{2}\right)$
\end_inset

, which is just the order statistic 
\begin_inset Formula $X_{\left(2\right)}$
\end_inset

.
 For some maximum value 
\begin_inset Formula $T\left(\mathbf{x}\right)=t$
\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
P\left(\left\{ X_{\left(2\right)}\leq t\right\} \right) & =P\left(\left\{ X_{1}\leq t\right\} \cap\left\{ X_{2}\leq t\right\} \right)\\
 & =P\left(\left\{ X_{1}\leq t\right\} \right)\cdot P\left(\left\{ X_{2}\leq t\right\} \right)\\
 & =\prod_{i=1}^{2}P\left(\left\{ X_{i}\leq t\right\} \right)\\
 & =\prod_{i=1}^{2}F_{X}\left(t\right)\\
 & =\left[F_{X}\left(t\right)\right]^{2}
\end{flalign*}

\end_inset

so that the pmf of 
\begin_inset Formula $X_{\left(2\right)}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{X_{\left(2\right)}}\left(t\right) & =P\left(\left\{ X_{\left(2\right)}=t\right\} \right)\\
 & =P\left(\left\{ X_{\left(2\right)}\leq t\right\} \right)-P\left(\left\{ X_{\left(2\right)}\leq t-1\right\} \right)\\
 & =F_{X_{\left(2\right)}}\left(t\right)-F_{X_{\left(2\right)}}\left(t-1\right)\\
 & =\left[F_{X}\left(t\right)\right]^{2}-\left[F_{X}\left(t-1\right)\right]^{2}\\
 & =\left[\sum_{k=0}^{t}p_{X}\left(k\right)\right]^{2}-\left[\sum_{k=0}^{t-1}p_{X}\left(k\right)\right]^{2}\\
 & =\left[\sum_{k=0}^{t}p_{X}\left(k\right)\right]^{2}-\left[\sum_{k=0}^{t}p_{X}\left(k\right)-p_{X}\left(t\right)\right]^{2}\\
 & =\left[\sum_{k=0}^{t}p_{X}\left(k\right)\right]^{2}-\left[\left(\sum_{k=0}^{t}p_{X}\left(k\right)\right)^{2}-2p_{X}\left(t\right)\sum_{k=0}^{t}p_{X}\left(k\right)+\left[p_{X}\left(t\right)\right]^{2}\right]\\
 & =2p_{X}\left(t\right)\sum_{k=0}^{t}p_{X}\left(k\right)-\left[p_{X}\left(t\right)\right]^{2}\\
 & =p_{X}\left(t\right)\left[2\sum_{k=0}^{t}p_{X}\left(k\right)-p_{X}\left(t\right)\right].
\end{flalign*}

\end_inset

Then, we have 
\begin_inset Formula 
\begin{flalign*}
P\left(\mathbf{X}|T\left(\mathbf{X}\right)\right) & =\frac{P\left(\left\{ \mathbf{X}=\mathbf{x}\right\} \cap\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)}{P\left(\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)}\\
 & =\frac{P\left(\left\{ \mathbf{X}=\mathbf{x}\right\} \right)}{P\left(\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)}\\
 & =\frac{\prod_{i=1}^{2}p_{X}\left(x_{i}\right)}{p_{X}\left(t\right)\left[2\sum_{k=0}^{t}p_{X}\left(k\right)-p_{X}\left(t\right)\right]}\\
 & =\frac{\left[\binom{3}{x_{1}}p^{x_{1}}\left(1-p\right)^{3-x_{1}}\right]\left[\binom{3}{x_{2}}p^{x_{2}}\left(1-p\right)^{3-x_{2}}\right]}{\left[\binom{3}{t}p^{t}\left(1-p\right)^{3-t}\right]\left[2\sum_{k=0}^{t}\left(\binom{3}{k}p^{k}\left(1-p\right)^{3-k}\right)-\binom{3}{t}p^{t}\left(1-p\right)^{3-t}\right]}.
\end{flalign*}

\end_inset

Clearly, this expression depends on 
\begin_inset Formula $p$
\end_inset

, so 
\begin_inset Formula $T\left(\mathbf{X}\right)=\max\left(\mathbf{X}\right)$
\end_inset

 is not a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sampling from a uniform distribution]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim U\left(0,\theta\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pdf of 
\begin_inset Formula $X$
\end_inset

.
 Let 
\begin_inset Formula $T\left(\mathbf{X}\right)=\max\left(X_{1},\ldots,X_{n}\right)$
\end_inset

.
 Show that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "exa:suff-statistic-uniform"

\end_inset


\end_layout

\begin_layout Example
The pdf of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x\right) & =\frac{1}{\theta-0}\\
 & =\frac{1}{\theta}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left(0,\theta\right)$
\end_inset

 and 
\begin_inset Formula $f_{X}\left(x\right)=0$
\end_inset

 otherwise, so that the joint pdf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}\right) & =P\left(\left\{ X_{1}=x_{1}\right\} \cap\cdots\cap\left\{ X_{n}=x_{n}\right\} \right)\\
 & =P\left(\left\{ X_{1}=x_{1}\right\} \right)\cdot\ldots\cdot P\left(\left\{ X_{n}=x_{n}\right\} \right)\\
 & =\prod_{i=1}^{n}f_{X}\left(x_{i}\right)\\
 & =\left(\frac{1}{\theta}\right)^{n}\\
 & =\frac{1}{\theta^{n}}.
\end{flalign*}

\end_inset

The cdf of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
F_{X}\left(x\right) & =\int_{-\infty}^{x}f_{X}\left(t\right)\mbox{d}t\\
 & =\int_{-\infty}^{0}0\mbox{d}t+\int_{0}^{x}\frac{1}{\theta}\mbox{d}t\\
 & =0+\left(\frac{1}{\theta}\int_{0}^{x}1\mbox{d}t\right)\\
 & =\frac{1}{\theta}\left(t\Big\rvert_{0}^{x}\right)\\
 & =\frac{1}{\theta}\left(x-0\right)\\
 & =\frac{x}{\theta}.
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $T\left(\mathbf{X}\right)=\max\left(X_{1},\ldots,X_{n}\right)$
\end_inset

, which is just the order statistic 
\begin_inset Formula $X_{\left(n\right)}$
\end_inset

.
 By 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:order-stat-continuous"

\end_inset

, we have 
\begin_inset Formula 
\begin{flalign*}
f_{X_{\left(n\right)}}\left(x\right) & =\frac{n!}{\left(j-1\right)!\left(n-j\right)!}f_{X}\left(x\right)\left[F_{X}\left(x\right)\right]^{j-1}\left[1-F_{X}\left(x\right)\right]^{n-j}\\
 & =\frac{n!}{\left(n-1\right)!\left(n-n\right)!}f_{X}\left(x\right)\left[F_{X}\left(x\right)\right]^{n-1}\left[1-F_{X}\left(x\right)\right]^{n-n}\\
 & =\frac{n!}{\left(n-1\right)!}\left(\frac{1}{\theta}\right)\left[\frac{x}{\theta}\right]^{n-1}\left[1-\frac{x}{\theta}\right]^{0}\\
 & =n\left(\frac{1}{\theta}\right)\left(\frac{x}{\theta}\right)^{n-1}\\
 & =n\left(\frac{1}{\theta}\right)\frac{x^{n-1}}{\theta^{n-1}}\\
 & =nx^{n-1}\left(\frac{1}{\theta}\right)\left(\frac{1}{\theta^{n-1}}\right)\\
 & =nx^{n-1}\left(\frac{1}{\theta^{n}}\right).
\end{flalign*}

\end_inset

Let 
\begin_inset Formula $p\left(\mathbf{x}|\theta\right)$
\end_inset

 be the joint pdf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

, and let 
\begin_inset Formula $q\left(T\left(\mathbf{X}\right)|\theta\right)$
\end_inset

 be the pdf of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

.
 Then, by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:suff-stat-ratio"

\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
\frac{p\left(\mathbf{x}|\theta\right)}{q\left(T\left(\mathbf{X}\right)|\theta\right)} & =\frac{1/\theta^{n}}{nx^{n-1}\left(1/\theta^{n}\right)}\\
 & =\frac{1}{nx^{n-1}}.
\end{flalign*}

\end_inset

This expression does not depend on 
\begin_inset Formula $\theta$
\end_inset

, so it follows that 
\begin_inset Formula $p\left(\mathbf{x}|\theta\right)/q\left(T\left(\mathbf{X}\right)|\theta\right)$
\end_inset

 is constant as a function of 
\begin_inset Formula $\theta$
\end_inset

, so that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sampling from a Poisson distribution]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim P\left(\lambda\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},X_{2}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pmf of 
\begin_inset Formula $X$
\end_inset

.
 Let 
\begin_inset Formula $T\left(\mathbf{X}\right)=X_{1}+X_{2}$
\end_inset

.
 Show that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\lambda$
\end_inset

.
 The pmf of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{X}\left(x\right) & =\frac{e^{-\lambda}\lambda^{x}}{x!}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left\{ 0,1,2,\ldots\right\} $
\end_inset

 and 
\begin_inset Formula $p_{X}\left(x\right)=0$
\end_inset

 otherwise, so that the joint pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{\mathbf{X}}\left(\mathbf{x}\right) & =P\left(\left\{ X_{1}=x_{1}\right\} \cap\left\{ X_{2}\cap x_{x}\right\} \right)\\
 & =P\left(\left\{ X_{2}=x_{1}\right\} \right)\cdot P\left(\left\{ X_{2}=x_{2}\right\} \right)\\
 & =p_{X_{1}}\left(x_{1}\right)\cdot p_{X_{2}}\left(x_{2}\right)\\
 & =\left(\frac{e^{-\lambda}\lambda^{x_{1}}}{x_{1}!}\right)\left(\frac{e^{-\lambda}\lambda^{x_{2}}}{x_{2}!}\right)\\
 & =\frac{e^{-2\lambda}\lambda^{x_{1}+x_{2}}}{x_{1}!x_{2}!}.
\end{flalign*}

\end_inset

Let 
\begin_inset Formula $z=x_{1}+x_{2}$
\end_inset

.
 Then, the pmf of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign}
P\left(\left\{ X_{1}+X_{2}=z\right\} \right) & =\sum_{k=0}^{z}P\left(\left\{ X_{1}=k\right\} \cap\left\{ X_{2}=z-k\right\} \right)\\
 & =\sum_{k=0}^{z}P\left(\left\{ X_{1}=k\right\} \right)\cdot P\left(\left\{ X_{2}=z-k\right\} \right)\\
 & =\sum_{k=0}^{z}\left(\frac{e^{-\lambda}\lambda^{k}}{k!}\right)\left(\frac{e^{-\lambda}\lambda^{z-k}}{\left(z-k\right)!}\right)\\
 & =\sum_{k=0}^{z}\frac{e^{-2\lambda}\lambda^{z}}{k!\left(z-k\right)!}\\
 & =e^{-2\lambda}\lambda^{z}\sum_{k=0}^{z}\frac{1}{k!\left(z-k\right)!}\\
 & =\frac{e^{-2\lambda}\lambda^{z}}{z!}\sum_{k=0}^{z}\frac{z!}{k!\left(z-k\right)!}\\
 & =\frac{e^{-2\lambda}\lambda^{z}}{z!}\cdot2^{z}\\
 & =\frac{e^{-2\lambda}\left(2\lambda\right)^{z}}{z!}\\
 & =\frac{e^{-2\lambda}\left(2\lambda\right)^{x_{1}+x_{2}}}{\left(x_{1}+x_{2}\right)!}
\end{flalign}

\end_inset

so that 
\begin_inset Formula $T\left(\mathbf{X}\right)=X_{1}+X_{2}\sim P\left(2\lambda\right)$
\end_inset

.
 (1) follows from Proposition 6.18 in Weiss' text, which gives the pmf of
 the sum of two discrete random variables.
 (2) follows because 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 are independent.
 (3) follows because 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 each has the pmf of 
\begin_inset Formula $X$
\end_inset

.
 (4) and (5) follow from algebra.
 (6) follows by multiplying by 
\begin_inset Formula $1=z!/z!$
\end_inset

 and rearrangement.
 (7) follows from the binomial theorem, which gives 
\begin_inset Formula 
\begin{flalign*}
\left(x+y\right)^{n} & =\sum_{k=0}^{n}\binom{n}{k}x^{n-k}y^{k}
\end{flalign*}

\end_inset

so that 
\begin_inset Formula 
\begin{flalign*}
2^{z} & =\left(1+1\right)^{z}\\
 & =\sum_{k=0}^{z}\binom{z}{k}1^{z-k}1^{k}\\
 & =\sum_{k=0}^{z}\binom{z}{k}\\
 & =\sum_{k=0}^{z}\frac{z!}{k!\left(z-k\right)!}.
\end{flalign*}

\end_inset

(8) and (9) follow from algebra.
 Let 
\begin_inset Formula $p\left(\mathbf{x}|\lambda\right)$
\end_inset

 be the joint pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

, and let 
\begin_inset Formula $q\left(T\left(\mathbf{X}\right)|\lambda\right)$
\end_inset

 be the pmf of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

.
 Then, by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:suff-stat-ratio"

\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
\frac{p\left(\mathbf{x}|\lambda\right)}{q\left(T\left(\mathbf{X}\right)|\lambda\right)} & =\frac{\frac{e^{-2\lambda}\lambda^{x_{1}+x_{2}}}{x_{1}!x_{2}!}}{\frac{e^{-2\lambda}\left(2\lambda\right)^{x_{1}+x_{2}}}{\left(x_{1}+x_{2}\right)!}}\\
 & =\frac{\lambda^{x_{1}+x_{2}}\left(x_{1}+x_{2}\right)!}{\left(2\lambda\right)^{x_{1}+x_{2}}x_{1}!x_{2}!}\\
 & =\frac{\lambda^{x_{1}+x_{2}}\left(x_{1}+x_{2}\right)!}{2^{x_{1}+x_{2}}\lambda^{x_{1}+x_{2}}x_{1}!x_{2}!}\\
 & =\frac{\left(x_{1}+x_{2}\right)!}{x_{1}!x_{2}!}\left(\frac{1}{2}\right)^{x_{1}+x_{2}}.
\end{flalign*}

\end_inset

Clearly, this expression does not depend on 
\begin_inset Formula $\lambda$
\end_inset

, so it follows that 
\begin_inset Formula $p\left(\mathbf{x}|\lambda\right)/q\left(T\left(\mathbf{X}\right)|\lambda\right)$
\end_inset

 is constant as a function of 
\begin_inset Formula $\lambda$
\end_inset

, so that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sampling from a Bernoulli distribution]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim Bernoulli\left(p\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pmf of 
\begin_inset Formula $X$
\end_inset

.
 Let 
\begin_inset Formula $T\left(\mathbf{X}\right)=\frac{1}{n}\sum_{i=1}^{n}X_{i}$
\end_inset

 (this is the MLE 
\begin_inset Formula $\hat{p}$
\end_inset

).
 Show that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
 A Bernoulli random variable is a binomial random variable with 
\begin_inset Formula $n=1$
\end_inset

, so the pmf of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{X}\left(x\right) & =\binom{1}{x}p^{x}\left(1-p\right)^{1-x}\\
 & =p^{x}\left(1-p\right)^{1-x}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left\{ 0,1\right\} $
\end_inset

 and 
\begin_inset Formula $p_{X}\left(x\right)=0$
\end_inset

 otherwise.
 Then, the joint pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{\mathbf{X}}\left(\mathbf{x}\right) & =P\left(\left\{ X_{1}=x_{1}\right\} \cap\cdots\cap\left\{ X_{n}=x_{n}\right\} \right)\\
 & =P\left(\left\{ X_{1}=x_{1}\right\} \right)\cdot\ldots\cdot P\left(\left\{ X_{n}=x_{n}\right\} \right)\\
 & =\prod_{i=1}^{n}p_{X}\left(x_{i}\right)\\
 & =\prod_{i=1}^{n}p^{x_{i}}\left(1-p\right)^{1-x_{i}}\\
 & =p^{\sum_{i=1}^{n}x_{i}}\left(1-p\right)^{\sum_{i=1}^{n}\left(1-x_{i}\right)}\\
 & =p^{\sum_{i=1}^{n}x_{i}}\left(1-p\right)^{n-\sum_{i=1}^{n}x_{i}}.
\end{flalign*}

\end_inset

Proposition 6.20 from Weiss' text states that if 
\begin_inset Formula $Y_{1},\ldots,Y_{m}$
\end_inset

 are independent random variables with 
\begin_inset Formula $Y_{j}\sim B\left(n_{j},p\right)$
\end_inset

 for 
\begin_inset Formula $1\leq j\leq m$
\end_inset

, then 
\begin_inset Formula $Y_{1}+\cdots+Y_{m}\sim B\left(n_{1}+\cdots n_{m},p\right)$
\end_inset

.
 It follows that 
\begin_inset Formula 
\begin{flalign*}
\sum_{i=1}^{n}X_{i} & \sim B\left(\sum_{i=1}^{n}1,p\right)\\
 & =B\left(n,p\right).
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $T\left(\mathbf{X}\right)=\frac{1}{n}\sum_{i=1}^{n}X_{i}$
\end_inset

, so it follows that 
\begin_inset Formula $nT\left(\mathbf{X}\right)=\sum_{i=1}^{n}X_{i}$
\end_inset

, so that 
\begin_inset Formula $nT\left(\mathbf{X}\right)\sim B\left(n,p\right)$
\end_inset

.
 Then, the pmf of 
\begin_inset Formula $nT\left(\mathbf{X}\right)$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
P\left(\left\{ nT\left(\mathbf{X}\right)=\sum_{i=1}^{n}x_{i}\right\} \right) & =\binom{n}{\sum_{i=1}^{n}x_{i}}p^{\sum_{i=1}^{n}x_{i}}\left(1-p\right)^{n-\sum_{i=1}^{n}x_{i}}.
\end{flalign*}

\end_inset

Let 
\begin_inset Formula $p\left(\mathbf{x}|p\right)$
\end_inset

 be the joint pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

, and let 
\begin_inset Formula $q\left(nT\left(\mathbf{X}\right)|p\right)$
\end_inset

 be the pmf of 
\begin_inset Formula $nT\left(\mathbf{X}\right)$
\end_inset

.
 Then, by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:suff-stat-ratio"

\end_inset

, we have 
\begin_inset Formula 
\begin{flalign*}
\frac{p\left(\mathbf{x}|p\right)}{q\left(nT\left(\mathbf{X}\right)|p\right)} & =\frac{p^{\sum_{i=1}^{n}x_{i}}\left(1-p\right)^{n-\sum_{i=1}^{n}x_{i}}}{\binom{n}{\sum_{i=1}^{n}x_{i}}p^{\sum_{i=1}^{n}x_{i}}\left(1-p\right)^{n-\sum_{i=1}^{n}x_{i}}}\\
 & =\frac{1}{\binom{n}{\sum_{i=1}^{n}x_{i}}}.
\end{flalign*}

\end_inset

Clearly, this expression does not depend on 
\begin_inset Formula $p$
\end_inset

, so it follows that 
\begin_inset Formula $nT\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

, so that 
\begin_inset Formula $T\left(\mathbf{X}\right)=\hat{p}$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Subsection
Factorization theorem
\end_layout

\begin_layout Theorem
\begin_inset ERT
status open

\begin_layout Plain Layout

[Factorization Theorem]
\end_layout

\end_inset

Let 
\begin_inset Formula $f\left(\mathbf{x}|\theta\right)$
\end_inset

 be the joint pdf or pmf of a sample 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
 A statistic 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is sufficient for 
\begin_inset Formula $\theta$
\end_inset

 if and only if there exist functions 
\begin_inset Formula $g\left(t|\theta\right)$
\end_inset

 and 
\begin_inset Formula $h\left(\mathbf{x}\right)$
\end_inset

 such that 
\begin_inset Formula $f\left(\mathbf{x}|\theta\right)=g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{x}\right)$
\end_inset

 for all sample points 
\begin_inset Formula $\mathbf{x}$
\end_inset

 and all 
\begin_inset Formula $\theta$
\end_inset

.
 (This is Theorem 6.2.6 from Casella and Berger; the following proof is given
 there.)
\begin_inset CommandInset label
LatexCommand label
name "thm:factorization"

\end_inset


\end_layout

\begin_layout Proof
We will give the proof only for the discrete case.
\end_layout

\begin_layout Proof
Suppose 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic.
 Choose 
\begin_inset Formula $g\left(t|\theta\right)=P_{\theta}\left(\left\{ T\left(\mathbf{X}\right)=t\right\} \right)$
\end_inset

 and 
\begin_inset Formula $h\left(\mathbf{x}\right)=P\left(\left\{ \mathbf{X}=\mathbf{x}|T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)$
\end_inset

.
 Because 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is sufficient, the conditional probability defining 
\begin_inset Formula $h\left(\mathbf{x}\right)$
\end_inset

 does not depend on 
\begin_inset Formula $\theta$
\end_inset

.
 Thus, this choice of 
\begin_inset Formula $h\left(\mathbf{x}\right)$
\end_inset

 and 
\begin_inset Formula $g\left(t|\theta\right)$
\end_inset

 is legitimate, and for this choice we have
\begin_inset Formula 
\begin{flalign}
f\left(\mathbf{x}|\theta\right) & =P_{\theta}\left(\left\{ \mathbf{X}=\mathbf{x}\right\} \right)\\
 & =P_{\theta}\left(\left\{ \mathbf{X}=\mathbf{x}\right\} \cap\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)\\
 & =P_{\theta}\left(\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)\cdot P\left(\left\{ \mathbf{X}=\mathbf{x}\right\} |\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)\\
 & =g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{x}\right).
\end{flalign}

\end_inset

(1) follows from the definition of a pmf.
 (2) follows because 
\begin_inset Formula $\left\{ \mathbf{X}=\mathbf{x}\right\} $
\end_inset

 is a subset of 
\begin_inset Formula $\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} $
\end_inset

, and if we have two sets 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 such that 
\begin_inset Formula $A\subset B$
\end_inset

, then 
\begin_inset Formula $A\cap B=A$
\end_inset

, so that 
\begin_inset Formula $P\left(A\cap B\right)=P\left(A\right)$
\end_inset

.
 (3) follows from the definition of conditional probability.
 (4) follows from our definitions of 
\begin_inset Formula $g\left(t|\theta\right)$
\end_inset

 and 
\begin_inset Formula $h\left(\mathbf{x}\right)$
\end_inset

.
 So factorization has been exhibited.
 We also see from the last two lines above that 
\begin_inset Formula $P_{\theta}\left(\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)=g\left(T\left(\mathbf{x}\right)|\theta\right)$
\end_inset

, so 
\begin_inset Formula $g\left(T\left(\mathbf{x}\right)|\theta\right)$
\end_inset

 is the pmf of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

.
 
\end_layout

\begin_layout Proof
Now assume the factorization 
\begin_inset Formula $f\left(\mathbf{x}|\theta\right)=g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{x}\right)$
\end_inset

 exists.
 Let 
\begin_inset Formula $q\left(t|\theta\right)$
\end_inset

 be the pmf of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

.
 To now show that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is sufficient, we examine the ratio 
\begin_inset Formula $f\left(\mathbf{x}|\theta\right)/q\left(T\left(\mathbf{x}\right)|\theta\right)$
\end_inset

.
 Define 
\begin_inset Formula $A_{T\left(\mathbf{x}\right)}=\left\{ \mathbf{y}:T\left(\mathbf{y}\right)=T\left(\mathbf{x}\right)\right\} $
\end_inset

.
 Then
\begin_inset Formula 
\begin{flalign}
\frac{f\left(\mathbf{x}|\theta\right)}{q\left(T\left(\mathbf{x}\right)|\theta\right)} & =\frac{g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{x}\right)}{q\left(T\left(\mathbf{x}\right)|\theta\right)}\\
 & =\frac{g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{x}\right)}{\sum_{A_{T\left(\mathbf{x}\right)}}g\left(T\left(\mathbf{y}\right)|\theta\right)h\left(\mathbf{y}\right)}\\
 & =\frac{g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{x}\right)}{\sum_{A_{T\left(\mathbf{x}\right)}}g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{y}\right)}\\
 & =\frac{g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{x}\right)}{g\left(T\left(\mathbf{x}\right)|\theta\right)\sum_{A_{T\left(\mathbf{x}\right)}}h\left(\mathbf{y}\right)}\\
 & =\frac{h\left(\mathbf{x}\right)}{\sum_{A_{T\left(\mathbf{x}\right)}}h\left(\mathbf{y}\right)}.
\end{flalign}

\end_inset

(1) follows from our assumption that the factorization exists.
 (2) follows from the definition of the pmf of 
\begin_inset Formula $T$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
f_{T\left(\mathbf{X}\right)}\left(T\left(\mathbf{x}\right)\right) & =P\left(\left\{ T\left(\mathbf{X}\right)=T\left(\mathbf{x}\right)\right\} \right)\\
 & =\sum_{\mathbf{y}\in T^{-1}\left(\left\{ T\left(\mathbf{x}\right)\right\} \right)}P\left(\left\{ \mathbf{X}=\mathbf{y}\right\} \right)\\
 & =\sum_{\mathbf{y}\in T^{-1}\left(\left\{ T\left(\mathbf{x}\right)\right\} \right)}f_{\mathbf{X}}\left(\mathbf{y}\right)\\
 & =\sum_{\mathbf{y}\in\left\{ \mathbf{y}:T\left(\mathbf{y}\right)=T\left(\mathbf{x}\right)\right\} }f_{\mathbf{X}}\left(\mathbf{y}\right)\\
 & =\sum_{\mathbf{y}\in A_{T\left(\mathbf{x}\right)}}g\left(T\left(\mathbf{y}\right)|\theta\right)h\left(\mathbf{y}\right).
\end{flalign*}

\end_inset

(3) and (4) follow from the fact that 
\begin_inset Formula $T$
\end_inset

 is constant on 
\begin_inset Formula $A_{T\left(\mathbf{x}\right)}$
\end_inset

, i.e., 
\series bold

\begin_inset Formula $T\left(\mathbf{x}\right)=T\left(\mathbf{y}\right)$
\end_inset


\series default
.
 (5) follows from algebra.
 Because (5) does not depend on 
\begin_inset Formula $\theta$
\end_inset

, by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:suff-stat-ratio"

\end_inset

 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sufficient statistic for a Poisson random variable]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim Poisson\left(\lambda\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pmf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
p_{X}\left(x|\lambda\right) & =\frac{e^{-\lambda}\lambda^{x}}{x!}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left\{ 0,1,2,\ldots\right\} $
\end_inset

 and 
\begin_inset Formula $p_{X}\left(x\right)=0$
\end_inset

 otherwise, so that the joint pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{\mathbf{X}}\left(\mathbf{x}|\lambda\right) & =\prod_{i=1}^{n}p_{X_{i}}\left(x_{i}\right)\\
 & =\prod_{i=1}^{n}\left(\frac{e^{-\lambda}\lambda^{x_{i}}}{x_{i}!}\right)\\
 & =\left(\prod_{i=1}^{n}\frac{1}{x_{i}!}\right)\left(\prod_{i=1}^{n}e^{-\lambda}\lambda^{x_{i}}\right)\\
 & =\left(\prod_{i=1}^{n}\frac{1}{x_{i}!}\right)e^{-n\lambda}\lambda^{x_{1}+\cdots+x_{n}}\\
 & =\underbrace{\left(\prod_{i=1}^{n}\frac{1}{x_{i}!}\right)}_{h\left(\mathbf{x}\right)}\underbrace{e^{-n\lambda}\lambda^{\sum_{i=1}^{n}x_{i}}}_{g\left(T\left(\mathbf{x}\right)|\lambda\right)}.
\end{flalign*}

\end_inset

It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:factorization"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{x}\right)=\sum_{i=1}^{n}x_{i}$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\lambda$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "exa:suff-stat-poisson"

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sufficient statistic for a Bernoulli random variable]
\end_layout

\end_inset

Consider a sequence of independent Bernoulli random variables 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 where 
\begin_inset Formula $P\left(\left\{ X_{i}=x\right\} \right)=\theta^{x}\left(1-\theta\right)^{1-x}$
\end_inset

 where 
\begin_inset Formula $x\in\left\{ 0,1\right\} $
\end_inset

.
 Then, the joint pmf of the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{\left(X_{1},\ldots,X_{n}|\theta\right)}\left(\mathbf{x}|\theta\right) & =\prod_{i=1}^{n}\left(\theta^{x_{i}}\left(1-\theta\right)^{1-x_{i}}\right)\\
 & =\theta^{\sum_{i=1}^{n}x_{i}}\prod_{i=1}^{n}\left[\left(1-\theta\right)^{1}\left(1-\theta\right)^{-x_{i}}\right]\\
 & =\theta^{\sum_{i=1}^{n}x_{i}}\left(1-\theta\right)^{n}\left(1-\theta\right)^{-\sum_{i=1}^{n}x_{i}}\\
 & =\theta^{\sum_{i=1}^{n}x_{i}}\left(1-\theta\right)^{n}\left(\frac{1}{1-\theta}\right)^{\sum_{i=1}^{n}x_{i}}\\
 & =\underbrace{\left(1-\theta\right)^{n}\left(\frac{\theta}{1-\theta}\right)^{\sum_{i=1}^{n}x_{i}}}_{g\left(T\left(\mathbf{x}\right)|\theta\right)}.
\end{flalign*}

\end_inset

We set 
\begin_inset Formula $h\left(\mathbf{x}\right)=1$
\end_inset

.
 Then, it follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:factorization"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{x}\right)=\sum_{i=1}^{n}x_{i}$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "exa:suff-stat-bernoulli"

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sufficient statistic for a normal random variable]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim N\left(\mu,\sigma^{2}\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pdf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x|\mu,\sigma^{2}\right) & =\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\left(x-\mu\right)^{2}/\left(2\sigma^{2}\right)}
\end{flalign*}

\end_inset

for 
\begin_inset Formula $x\in\mathbb{R}$
\end_inset

, where 
\begin_inset Formula $\mu\in\mathbb{R}$
\end_inset

 and 
\begin_inset Formula $\sigma>0$
\end_inset

.
 Find a sufficient statistic for 
\begin_inset Formula $\theta=\left(\mu,\sigma^{2}\right)$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "exa:suff-stat-normal"

\end_inset


\end_layout

\begin_layout Example
A joint pdf for 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\mu,\sigma^{2}\right) & =\prod_{i=1}^{n}\left[\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left\{ -\frac{1}{2}\left(\frac{\left(x_{i}-\mu\right)^{2}}{\sigma^{2}}\right)\right\} \right]\\
 & =\prod_{i=1}^{n}\left[\left(2\pi\sigma^{2}\right)^{-1/2}\exp\left\{ -\frac{1}{2}\left(\frac{\left(x_{i}-\mu\right)^{2}}{\sigma^{2}}\right)\right\} \right]\\
 & =\left(2\pi\sigma^{2}\right)^{-n/2}\exp\left\{ \sum_{i=1}^{n}-\frac{1}{2}\left(\frac{\left(x_{i}-\mu\right)^{2}}{\sigma^{2}}\right)\right\} \\
 & =\left(2\pi\sigma^{2}\right)^{-n/2}\exp\left\{ -\frac{1}{2}\sum_{i=1}^{n}\left(\frac{x_{i}^{2}}{\sigma^{2}}-\frac{2\mu x_{i}}{\sigma^{2}}+\frac{\mu^{2}}{\sigma^{2}}\right)\right\} \\
 & =\left(2\pi\sigma^{2}\right)^{-n/2}\exp\left\{ -\frac{1}{2}\left(\frac{\sum_{i=1}^{n}x_{i}^{2}}{\sigma^{2}}-\frac{2\mu\sum_{i=1}^{n}x_{i}}{\sigma^{2}}+\frac{n\mu^{2}}{\sigma^{2}}\right)\right\} \\
 & =\underbrace{\left(2\pi\sigma^{2}\right)^{-n/2}\exp\left\{ -\frac{n\mu^{2}}{2\sigma^{2}}\right\} \exp\left\{ -\frac{\sum_{i=1}^{n}x_{i}^{2}}{2\sigma^{2}}+\frac{\mu\sum_{i=1}^{n}x_{i}}{\sigma^{2}}\right\} }_{g\left(T\left(\mathbf{x}\right)|\theta\right)}.
\end{flalign*}

\end_inset

We set 
\begin_inset Formula $h\left(\mathbf{x}\right)=1$
\end_inset

.
 Then, it follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:factorization"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)=\left(\sum_{i=1}^{n}X_{i}^{2},\sum_{i=1}^{n}X_{i}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta=\left(\mu,\sigma^{2}\right)$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Sufficient statistic for a uniform distribution]
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim U\left(0,\theta\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pdf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x|\theta\right) & =\frac{1}{\theta}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left(0,\theta\right)$
\end_inset

 and 
\begin_inset Formula $f\left(x|\theta\right)=0$
\end_inset

 otherwise, so that a joint pdf for 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\theta\right) & =\prod_{i=1}^{n}\left(\frac{1}{\theta}I_{\left\{ 0<x_{i}<\theta\right\} }\right)\\
 & =\left(\frac{1}{\theta}\right)^{n}I_{\left\{ x_{\left(1\right)}>0\right\} }I_{\left\{ x_{\left(n\right)}<\theta\right\} }.
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $h\left(\mathbf{x}\right)=I_{\left\{ x_{\left(1\right)}>0\right\} }$
\end_inset

 and 
\begin_inset Formula $g\left(T\left(\mathbf{x}\right)|\theta\right)=\theta^{-n}I_{\left\{ x_{\left(n\right)}<\theta\right\} }$
\end_inset

.
 It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:factorization"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{x}\right)=x_{\left(n\right)}=\underset{1\leq i\leq n}{\max}x_{i}$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 be iid observations from a pdf or pmf 
\begin_inset Formula $f\left(x|\boldsymbol{\theta}\right)$
\end_inset

 that belongs to an exponential family given by
\begin_inset Formula 
\begin{flalign*}
f\left(x|\boldsymbol{\theta}\right) & =h\left(x\right)c\left(\boldsymbol{\theta}\right)\exp\left(\sum_{i=1}^{k}\omega_{i}\left(\boldsymbol{\theta}\right)t_{i}\left(x\right)\right)
\end{flalign*}

\end_inset

where 
\begin_inset Formula $\boldsymbol{\theta}=\left(\theta_{1},\ldots,\theta_{d}\right)$
\end_inset

, 
\begin_inset Formula $d\leq k$
\end_inset

.
 Then
\begin_inset Formula 
\begin{flalign*}
T\left(\mathbf{X}\right) & =\left(\sum_{j=1}^{n}t_{1}\left(X_{j}\right),\ldots,\sum_{j=1}^{n}t_{k}\left(X_{j}\right)\right)
\end{flalign*}

\end_inset

is a sufficient statistic for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is called the 
\series bold
natural sufficient statistic.

\series default
 (This is Theorem 6.2.10 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:suff-statistic-exp-family"

\end_inset


\end_layout

\begin_layout Proof
The joint pdf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\theta\right) & =\prod_{j=1}^{n}\left[h\left(x_{j}\right)c\left(\theta\right)\exp\left(\sum_{i=1}^{k}\omega_{i}\left(\theta\right)t_{i}\left(x_{j}\right)\right)\right]\\
 & =\underbrace{c\left(\theta\right)^{n}\exp\left\{ \sum_{i=1}^{k}\left(\omega_{i}\left(\theta\right)\sum_{j=1}^{n}t_{i}\left(x_{j}\right)\right)\right\} }_{g\left(T\left(\mathbf{x}\right)|\theta\right)}\underbrace{\prod_{j=1}^{n}h\left(x_{j}\right)}_{h\left(\mathbf{x}\right)}.
\end{flalign*}

\end_inset

It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:factorization"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)=\left(\sum_{j=1}^{n}t_{1}\left(X_{j}\right),\ldots,\sum_{j=1}^{n}t_{k}\left(X_{j}\right)\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Subsection
Minimal sufficient statistics
\end_layout

\begin_layout Standard
In the preceding section, we found one sufficient statistic for each model
 considered.
 In fact, there are many sufficient statistics.
 It is always true that the data 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is a sufficient statistic; we can factor the pdf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 as 
\begin_inset Formula $f\left(\mathbf{x}|\theta\right)=f\left(T\left(\mathbf{X}\right)|\theta\right)h\left(\mathbf{x}\right)$
\end_inset

, where 
\begin_inset Formula $T\left(\mathbf{x}\right)=\mathbf{x}$
\end_inset

 and 
\begin_inset Formula $h\left(\mathbf{x}\right)=1$
\end_inset

 for all 
\begin_inset Formula $\mathbf{x}$
\end_inset

.
 Any one-to-one function of a sufficient statistic is sufficient.
 We might ask whether one sufficient statistic is any better than another.
\end_layout

\begin_layout Definition
A sufficient statistic 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is called a 
\shape italic
minimal sufficient statistic
\shape default
 if, for any other sufficient statistic 
\begin_inset Formula $T'\left(\mathbf{X}\right)$
\end_inset

, 
\begin_inset Formula $T\left(\mathbf{x}\right)$
\end_inset

 is a function of 
\begin_inset Formula $T'\left(\mathbf{x}\right)$
\end_inset

, i.e., 
\begin_inset Formula $T\left(\mathbf{x}\right)=g\left(T'\left(\mathbf{x}\right)\right)$
\end_inset

.
\end_layout

\begin_layout Standard
Of all sufficient statistics, a minimal sufficient statistic provides the
 greatest reduction of the data.
 In terms of the partition sets described above, if 
\begin_inset Formula $\left\{ B_{t'}:t'\in\mathcal{T}'\right\} $
\end_inset

 are the partition sets of 
\begin_inset Formula $T'\left(\mathbf{x}\right)$
\end_inset

 and 
\begin_inset Formula $\left\{ A_{t}:t\in\mathcal{T}\right\} $
\end_inset

 are the partition sets for 
\begin_inset Formula $T\left(\mathbf{x}\right)$
\end_inset

, then every 
\begin_inset Formula $B_{t'}$
\end_inset

 is a subset of 
\begin_inset Formula $A_{t}$
\end_inset

.
 The partition associated with the minimal sufficient statistic is the coarest
 possible partition (among those induced by sufficient statistics).
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $f\left(\mathbf{x}|\theta\right)$
\end_inset

 be the pmf or pdf of a sample 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
 Suppose there exists a function 
\begin_inset Formula $T\left(\mathbf{x}\right)$
\end_inset

 such that, for every two sample points 
\begin_inset Formula $\mathbf{x}$
\end_inset

 and 
\begin_inset Formula $\mathbf{y}$
\end_inset

, the ratio 
\begin_inset Formula $f\left(\mathbf{x}|\theta\right)/f\left(\mathbf{y}|\theta\right)$
\end_inset

 is constant as a function of 
\begin_inset Formula $\theta$
\end_inset

 if and only if 
\begin_inset Formula $T\left(\mathbf{x}\right)=T\left(\mathbf{y}\right)$
\end_inset

.
 Then 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a minimal sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
 (This is Theorem 6.2.13 from Casella & Berger; the following proof is given
 there.)
\begin_inset CommandInset label
LatexCommand label
name "thm:minimal-sufficient"

\end_inset


\end_layout

\begin_layout Proof
To simplify the proof, we assume 
\begin_inset Formula $f\left(x|\theta\right)>0$
\end_inset

 for all 
\begin_inset Formula $x\in\mathcal{X}$
\end_inset

 and 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Proof
First, we show that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic.
 Let 
\begin_inset Formula $\mathcal{T}=\left\{ t:t=T\left(\mathbf{x}\right),\mathbf{x}\in\mathcal{X}\right\} $
\end_inset

 be the image of 
\begin_inset Formula $\mathcal{X}$
\end_inset

 under 
\begin_inset Formula $T\left(\mathbf{x}\right)$
\end_inset

.
 Define the partition sets induced by 
\begin_inset Formula $T\left(\mathbf{x}\right)$
\end_inset

 as 
\begin_inset Formula $A_{t}=\left\{ \mathbf{x}:T\left(\mathbf{x}\right)=t\right\} $
\end_inset

.
 For each 
\begin_inset Formula $A_{t}$
\end_inset

, choose and fix one element 
\begin_inset Formula $\mathbf{x}_{t}\in A_{t}$
\end_inset

.
 For any 
\begin_inset Formula $\mathbf{x}\in\mathcal{X}$
\end_inset

, 
\begin_inset Formula $\mathbf{x}_{T\left(\mathbf{x}\right)}$
\end_inset

 is the fixed element that is in the same set, 
\begin_inset Formula $A_{t}$
\end_inset

, as 
\begin_inset Formula $\mathbf{x}$
\end_inset

.
 Since 
\begin_inset Formula $\mathbf{x}$
\end_inset

 and 
\begin_inset Formula $\mathbf{x}_{T\left(\mathbf{x}\right)}$
\end_inset

 are in the same set 
\begin_inset Formula $A_{t}$
\end_inset

, 
\begin_inset Formula $T\left(\mathbf{x}\right)=T\left(\mathbf{x}_{T\left(\mathbf{x}\right)}\right)$
\end_inset

 and, hence, 
\begin_inset Formula $f\left(x|\theta\right)/f\left(\mathbf{x}_{T\left(\mathbf{x}\right)}|\theta\right)$
\end_inset

 is constant as a function of 
\begin_inset Formula $\theta$
\end_inset

.
 Thus, we can define a function on 
\begin_inset Formula $\mathcal{X}$
\end_inset

 by 
\begin_inset Formula $h\left(\mathbf{x}\right)=f\left(\mathbf{x}|\theta\right)/f\left(\mathbf{x}_{T\left(\mathbf{x}\right)}|\theta\right)$
\end_inset

 and 
\begin_inset Formula $h$
\end_inset

 does not depend on 
\begin_inset Formula $\theta$
\end_inset

.
 Define a function on 
\begin_inset Formula $\mathcal{T}$
\end_inset

 by 
\begin_inset Formula $g\left(t|\theta\right)=f\left(\mathbf{x}_{t}|\theta\right)$
\end_inset

.
 Then it can be seen that
\begin_inset Formula 
\begin{flalign*}
f\left(\mathbf{x}|\theta\right) & =\frac{f\left(\mathbf{x}_{T\left(\mathbf{x}\right)}|\theta\right)f\left(\mathbf{x}|\theta\right)}{f\left(\mathbf{x}_{T\left(\mathbf{x}\right)}|\theta\right)}\\
 & =g\left(T\left(\mathbf{x}\right)|\theta\right)h\left(\mathbf{x}\right)
\end{flalign*}

\end_inset

and, by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:factorization"

\end_inset

, 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Proof
Now to show that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is minimal, let 
\begin_inset Formula $T'\left(\mathbf{X}\right)$
\end_inset

 be any other sufficient statistic.
 By 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:factorization"

\end_inset

, there exist functions 
\begin_inset Formula $g'$
\end_inset

 and 
\begin_inset Formula $h'$
\end_inset

 such that 
\begin_inset Formula $f\left(\mathbf{x}|\theta\right)=g'\left(T'\left(\mathbf{x}\right)|\theta\right)h'\left(\mathbf{x}\right)$
\end_inset

.
 Let 
\begin_inset Formula $\mathbf{x}$
\end_inset

 and 
\begin_inset Formula $\mathbf{y}$
\end_inset

 be any two sample points with 
\begin_inset Formula $T'\left(\mathbf{x}\right)=T'\left(\mathbf{y}\right)$
\end_inset

.
 Then
\begin_inset Formula 
\begin{flalign*}
\frac{f\left(\mathbf{x}|\theta\right)}{f\left(\mathbf{y}|\theta\right)} & =\frac{g'\left(T'\left(\mathbf{x}\right)|\theta\right)h'\left(\mathbf{x}\right)}{g'\left(T'\left(\mathbf{y}\right)|\theta\right)h'\left(\mathbf{y}\right)}\\
 & =\frac{h'\left(\mathbf{x}\right)}{h'\left(\mathbf{y}\right)}.
\end{flalign*}

\end_inset

Since this ratio does not depend on 
\begin_inset Formula $\theta$
\end_inset

, the assumptions of the theorem imply that 
\begin_inset Formula $T\left(\mathbf{x}\right)=T\left(\mathbf{y}\right)$
\end_inset

.
 Thus, 
\begin_inset Formula $T\left(\mathbf{x}\right)$
\end_inset

 is a function of 
\begin_inset Formula $T'\left(\mathbf{x}\right)$
\end_inset

 and 
\begin_inset Formula $T\left(\mathbf{x}\right)$
\end_inset

 is minimal.
\end_layout

\begin_layout Corollary
If the partition of the sample space induced by 
\begin_inset Formula $f\left(x|\theta\right)/f\left(y|\theta\right)$
\end_inset

 is equivalent to that induced by 
\begin_inset Formula $T$
\end_inset

, then 
\begin_inset Formula $T$
\end_inset

 is minimal sufficient.
\begin_inset CommandInset label
LatexCommand label
name "cor:minimal-sufficient-partition"

\end_inset


\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Minimal sufficient statistic for a Bernoulli random variable]
\end_layout

\end_inset

Let 
\begin_inset Formula $X_{1},X_{2}\sim Bernoulli\left(p\right)$
\end_inset

.
 Let 
\begin_inset Formula $V=X_{1}$
\end_inset

, 
\begin_inset Formula $T=\sum_{i}X_{i}$
\end_inset

, and 
\begin_inset Formula $U=\left(T,X_{1}\right)$
\end_inset

.
 Determine whether 
\begin_inset Formula $V$
\end_inset

, 
\begin_inset Formula $T$
\end_inset

, or 
\begin_inset Formula $U$
\end_inset

 is a minimal sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
 
\end_layout

\begin_layout Example
The set of outcomes and the statistics are shown below.
\end_layout

\begin_layout Example
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $X_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $X_{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $V$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $T$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $U$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(0,0\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(1,0\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(1,1\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(2,1\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $\mathcal{V}=\left\{ v:v=x_{1},\mathbf{x}\in\mathcal{X}\right\} $
\end_inset

 be the image of 
\begin_inset Formula $\mathcal{X}$
\end_inset

, the sample space of 
\begin_inset Formula $\mathbf{X}$
\end_inset

, under 
\begin_inset Formula $V$
\end_inset

.
 From the table above, we have 
\begin_inset Formula $\mathcal{V}=\left\{ 0,1\right\} $
\end_inset

.
 Let 
\begin_inset Formula $W_{t}=\left\{ \mathbf{x}:X_{1}=v\right\} $
\end_inset

 be the partition sets induced by 
\begin_inset Formula $V$
\end_inset

, so that we have
\begin_inset Formula 
\begin{flalign*}
W_{0} & =\left\{ \left(0,0\right),\left(0,1\right)\right\} \\
W_{1} & =\left\{ \left(1,0\right),\left(1,1\right)\right\} .
\end{flalign*}

\end_inset

The joint pmf of 
\begin_inset Formula $\mathbf{X}=X_{1},X_{2}$
\end_inset

 conditioned on 
\begin_inset Formula $V$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{\left(\mathbf{X}|V\right)}\left(\mathbf{x}|v\right) & =P\left(\left\{ \mathbf{X}=\mathbf{x}\right\} |\left\{ V=v\right\} \right)\\
 & =\frac{p_{\mathbf{X}}\left(\mathbf{x}|p\right)}{p_{V}\left(v|p\right)}\\
 & =\frac{\left(p^{x_{1}}\left(1-p\right)^{1-x_{1}}\right)\left(p^{x_{2}}\left(1-p\right)^{1-x_{2}}\right)}{p^{x_{1}}\left(1-p\right)^{1-x_{1}}}\\
 & =p^{x_{2}}\left(1-p\right)^{1-x_{2}}.
\end{flalign*}

\end_inset

Clearly, this expression depends on 
\begin_inset Formula $p$
\end_inset

, so 
\begin_inset Formula $V$
\end_inset

 is not a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $\mathcal{T}=\left\{ t:t=\sum_{i}x_{i},\mathbf{x}\in\mathcal{X}\right\} $
\end_inset

 be the image of 
\begin_inset Formula $\mathcal{X}$
\end_inset

 under 
\begin_inset Formula $T$
\end_inset

.
 From the table above, we have 
\begin_inset Formula $\mathcal{T}=\left\{ 0,1,2\right\} $
\end_inset

.
 Let 
\begin_inset Formula $A_{t}=\left\{ \mathbf{x}:\sum_{i}x_{i}=t\right\} $
\end_inset

 be the partition sets induced by 
\begin_inset Formula $T$
\end_inset

, so that we have
\begin_inset Formula 
\begin{flalign*}
A_{0} & =\left\{ \left(0,0\right)\right\} \\
A_{1} & =\left\{ \left(0,1\right),\left(1,0\right)\right\} \\
A_{2} & =\left\{ \left(1,1\right)\right\} .
\end{flalign*}

\end_inset

We showed in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:suff-stat-bernoulli"

\end_inset

 that 
\begin_inset Formula $T$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
 We will now show that 
\begin_inset Formula $T$
\end_inset

 is minimal.
 From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:suff-stat-bernoulli"

\end_inset

, the pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 can be written as 
\begin_inset Formula $p_{\mathbf{X}}\left(\mathbf{x}|p\right)=g\left(T\left(\mathbf{x}\right)|p\right)h\left(\mathbf{x}\right)$
\end_inset

, where 
\begin_inset Formula $h\left(\mathbf{x}\right)=1$
\end_inset

 and 
\begin_inset Formula 
\begin{flalign*}
g\left(T\left(\mathbf{x}\right)|p\right) & =\left(1-p\right)^{n}\left(\frac{p}{1-p}\right)^{\sum_{i=1}^{n}x_{i}}\\
 & =\left(1-p\right)^{2}\left(\frac{p}{1-p}\right)^{x_{1}+x_{2}}.
\end{flalign*}

\end_inset

Then, we have
\begin_inset Formula 
\begin{flalign*}
\frac{p_{\mathbf{X}}\left(\mathbf{x}|p\right)}{p_{\mathbf{X}}\left(\mathbf{y}|p\right)} & =\frac{g\left(T\left(\mathbf{x}\right)|p\right)h\left(\mathbf{x}\right)}{g\left(T\left(\mathbf{y}\right)|p\right)h\left(\mathbf{y}\right)}\\
 & =\frac{\left[\left(1-p\right)^{2}\left(\frac{p}{1-p}\right)^{x_{1}+x_{2}}\right]\cdot1}{\left[\left(1-p\right)^{2}\left(\frac{p}{1-p}\right)^{y_{1}+y_{2}}\right]\cdot1}\\
 & =\frac{\left(\frac{p}{1-p}\right)^{x_{1}+x_{2}}}{\left(\frac{p}{1-p}\right)^{y_{1}+y_{2}}}.
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $p\in\left(0,1\right)$
\end_inset

, so that 
\begin_inset Formula $p/\left(1-p\right)>0$
\end_inset

, so that the ratio shown above will be defined.
 This ratio will be constant as a function of 
\begin_inset Formula $p$
\end_inset

 if and only if 
\begin_inset Formula $x_{1}+x_{2}=y_{1}+y_{2}$
\end_inset

, i.e., if 
\begin_inset Formula $T\left(\mathbf{x}\right)=T\left(\mathbf{y}\right)$
\end_inset

.
 It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:minimal-sufficient"

\end_inset

 that 
\begin_inset Formula $T$
\end_inset

 is a minimal sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $\mathcal{U}=\left\{ \mathbf{u}:\mathbf{u}=\left(T\left(\mathbf{x}\right),x_{1}\right),\mathbf{x}\in\mathcal{X}\right\} $
\end_inset

 be the image of 
\begin_inset Formula $\mathcal{X}$
\end_inset

 under 
\begin_inset Formula $\mathbf{U}$
\end_inset

.
 From the table above, we have 
\begin_inset Formula $\mathcal{U}=\left\{ \left(0,0\right),\left(1,0\right),\left(1,1\right),\left(2,1\right)\right\} $
\end_inset

.
 Let 
\begin_inset Formula $B_{t}=\left\{ \mathbf{x}:\left(T\left(\mathbf{x}\right),x_{1}\right)=\mathbf{u}\right\} $
\end_inset

 be the partition sets induced by 
\begin_inset Formula $\mathbf{U}$
\end_inset

, so that we have
\begin_inset Formula 
\begin{flalign*}
B_{\left(0,0\right)} & =\left\{ \left(0,0\right)\right\} \\
B_{\left(1,0\right)} & =\left\{ \left(1,0\right)\right\} \\
B_{\left(1,1\right)} & =\left\{ \left(0,1\right)\right\} \\
B_{\left(2,1\right)} & =\left\{ \left(1,1\right)\right\} .
\end{flalign*}

\end_inset

The pmf of 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{\mathbf{U}}\left(\mathbf{u}|p\right) & =P\left(\left\{ T\left(\mathbf{X}\right)=t\right\} \cap\left\{ X_{1}=x_{1}\right\} \right)\\
 & =P\left(\left\{ T\left(\mathbf{X}\right)=t\right\} |\left\{ X_{1}=x_{1}\right\} \right)\cdot P\left(\left\{ X_{1}=x_{1}\right\} \right)\\
 & =\left(\frac{p_{T\left(\mathbf{x}\right)}\left(t|p\right)}{p_{X_{1}}\left(x_{1}|p\right)}\right)\cdot p_{X_{1}}\left(x_{1}|p\right)\\
 & =p_{T\left(\mathbf{x}\right)}\left(t|p\right).
\end{flalign*}

\end_inset

To show that 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

, we examine the ratio
\begin_inset Formula 
\begin{flalign*}
\frac{p\left(\mathbf{x}|\theta\right)}{q\left(T\left(\mathbf{x}|\theta\right)\right)} & =\frac{p_{\mathbf{X}}\left(\mathbf{x}|p\right)}{p_{\mathbf{U}}\left(\mathbf{u}|p\right)}\\
 & =\frac{\left(p^{x_{1}}\left(1-p\right)^{1-x_{1}}\right)\left(p^{x_{2}}\left(1-p\right)^{1-x_{2}}\right)}{\left(1-p\right)^{2}\left(\frac{p}{1-p}\right)^{x_{1}+x_{2}}}\\
 & =\frac{p^{x_{1}+x_{2}}\left(1-p\right)^{2-x_{1}-x_{2}}}{\left(1-p\right)^{2}p^{x_{1}+x_{2}}\left(1-p\right)^{-x_{1}-x_{2}}}\\
 & =\frac{p^{x_{1}+x_{x}}\left(1-p\right)^{2-x_{1}-x_{2}}}{p^{x_{1}+x_{2}}\left(1-p\right)^{2-x_{1}-x_{x}}}\\
 & =1.
\end{flalign*}

\end_inset

Because the ratio 
\begin_inset Formula $p_{\mathbf{X}}\left(\mathbf{x}|p\right)/p_{\mathbf{U}}\left(\mathbf{u}|p\right)$
\end_inset

 is constant as a function of 
\begin_inset Formula $p$
\end_inset

, it follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:suff-stat-ratio"

\end_inset

 that 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
 We will now check whether 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is minimal.
 We showed above that 
\begin_inset Formula 
\begin{flalign*}
\frac{p_{\mathbf{X}}\left(\mathbf{x}|p\right)}{p_{\mathbf{X}}\left(\mathbf{y}|p\right)} & =\frac{\left(\frac{p}{1-p}\right)^{x_{1}+x_{2}}}{\left(\frac{p}{1-p}\right)^{y_{1}+y_{2}}}.
\end{flalign*}

\end_inset

By 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:minimal-sufficient"

\end_inset

, if this ratio is constant if and only if 
\begin_inset Formula $\mathbf{U}\left(\mathbf{x}\right)=\mathbf{U}\left(\mathbf{y}\right)$
\end_inset

, then 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is minimal.
 We have 
\begin_inset Formula 
\begin{flalign*}
\mathbf{U}\left(\mathbf{x}\right) & =\left(T\left(\mathbf{x}\right),x_{1}\right)\\
 & =\left(x_{1}+x_{2},x_{1}\right)
\end{flalign*}

\end_inset

and
\begin_inset Formula 
\begin{flalign*}
\mathbf{U}\left(\mathbf{y}\right) & =\left(T\left(\mathbf{y}\right),y_{1}\right)\\
 & =\left(y_{1}+y_{2},y_{1}\right).
\end{flalign*}

\end_inset

As shown above, the ratio 
\begin_inset Formula $p_{\mathbf{X}}\left(\mathbf{x}|p\right)/p_{\mathbf{X}}\left(\mathbf{y}|p\right)$
\end_inset

 will be constant if and only if 
\begin_inset Formula $x_{1}+y_{1}=x_{2}+y_{2}$
\end_inset

, which does not imply 
\begin_inset Formula $x_{1}=y_{1}$
\end_inset

.
 Thus, it is not the case that the ratio will be constant if and only if
 
\begin_inset Formula $\mathbf{U}\left(\mathbf{x}\right)=\mathbf{U}\left(\mathbf{y}\right)$
\end_inset

, so it follows that 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is not a minimal sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
 Another way to see that 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is not minimal is to observe that 
\begin_inset Formula 
\begin{flalign*}
B_{\left(0,0\right)} & =\left\{ \left(0,0\right)\right\} =A_{0}\\
B_{\left(1,0\right)} & =\left\{ \left(1,0\right)\right\} \subset A_{1}\\
B_{\left(1,1\right)} & =\left\{ \left(0,1\right)\right\} \subset A_{1}\\
B_{\left(2,1\right)} & =\left\{ \left(1,1\right)\right\} =A_{2}.
\end{flalign*}

\end_inset

Thus, 
\begin_inset Formula $B_{t}\subseteq A_{t}$
\end_inset

, i.e., the partition of 
\begin_inset Formula $\mathcal{X}$
\end_inset

 induced by 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is not equivalent to that induced by 
\begin_inset Formula $T$
\end_inset

, which is minimal sufficient, so by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "cor:minimal-sufficient-partition"

\end_inset

, 
\begin_inset Formula $\mathbf{U}$
\end_inset

 is not a minimal sufficient statistic for 
\begin_inset Formula $p$
\end_inset

.
 Conversely, note that the statistic 
\begin_inset Formula $W=17T$
\end_inset

 generates the same partition as 
\begin_inset Formula $T$
\end_inset

, so 
\begin_inset Formula $W$
\end_inset

 is also minimal sufficient.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

Minimal sufficient statistic for an exponential random variable
\end_layout

\end_inset

Let 
\begin_inset Formula $X\sim\mbox{Exp}\left(\lambda\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pdf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
f\left(x|\lambda\right) & =\lambda e^{-\lambda x}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x>0$
\end_inset

 and 
\begin_inset Formula $f\left(x|\lambda\right)=0$
\end_inset

 otherwise, so that a joint pdf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\lambda\right) & =\prod_{i=1}^{n}\lambda e^{-\lambda x}I_{\left\{ x_{i}>0\right\} }\\
 & =\lambda^{n}e^{-\sum_{i=1}^{n}\lambda x_{i}}I_{\left\{ x_{\left(1\right)}>0\right\} }.
\end{flalign*}

\end_inset

Find a minimal sufficient statistic for 
\begin_inset Formula $\lambda$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "exa:minimal-sufficient-exp-rv"

\end_inset


\end_layout

\begin_layout Example
We have
\begin_inset Formula 
\begin{flalign*}
\frac{f_{\mathbf{X}}\left(\mathbf{x}|\lambda\right)}{f_{\mathbf{X}}\left(\mathbf{y}|\lambda\right)} & =\frac{\lambda^{n}e^{-\lambda\sum_{i=1}^{n}x_{i}}I_{\left\{ x_{\left(1\right)}>0\right\} }}{\lambda^{n}e^{-\lambda\sum_{i=1}^{n}y_{i}}I_{\left\{ y_{\left(1\right)}>0\right\} }}\\
 & =e^{-\lambda\sum_{i=1}^{n}x_{i}}e^{\lambda\sum_{i=1}^{n}y_{i}}\left(\frac{I_{\left\{ x_{\left(1\right)}>0\right\} }}{I_{\left\{ y_{\left(1\right)}>0\right\} }}\right)\\
 & =e^{-\lambda\left(\sum_{i=1}^{n}x_{i}-\sum_{i=1}^{n}y_{i}\right)}\left(\frac{I_{\left\{ x_{\left(1\right)}>0\right\} }}{I_{\left\{ y_{\left(1\right)}>0\right\} }}\right).
\end{flalign*}

\end_inset

This ratio will be constant as a function of 
\begin_inset Formula $\lambda$
\end_inset

 if and only if 
\begin_inset Formula $\sum_{i=1}^{n}x_{i}-\sum_{i=1}^{n}y_{i}=0$
\end_inset

, i.e., if 
\begin_inset Formula $\sum_{i=1}^{n}x_{i}=\sum_{i=1}^{n}y_{i}$
\end_inset

.
 It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:minimal-sufficient"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)=\sum_{i=1}^{n}X_{i}$
\end_inset

 is a minimal sufficient statistic for 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Minimal sufficient statistics for an exponential family]
\end_layout

\end_inset

The set of sufficient statistics 
\begin_inset Formula $T\left(X\right)=\left\{ T_{1}\left(X\right),\ldots,T_{n}\left(X\right)\right\} $
\end_inset

 from an exponential family are minimal sufficient.
 Recall that the pmf or pdf of an exponential family can be written as
\begin_inset Formula 
\begin{flalign*}
f\left(x|\theta\right) & =h^{*}\left(x\right)c^{*}\left(\theta\right)\exp\left\{ \sum_{j=1}^{k}\omega_{j}\left(\theta\right)T_{j}\left(x\right)\right\} .
\end{flalign*}

\end_inset

We have
\begin_inset Formula 
\begin{flalign*}
\frac{f\left(x|\theta\right)}{f\left(y|\theta\right)} & =\frac{h^{*}\left(x\right)c^{*}\left(\theta\right)\exp\left\{ \sum_{j=1}^{k}\omega_{j}\left(\theta\right)T_{j}\left(x\right)\right\} }{h^{*}\left(y\right)c^{*}\left(\theta\right)\exp\left\{ \sum_{j=1}^{k}\omega_{j}\left(\theta\right)T_{j}\left(y\right)\right\} }\\
 & =\frac{h^{*}\left(x\right)}{h^{*}\left(y\right)}\exp\left\{ \sum_{j=1}^{k}\omega_{j}\left(\theta\right)T_{j}\left(x\right)\right\} \exp\left\{ -\sum_{j=1}^{k}\omega_{j}\left(\theta\right)T_{j}\left(y\right)\right\} \\
 & =\frac{h^{*}\left(x\right)}{h^{*}\left(y\right)}\exp\left\{ \left[\sum_{j=1}^{k}\omega_{j}\left(\theta\right)T_{j}\left(x\right)\right]-\left[\sum_{j=1}^{k}\omega_{j}\left(\theta\right)T_{j}\left(y\right)\right]\right\} \\
 & =\frac{h^{*}\left(x\right)}{h^{*}\left(y\right)}\exp\left\{ \left[\omega_{1}\left(\theta\right)T_{1}\left(x\right)+\cdots+\omega_{k}T_{k}\left(x\right)\right]-\left[\omega_{1}\left(\theta\right)T_{1}\left(y\right)+\cdots+\omega_{k}\left(\theta\right)T_{k}\left(y\right)\right]\right\} \\
 & =\frac{h^{*}\left(x\right)}{h^{*}\left(y\right)}\exp\left\{ \omega_{1}\left(\theta\right)\left[T_{1}\left(x\right)-T_{1}\left(y\right)\right]+\cdots+\omega_{k}\left[T_{k}\left(x\right)-T_{k}\left(y\right)\right]\right\} \\
 & =\frac{h^{*}\left(x\right)}{h^{*}\left(y\right)}\exp\left\{ \sum_{j=1}^{k}\omega_{j}\left(\theta\right)\left[T_{j}\left(x\right)-T_{j}\left(y\right)\right]\right\} .
\end{flalign*}

\end_inset

This ratio will be constant as a function of 
\begin_inset Formula $\theta$
\end_inset

 if and only if 
\begin_inset Formula $T\left(X\right)=T\left(Y\right)$
\end_inset

.
 It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:minimal-sufficient"

\end_inset

 that 
\begin_inset Formula $T\left(X\right)=\left\{ T_{1}\left(X\right),\ldots,T_{n}\left(X\right)\right\} $
\end_inset

 is a minimal sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "exa:min-sufficient-exp-family"

\end_inset


\end_layout

\begin_layout Subsection
Ancillary statistics
\end_layout

\begin_layout Definition
A statistic 
\begin_inset Formula $S\left(\mathbf{X}\right)$
\end_inset

 whose distribution does not depend on the parameter 
\begin_inset Formula $\theta$
\end_inset

 is called an 
\shape italic
ancillary statistic
\shape default
.
\end_layout

\begin_layout Standard
Alone, an ancillary statistic contains no information about 
\begin_inset Formula $\theta$
\end_inset

.
 When used in conjunction with other statistics, it sometimes contains valuable
 information for inference about 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.5}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Bivariate transformations
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left(X,Y\right)$
\end_inset

 be a random vector with a known probability distribution.
 Now consider a new bivariate random vector 
\begin_inset Formula $\left(U,V\right)$
\end_inset

 defined by 
\begin_inset Formula $U=g_{1}\left(X,Y\right)$
\end_inset

 and 
\begin_inset Formula $V=g_{2}\left(X,Y\right)$
\end_inset

, where 
\begin_inset Formula $g_{1}\left(x,y\right)$
\end_inset

 and 
\begin_inset Formula $g_{2}\left(x,y\right)$
\end_inset

 are some specified functions.
 If 
\begin_inset Formula $B$
\end_inset

 is any subset of 
\begin_inset Formula $\mathbb{R}^{2}$
\end_inset

, then 
\begin_inset Formula $\left(U,V\right)\in B$
\end_inset

 if and only if 
\begin_inset Formula $\left(X,Y\right)\in A$
\end_inset

, where 
\begin_inset Formula $A=\left\{ \left(x,y\right):\left(g_{1}\left(x,y\right),g_{2}\left(x,y\right)\right)\in B\right\} $
\end_inset

.
 Thus 
\begin_inset Formula $P\left(\left\{ \left(U,V\right)\in B\right\} \right)=P\left(\left\{ \left(X,Y\right)\in A\right\} \right)$
\end_inset

, and the probability distribution of 
\begin_inset Formula $\left(U,V\right)$
\end_inset

 is completely determined by the probability distribution of 
\begin_inset Formula $\left(X,Y\right)$
\end_inset

.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\left(X,Y\right)$
\end_inset

 is a continuous random vector with joint pdf 
\begin_inset Formula $f_{X,Y}\left(x,y\right)$
\end_inset

, then the joint pdf of 
\begin_inset Formula $\left(U,V\right)$
\end_inset

 can be expressed in terms of 
\begin_inset Formula $f_{X,Y}\left(x,y\right)$
\end_inset

.
 Let 
\begin_inset Formula 
\begin{flalign*}
\mathcal{A} & =\left\{ \left(x,y\right):f_{X,Y}\left(x,y\right)>0\right\} 
\end{flalign*}

\end_inset

 and 
\begin_inset Formula 
\begin{flalign*}
\mathcal{B} & =\left\{ \left(u,v\right):u=g_{1}\left(x,y\right),v=g_{2}\left(x,y\right),\left(x,y\right)\in\mathcal{A}\right\} .
\end{flalign*}

\end_inset

The joint pdf 
\begin_inset Formula $f_{U,V}$
\end_inset


\begin_inset Formula $\left(u,v\right)$
\end_inset

 will be positive on the set 
\begin_inset Formula $\mathcal{B}$
\end_inset

.
 For the simplest version of this result we assume that the transformation
 
\begin_inset Formula $u=g_{1}\left(x,y\right)$
\end_inset

 and 
\begin_inset Formula $v=g_{2}\left(x,y\right)$
\end_inset

 defines a one-to-one transformation of 
\begin_inset Formula $\mathcal{A}$
\end_inset

 onto 
\begin_inset Formula $\mathcal{B}$
\end_inset

.
 We are assuming that for each 
\begin_inset Formula $\left(u,v\right)\in\mathcal{B}$
\end_inset

, there is only one 
\begin_inset Formula $\left(x,y\right)\in\mathcal{A}$
\end_inset

 such that 
\begin_inset Formula $\left(u,v\right)=\left(g_{1}\left(x,y\right),g_{2}\left(x,y\right)\right)$
\end_inset

.
 For such a one-to-one, onto transformation, we can solve the equations
 
\begin_inset Formula $u=g_{1}\left(x,y\right)$
\end_inset

 and 
\begin_inset Formula $v=g_{2}\left(x,y\right)$
\end_inset

 for 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

 in terms of 
\begin_inset Formula $u$
\end_inset

 and 
\begin_inset Formula $v$
\end_inset

.
 We will denote this inverse transformation by 
\begin_inset Formula $x=h_{1}\left(u,v\right)$
\end_inset

 and 
\begin_inset Formula $y=h_{2}\left(u,v\right)$
\end_inset

.
 The role played by the derivative in the univariate case is now played
 by quantity called the Jacobian of the transformation.
 This function of 
\begin_inset Formula $\left(u,v\right)$
\end_inset

, denoted by 
\begin_inset Formula $J$
\end_inset

, is the determinant of a matrix of partial derivatives, and is defined
 by
\begin_inset Formula 
\begin{flalign*}
J= & \left|\begin{array}{cc}
\frac{\partial x}{\partial u} & \frac{\partial x}{\partial v}\\
\frac{\partial y}{\partial u} & \frac{\partial y}{\partial v}
\end{array}\right|=\frac{\partial x}{\partial u}\frac{\partial y}{\partial v}-\frac{\partial y}{\partial u}\frac{\partial x}{\partial v},
\end{flalign*}

\end_inset

where 
\begin_inset Formula 
\[
\frac{\partial x}{\partial u}=\frac{\partial h_{1}\left(u,v\right)}{\partial u},\quad\frac{\partial x}{\partial v}=\frac{\partial h_{1}\left(u,v\right)}{\partial v},\quad\frac{\partial y}{\partial u}=\frac{\partial h_{2}\left(u,v\right)}{\partial u},\quad\mbox{and}\quad\frac{\partial y}{\partial v}=\frac{\partial h_{2}\left(u,v\right)}{\partial v}.
\]

\end_inset

Then, the joint pdf of 
\begin_inset Formula $\left(U,V\right)$
\end_inset

 is 0 outside the set 
\begin_inset Formula $\mathcal{B}$
\end_inset

 and on the set 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{U,V}\left(u,v\right) & =f_{X,Y}\left(h_{1}\left(u,v\right),h_{2}\left(u,v\right)\right)\left|J\right|.
\end{flalign*}

\end_inset


\end_layout

\begin_layout Remark*
This technique, which is easily generalized to more than two variables,
 can be used to find the pdf of some function of interest by first finding
 the joint pdf of that function and another, conveniently chosen function,
 then integrating the resulting joint pdf with respect to the second function,
 which gives the (marginal) pdf of the function of interest.
 This technique is demonstrated in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:ancillary-stat-uniform-range"

\end_inset

.
\end_layout

\begin_layout Theorem
\begin_inset ERT
status open

\begin_layout Plain Layout

[Distribution of the sum of Poisson variables]
\end_layout

\end_inset

If 
\begin_inset Formula $X\sim\mbox{Poisson}\left(\theta\right)$
\end_inset

 and 
\begin_inset Formula $Y\sim\mbox{Poisson}\left(\lambda\right)$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are independent, then 
\begin_inset Formula $X+Y\sim\mbox{Poisson}\left(\theta+\lambda\right)$
\end_inset

.
 (This is Theorem 4.3.2 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:dist-of-sum-of-poisson-rv"

\end_inset


\end_layout

\begin_layout Proof
[proof goes here]
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Ancillary statistic for a uniform random variable]
\end_layout

\end_inset

Let 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 be iid uniform observations on the interval 
\begin_inset Formula $\left(\theta,\theta+1\right)$
\end_inset

, 
\begin_inset Formula $-\infty<\theta<\infty$
\end_inset

.
 Let 
\begin_inset Formula $X_{\left(1\right)}<\cdots<X_{\left(n\right)}$
\end_inset

 be the order statistics from the sample.
 Show that the range statistic 
\begin_inset Formula $R=X_{\left(n\right)}-X_{\left(1\right)}$
\end_inset

 is an ancillary statistic.
 (This is example 6.2.17 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "exa:ancillary-stat-uniform-range"

\end_inset


\end_layout

\begin_layout Standard
The pdf of each 
\begin_inset Formula $X_{i}$
\end_inset

 is given by 
\begin_inset Formula 
\begin{flalign*}
f_{X_{i}}\left(x|\theta\right) & =\frac{1}{\left(\theta+1\right)-\theta}\\
 & =1,
\end{flalign*}

\end_inset

where 
\begin_inset Formula $\theta<x<\theta+1$
\end_inset

 and 
\begin_inset Formula $f_{X_{i}}\left(x|\theta\right)=0$
\end_inset

 otherwise, so that the cdf of each 
\begin_inset Formula $X_{i}$
\end_inset

 is given by
\begin_inset Formula 
\[
F_{X_{i}}\left(x|\theta\right)=\begin{cases}
0, & x\leq\theta\\
\int_{\theta}^{x}1\mbox{d}x=x-\theta, & \theta<x<\theta+1\\
1, & x\geq\theta+1
\end{cases}.
\]

\end_inset

Let 
\begin_inset Formula $u=x_{\left(1\right)}$
\end_inset

 and let 
\begin_inset Formula $v=x_{\left(n\right)}$
\end_inset

.
 By 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:order-stat-joint-pdf"

\end_inset

, the joint pdf of 
\begin_inset Formula $X_{\left(1\right)}$
\end_inset

 and 
\begin_inset Formula $X_{\left(n\right)}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{X_{\left(1\right)},X_{\left(n\right)}}\left(u,v\right) & =\frac{n!}{\left(1-1\right)!\left(n-1-1\right)!\left(n-n\right)!}f_{X}\left(u\right)f_{X}\left(v\right)\left[F_{X}\left(u\right)\right]^{1-1}\\
 & \quad\cdot\left[F_{X}\left(v\right)-F_{X}\left(u\right)\right]^{n-1-1}\left[1-F_{X}\left(v\right)\right]^{n-n}\\
 & =\frac{n!}{\left(n-2\right)!}f_{X}\left(u\right)f_{X}\left(v\right)\left[F_{X}\left(v\right)-F_{X}\left(u\right)\right]^{n-2}\\
 & =\frac{n!}{\left(n-2\right)!}\cdot1\cdot1\cdot\left[\left(v-\theta\right)-\left(u-\theta\right)\right]^{n-2}\\
 & =\frac{n!}{\left(n-2\right)!}\left(v-u\right)^{n-2}\\
 & =\frac{n\left(n-1\right)\left(n-2\right)!}{\left(n-2\right)!}\left(v-u\right)^{n-2}\\
 & =n\left(n-1\right)\left(v-u\right)^{n-2}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $\theta<u<v<\theta+1$
\end_inset

 and 
\begin_inset Formula $f_{X_{\left(1\right)},X_{\left(n\right)}}\left(u,v\right)=0$
\end_inset

 otherwise.
 Let 
\begin_inset Formula 
\begin{flalign*}
\mathcal{A} & =\left\{ \left(u,v\right):f_{X_{\left(1\right)},X_{\left(n\right)}}\left(u,v\right)>0\right\} ,
\end{flalign*}

\end_inset

and make the transformation 
\begin_inset Formula $R=X_{\left(n\right)}-X_{\left(1\right)}$
\end_inset

 and 
\begin_inset Formula $M=\left(X_{\left(1\right)}+X_{\left(n\right)}\right)/2$
\end_inset

, so that we have 
\begin_inset Formula 
\begin{flalign*}
\mathcal{B} & =\left\{ \left(r,m\right):r=v-u,m=\left(u+v\right)/2,\left(u,v\right)\in\mathcal{A}\right\} .
\end{flalign*}

\end_inset

Then, 
\begin_inset Formula $f_{R,M}\left(r,m\right)$
\end_inset

 will be positive on 
\begin_inset Formula $\mathcal{B}$
\end_inset

.
 We have the inverse transformation 
\begin_inset Formula 
\begin{flalign*}
X_{\left(1\right)} & =2M-X_{\left(n\right)}\\
 & =2M-\left(R+X_{\left(1\right)}\right)\\
\Leftrightarrow2X_{\left(1\right)} & =2M-R\\
\Leftrightarrow X_{\left(1\right)} & =\left(2M-R\right)/2\\
\Leftrightarrow u & =\left(2m-r\right)/2
\end{flalign*}

\end_inset

and
\begin_inset Formula 
\begin{flalign*}
X_{\left(n\right)} & =2M-X_{\left(1\right)}\\
 & =2M-\left(X_{\left(n\right)}-R\right)\\
\Leftrightarrow2X_{\left(n\right)} & =2M+R\\
\Leftrightarrow X_{\left(n\right)} & =\left(2M+R\right)/2\\
\Leftrightarrow v & =\left(2m+r\right)/2.
\end{flalign*}

\end_inset

The Jacobian of the transformation is given by
\begin_inset Formula 
\begin{flalign*}
J & =\begin{vmatrix}\frac{\partial u}{\partial r} & \frac{\partial u}{\partial m}\\
\frac{\partial v}{\partial r} & \frac{\partial v}{\partial m}
\end{vmatrix}\\
 & =\begin{vmatrix}-\frac{1}{2} & 1\\
\frac{1}{2} & 1
\end{vmatrix}\\
 & =\left(-\frac{1}{2}\right)\left(1\right)-\left(\frac{1}{2}\right)\left(1\right)\\
 & =-1.
\end{flalign*}

\end_inset

We will now find the range for 
\begin_inset Formula $f_{R,M}$
\end_inset

.
 We have
\begin_inset Formula 
\begin{flalign*}
u>\theta & \Rightarrow m-\frac{r}{2}>\theta\\
 & \Rightarrow m>\theta+\frac{r}{2}\\
v>u & \Rightarrow m+\frac{r}{2}>m-\frac{r}{2}\\
 & \Rightarrow\frac{r}{2}>-\frac{r}{2}\\
 & \Rightarrow r>0\\
v<\theta+1 & \Rightarrow\frac{2m+r}{2}<\theta+1\\
 & \Rightarrow m<\theta+1-\frac{r}{2}
\end{flalign*}

\end_inset

[insert figure here whenever Octave decides to cooperate] From the figure
 above, we see that the region where 
\begin_inset Formula $f_{R,M}$
\end_inset

 is positive is bounded by 
\begin_inset Formula $r>0$
\end_inset

, 
\begin_inset Formula $m>\theta+\left(r/2\right)$
\end_inset

, and 
\begin_inset Formula $m<\theta+1-\left(r/2\right)$
\end_inset

.
 The upper limit of integration for 
\begin_inset Formula $r$
\end_inset

 is given by the intersection of 
\begin_inset Formula $m=\theta+\left(r/2\right)$
\end_inset

 and 
\begin_inset Formula $m=\theta+1-\left(r/2\right)$
\end_inset

.
 Setting them equal, we have
\begin_inset Formula 
\begin{flalign*}
\theta+\frac{r}{2} & =\theta+1-\frac{r}{2}\\
\Leftrightarrow r & =1.
\end{flalign*}

\end_inset

Then, the joint pdf of 
\begin_inset Formula $R$
\end_inset

 and 
\begin_inset Formula $M$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{R,M}\left(r,m\right) & =f_{X_{\left(1\right)},X_{\left(n\right)}}\left(\frac{2m-r}{2},\frac{2m+r}{2}\right)\left|J\right|\\
 & =n\left(n-1\right)\left(\frac{2m+r}{2}-\frac{2m-r}{2}\right)^{n-2}\left|-1\right|\\
 & =n\left(n-1\right)\left(\frac{2m+r-2m+r}{2}\right)^{n-2}\\
 & =n\left(n-1\right)\left(\frac{2r}{2}\right)^{n-2}\\
 & =n\left(n-1\right)r^{n-2}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $0<r<1$
\end_inset

 and 
\begin_inset Formula $\theta+\left(r/2\right)<m<\theta+1-\left(r/2\right)$
\end_inset

 and 
\begin_inset Formula $f_{R,M}\left(r,m\right)=0$
\end_inset

 otherwise.
 We will find the (marginal) pdf of 
\begin_inset Formula $R$
\end_inset

 by integrating the joint pdf with respect to 
\begin_inset Formula $m$
\end_inset

.
\begin_inset Formula 
\begin{flalign*}
f_{R}\left(r|\theta\right) & =\int_{\theta+\left(r/2\right)}^{\theta+1-\left(r/2\right)}n\left(n-1\right)r^{n-2}\mbox{d}m\\
 & =n\left(n-1\right)r^{n-2}\left[m\Big\rvert_{\theta+\left(r/2\right)}^{\theta+1-\left(r/2\right)}\right]\\
 & =n\left(n-1\right)r^{n-2}\left[\theta+1-\frac{r}{2}-\left(\theta+\frac{r}{2}\right)\right]\\
 & =n\left(n-1\right)r^{n-2}\left[1-\frac{r}{2}-\frac{r}{2}\right]\\
 & =n\left(n-1\right)r^{n-2}\left(1-r\right)
\end{flalign*}

\end_inset

where 
\begin_inset Formula $0<r<1$
\end_inset

.
 This expression is independent of 
\begin_inset Formula $\theta$
\end_inset

, so it follows that 
\begin_inset Formula $R$
\end_inset

 is ancillary.
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Ancillary statistic for location family]
\end_layout

\end_inset

Let 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 be iid observations from a location parameter family with cdf 
\begin_inset Formula $F\left(x-\theta\right)$
\end_inset

, 
\begin_inset Formula $-\infty<\theta<\infty$
\end_inset

.
 We will show that the range, 
\begin_inset Formula $R=X_{\left(n\right)}-X_{\left(1\right)}$
\end_inset

, is an ancillary statistic.
 (This is example 6.2.18 from Casella & Berger.)
\end_layout

\begin_layout Example
We will use 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:location-scale-family"

\end_inset

 and work with 
\begin_inset Formula $Z_{1},\ldots,Z_{n}$
\end_inset

 iid observations from 
\begin_inset Formula $F\left(x\right)$
\end_inset

 (corresponding to 
\begin_inset Formula $\theta=0$
\end_inset

) with 
\begin_inset Formula $X_{1}=Z_{1}+\theta,\ldots,X_{n}=Z_{n}+\theta$
\end_inset

.
 Thus, the cdf of the range statistic, 
\begin_inset Formula $R$
\end_inset

, is
\begin_inset Formula 
\begin{flalign*}
F_{R}\left(r|\theta\right) & =P_{\theta}\left(\left\{ R\leq r\right\} \right)\\
 & =P_{\theta}\left(\left\{ \max_{i}X_{i}-\min_{i}X_{i}\leq r\right\} \right)\\
 & =P_{\theta}\left(\left\{ \max\left(X_{1},\ldots,X_{n}\right)-\min\left(X_{1},\ldots,X_{n}\right)\leq r\right\} \right)\\
 & =P_{\theta}\left(\left\{ \max\left(Z_{1}+\theta,\ldots,Z_{n}+\theta\right)-\min\left(Z_{1}+\theta,\ldots,Z_{n}+\theta\right)\leq r\right\} \right)\\
 & =P_{\theta}\left(\left\{ Z_{\left(n\right)}+\theta-\left(Z_{\left(1\right)}+\theta\right)\right\} \leq r\right)\\
 & =P_{\theta}\left(\left\{ Z_{\left(n\right)}-Z_{\left(1\right)}\leq r\right\} \right).
\end{flalign*}

\end_inset

This expression does not depend on 
\begin_inset Formula $\theta$
\end_inset

, so it follows that the cdf of 
\begin_inset Formula $R$
\end_inset

 does not depend on 
\begin_inset Formula $\theta$
\end_inset

 and therefore 
\begin_inset Formula $R$
\end_inset

 is an ancillary statistic.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Ancillary statistic for scale family]
\end_layout

\end_inset

Let 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 be iid observations from a scale parameter family with cdf 
\begin_inset Formula $F\left(x/\sigma\right)$
\end_inset

, 
\begin_inset Formula $\sigma>0$
\end_inset

.
 Then, any statistic that depends on the sample only through the 
\begin_inset Formula $n-1$
\end_inset

 values 
\begin_inset Formula $X_{1}/X_{n},\ldots,X_{n-1}/X_{n}$
\end_inset

 is an ancillary statistic.
 (This is example 6.2.19 from Casella & Berger.)
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $Z_{1},\ldots,Z_{n}$
\end_inset

 be iid observations from 
\begin_inset Formula $F\left(x\right)$
\end_inset

 (corresponding to 
\begin_inset Formula $\sigma=1$
\end_inset

) with 
\begin_inset Formula $X_{i}=\sigma Z_{i}$
\end_inset

.
 The joint cdf of 
\begin_inset Formula $X_{1}/X_{n},\ldots,X_{n-1}/X_{n}$
\end_inset

 is
\begin_inset Formula 
\begin{flalign*}
F\left(y_{1},\ldots,y_{n-1}|\sigma\right) & =P_{\sigma}\left(\left\{ \frac{X_{1}}{X_{n}}\leq y_{1}\right\} \cap\cdots\cap\left\{ \frac{X_{n-1}}{X_{n}}\leq y_{n-1}\right\} \right)\\
 & =P_{\sigma}\left(\left\{ \frac{\sigma Z_{1}}{\sigma Z_{n}}\leq y_{1}\right\} \cap\cdots\cap\left\{ \frac{\sigma Z_{n-1}}{\sigma Z_{n}}\leq y_{n-1}\right\} \right)\\
 & =P_{\sigma}\left(\left\{ \frac{Z_{1}}{Z_{n}}\leq y_{1}\right\} \cap\cdots\cap\left\{ \frac{Z_{n-1}}{Z_{n}}\leq y_{n-1}\right\} \right).
\end{flalign*}

\end_inset

The last probability does not depend on 
\begin_inset Formula $\sigma$
\end_inset

 because the distribution of 
\begin_inset Formula $Z_{1},\ldots,Z_{n}$
\end_inset

 does not depend on 
\begin_inset Formula $\sigma$
\end_inset

.
 So the distribution of 
\begin_inset Formula $X_{1}/X_{n},\ldots,X_{n-1}/X_{n}$
\end_inset

 is independent of 
\begin_inset Formula $\sigma$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout

[Mixture of normal distributions]
\end_layout

\end_inset

Sometimes, an ancillary statistic is viewed in conjunction with another
 statistic, and together they form a minimal sufficient statistic, i.e., 
\begin_inset Formula $S=\left(T,C\right)$
\end_inset

 where 
\begin_inset Formula $C$
\end_inset

 is ancillary for 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $T$
\end_inset

 is minimal sufficient conditional on 
\begin_inset Formula $C$
\end_inset

.
\end_layout

\begin_layout Standard
Suppose that 
\begin_inset Formula $Y$
\end_inset

 is a mixture of normal distributions 
\begin_inset Formula $N\left(\mu,\sigma_{0}^{2}\right)$
\end_inset

 and 
\begin_inset Formula $N\left(\mu,\sigma_{1}^{2}\right)$
\end_inset

 with 
\begin_inset Formula $\sigma_{0}^{2}$
\end_inset

 and 
\begin_inset Formula $\sigma_{1}^{2}$
\end_inset

 known (for example, any two of the three distributions in 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ref{fig:ex-of-scale-normal}
\end_layout

\end_inset

).
 Let 
\begin_inset Formula $C$
\end_inset

 be defined as
\begin_inset Formula 
\[
C=\begin{cases}
0, & \mbox{if }Y\sim N\left(\mu,\sigma_{0}^{2}\right)\\
1, & \mbox{if }Y\sim N\left(\mu,\sigma_{1}^{2}\right)
\end{cases}.
\]

\end_inset


\begin_inset Formula $Y$
\end_inset

 is equally likely to be 
\begin_inset Formula $N\left(\mu,\sigma_{0}^{2}\right)$
\end_inset

 or 
\begin_inset Formula $N\left(\mu,\sigma_{1}^{2}\right)$
\end_inset

, so 
\begin_inset Formula $P\left(\left\{ Y\sim N\left(\mu,\sigma_{0}^{2}\right)\right\} \right)=P\left(\left\{ Y\sim N\left(\mu,\sigma_{1}^{2}\right)\right\} \right)=1/2$
\end_inset

.
 Then, the joint pdf of 
\begin_inset Formula $Y$
\end_inset

 and 
\begin_inset Formula $C$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{C,Y}\left(c,y\right) & =P\left(\left\{ C=c\right\} \cap\left\{ Y=y\right\} \right)\\
 & =P\left(\left\{ Y=y\right\} |\left\{ C=c\right\} \right)\cdot P\left(\left\{ C=c\right\} \right)\\
 & =\frac{1}{2}\frac{1}{\sqrt{2\pi\sigma_{c}^{2}}}e^{-\left(y-\mu\right)^{2}/\left(2\sigma_{c}^{2}\right)}\\
 & =\frac{1}{2}\frac{1}{\sqrt{2\pi\sigma_{c}^{2}}}\exp\left\{ -\frac{y^{2}}{2\sigma_{c}^{2}}-\frac{\mu^{2}}{2\sigma_{c}^{2}}+\frac{\mu y}{\sigma_{c}^{2}}\right\} \\
 & =\underbrace{\frac{1}{2}\frac{1}{\sqrt{2\pi\sigma_{c}^{2}}}\exp\left\{ -\frac{y^{2}}{2\sigma_{c}^{2}}\right\} }_{h\left(y\right)}\exp\left\{ \underbrace{-\frac{\mu^{2}}{2}}_{\omega_{1}\left(\mu\right)}\underbrace{\frac{1}{\sigma_{c}^{2}}}_{t_{1}\left(y\right)}+\underbrace{\mu}_{\omega_{2}\left(\mu\right)}\underbrace{\frac{y}{\sigma_{c}^{2}}}_{t_{2}\left(y\right)}\right\} .
\end{flalign*}

\end_inset

This last expression has the form of an exponential family, with 
\begin_inset Formula $c\left(\mu\right)=1$
\end_inset

.
 In 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:min-sufficient-exp-family"

\end_inset

, we showed that a minimal sufficient statistic for an exponential family
 is given by 
\begin_inset Formula $T\left(Y\right)=\left(T_{1}\left(Y\right),\ldots,T_{n}\left(Y\right)\right)$
\end_inset

.
 It follows that 
\begin_inset Formula 
\begin{flalign*}
T\left(Y\right) & =\left(\frac{1}{\sigma_{c}^{2}},\frac{Y}{\sigma_{c}^{2}}\right)
\end{flalign*}

\end_inset

is a minimal sufficient statistic for 
\begin_inset Formula $\mu$
\end_inset

 conditioned on 
\begin_inset Formula $C$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Expanded definition of ancillarity
\end_layout

\begin_layout Standard
Suppose that 
\begin_inset Formula $\theta=\left(\psi,\lambda\right)$
\end_inset

, where 
\begin_inset Formula $\lambda$
\end_inset

 is not of direct interest (
\begin_inset Formula $\lambda$
\end_inset

 is a nuisance parameter).
 Suppose that 
\begin_inset Formula $S=\left(T,C\right)$
\end_inset

 is minimal sufficient for 
\begin_inset Formula $\theta$
\end_inset

, where the pdf of 
\begin_inset Formula $C$
\end_inset

 depends on 
\begin_inset Formula $\lambda$
\end_inset

 but not on 
\begin_inset Formula $\psi$
\end_inset

, and the conditional pdf of 
\begin_inset Formula $T$
\end_inset

 given 
\begin_inset Formula $C$
\end_inset

 depends on 
\begin_inset Formula $\psi$
\end_inset

 but not 
\begin_inset Formula $\lambda$
\end_inset

.
 Then 
\begin_inset Formula $C$
\end_inset

 is called ancillary in the extended sense.
\end_layout

\begin_layout Subsection
Complete statistics
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $f\left(t|\theta\right)$
\end_inset

 be a family of pdfs or pmfs for a statistic 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

.
 The family of probability distributions is called 
\shape italic
complete
\shape default
 if 
\begin_inset Formula $\mbox{E}_{\theta}\left[g\left(T\right)\right]=0$
\end_inset

 for all 
\begin_inset Formula $\theta$
\end_inset

 implies 
\begin_inset Formula $P_{\theta}\left(\left\{ g\left(T\right)=0\right\} \right)=1$
\end_inset

 for all 
\begin_inset Formula $\theta$
\end_inset

.
 Equivalently, 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is called a 
\shape italic
complete statistic
\shape default
.
 I.e., 
\begin_inset Formula $T$
\end_inset

 is complete if 
\begin_inset Formula 
\[
\mbox{E}_{\theta}\left[g\left(T\right)\right]=0\quad\forall\theta\quad\Rightarrow\quad P_{\theta}\left(\left\{ g\left(T\right)=0\right\} \right)=1\quad\forall g.
\]

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $T\left(X\right)$
\end_inset

 is sufficient and complete for 
\begin_inset Formula $\theta$
\end_inset

, then 
\begin_inset Formula $T$
\end_inset

 is minimal sufficient.
\end_layout

\begin_layout Proof
[proof goes here]
\end_layout

\begin_layout Theorem
\begin_inset ERT
status open

\begin_layout Plain Layout

[Complete statistics in the exponential family]
\end_layout

\end_inset

Let 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 be iid observations from an exponential family with pdf or pmf of the form
\begin_inset Formula 
\begin{flalign*}
f\left(x|\boldsymbol{\theta}\right) & =h\left(x\right)c\left(\boldsymbol{\theta}\right)\exp\left(\sum_{j=1}^{k}\omega_{j}\left(\boldsymbol{\theta}\right)t_{j}\left(x\right)\right),
\end{flalign*}

\end_inset

where 
\begin_inset Formula $\boldsymbol{\theta}=\left(\theta_{1},\theta_{2},\ldots,\theta_{k}\right)$
\end_inset

.
 Then the statistic
\begin_inset Formula 
\[
T\left(\mathbf{X}\right)=\left(\sum_{i=1}^{n}t_{1}\left(X_{i}\right),\sum_{i=1}^{n}t_{2}\left(X_{i}\right),\ldots,\sum_{i=1}^{n}t_{k}\left(X_{i}\right)\right)
\]

\end_inset

is complete if 
\begin_inset Formula $\left\{ \left(\omega_{1}\left(\boldsymbol{\theta}\right),\ldots,\omega_{k}\left(\boldsymbol{\theta}\right)\right):\boldsymbol{\theta}\in\Theta\right\} $
\end_inset

 contains an open set in 
\begin_inset Formula $\mathbb{R}^{k}$
\end_inset

.
 (This is Theorem 6.2.25 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:complete-stat-exp-family"

\end_inset


\end_layout

\begin_layout Proof
[proof goes here]
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Theorem
If a minimal sufficient statistic exists, then any complete sufficient statistic
 is also a minimal sufficient statistic.
 (This is Theorem 6.2.28 from Casella & Berger.)
\end_layout

\begin_layout Proof
[proof goes here]
\end_layout

\begin_layout Remark
Minimal sufficiency does not imply completeness.
 In 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:3-param-exp-family"

\end_inset

, we expressed the family of distributions with densities 
\begin_inset Formula 
\begin{flalign*}
f\left(x|\theta\right) & =\frac{2}{\Gamma\left(1/4\right)}\exp\left[-\left(x-\theta\right)^{4}\right]
\end{flalign*}

\end_inset

for 
\begin_inset Formula $x\in\mathbb{R}$
\end_inset

 as
\begin_inset Formula 
\begin{flalign*}
f\left(x|\theta\right) & =\underbrace{\frac{2}{\Gamma\left(1/4\right)}\exp\left\{ -x^{4}\right\} }_{h\left(x\right)}\underbrace{\exp\left\{ -\theta^{4}\right\} }_{c\left(\theta\right)}\exp\left\{ \underbrace{4x^{3}}_{t_{1}\left(x\right)}\underbrace{\theta}_{\omega_{1}\left(\theta\right)}\underbrace{-6x^{2}}_{t_{2}\left(x\right)}\underbrace{\theta^{2}}_{\omega_{2}\left(\theta\right)}+\underbrace{4x}_{t_{3}\left(x\right)}\underbrace{\theta^{3}}_{\omega_{3}\left(\theta\right)}\right\} ,
\end{flalign*}

\end_inset

which is in exponential form, so that 
\begin_inset Formula $T\left(\mathbf{X}\right)=\left(4x^{3},-6x^{2},4x\right)$
\end_inset

.
 It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:min-sufficient-exp-family"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a minimal sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
 The parameter space for this distribution is given by 
\begin_inset Formula $\left\{ \omega_{1}\left(\theta\right),\omega_{2}\left(\theta\right),\omega_{3}\left(\theta\right)\right\} =\left\{ \theta,\theta^{2},\theta^{3}\right\} $
\end_inset

, i.e., 
\begin_inset Formula $k=3$
\end_inset

.
 We have 
\begin_inset Formula $d=1$
\end_inset

, so by definition this familiy of densities is a curved exponential family.
 Its graph in 
\begin_inset Formula $\mathbb{R}^{3}$
\end_inset

 is the curve shown in 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
figref{curved-exp-family}
\end_layout

\end_inset

.
 This graph does not have positive length (volume in 
\begin_inset Formula $\mathbb{R}^{3}$
\end_inset

), i.e., 
\begin_inset Formula $\left\{ \theta,\theta^{2},\theta^{3}\right\} $
\end_inset

 does not contain an open set in 
\begin_inset Formula $\mathbb{R}^{3}$
\end_inset

, so it follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:complete-stat-exp-family"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is not complete.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<curved-exp-family, echo=FALSE, fig.height=3, fig.align='center', fig.pos='!htb',
 fig.cap='graph of $x=
\backslash

\backslash
theta,y=
\backslash

\backslash
theta^{2},z=
\backslash

\backslash
theta^{3}$'>>=
\end_layout

\begin_layout Plain Layout

library(lattice)
\end_layout

\begin_layout Plain Layout

t <- seq(-2, 2, length.out=500)
\end_layout

\begin_layout Plain Layout

cloud(z~x+y, data.frame(x=t, y=t^2, z=t^3), pch=".", ylim=c(0,1.5), xlim=c(-1,1),
 zlim=c(-2,2))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Remark
Although the condition in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:complete-stat-exp-family"

\end_inset

 that the set 
\begin_inset Formula $\left\{ \left(\omega_{1}\left(\boldsymbol{\theta}\right),\ldots,\omega_{k}\left(\boldsymbol{\theta}\right):\boldsymbol{\theta}\in\Theta\right)\right\} $
\end_inset

 contain an open set is sufficient to guarantee completeness, it is not
 necessary.
 That is, the failure of this condition does not show that a statistic is
 not complete, as shown in the following example.
\end_layout

\begin_deeper
\begin_layout Example
Suppose 
\begin_inset Formula $X\sim\mbox{Bernoulli}\left(p\right)$
\end_inset

 and the parameter space consists of the two points 
\begin_inset Formula $p=1/4$
\end_inset

 and 
\begin_inset Formula $p=3/4$
\end_inset

.
 The pmf for 
\begin_inset Formula $X$
\end_inset

 can be written as
\begin_inset Formula 
\begin{flalign*}
p_{X}\left(x\right) & =p^{x}\left(1-p\right)^{1-x}\\
 & =p^{x}\left(1-p\right)^{-x}\left(1-p\right)\\
 & =\left(1-p\right)\left(\frac{p}{1-p}\right)^{x}\\
 & =\left(1-p\right)\exp\left\{ \log\left(\left(\frac{p}{1-p}\right)^{x}\right)\right\} \\
 & =\underbrace{\left(1-p\right)}_{c\left(p\right)}\exp\left\{ \underbrace{x}_{t_{1}\left(x\right)}\underbrace{\log\left(\frac{p}{1-p}\right)}_{\omega_{1}\left(p\right)}\right\} 
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left\{ 0,1\right\} $
\end_inset

 and 
\begin_inset Formula $p_{X}\left(x\right)=0$
\end_inset

 otherwise, i.e., 
\begin_inset Formula $X$
\end_inset

 has an exponential family distribution.
 Then, the parameter space is given by
\begin_inset Formula 
\begin{flalign*}
\left\{ \omega_{1}\left(p\right):p=\left\{ \frac{1}{4},\frac{3}{4}\right\} \right\}  & =\left\{ \log\left(\frac{1/4}{1-\left(1/4\right)}\right),\log\left(\frac{3/4}{1-\left(3-4\right)}\right)\right\} \\
 & =\left\{ \log\left(\frac{1/4}{3/4}\right),\log\left(\frac{3/4}{1/4}\right)\right\} \\
 & =\left\{ \log\frac{1}{3},\log3\right\} 
\end{flalign*}

\end_inset

The condition of 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:complete-stat-exp-family"

\end_inset

 is not satisfied because the parameter space has only two points in it,
 and hence the range of 
\begin_inset Formula $\log\left(p/\left(1-p\right)\right)$
\end_inset

 as 
\begin_inset Formula $p$
\end_inset

 varies over the parameter space does not contain an open set (an interval)
 in 
\begin_inset Formula $\mathbb{R}^{1}$
\end_inset

.
\end_layout

\begin_layout Example
Yet, the distribution of 
\begin_inset Formula $X$
\end_inset

 is complete.
 To see this, suppose 
\begin_inset Formula $g$
\end_inset

 is a function defined on the sample space such that 
\begin_inset Formula $\mbox{E}\left[g\left(X\right)\right]=0$
\end_inset

.
 To show that the distribution of 
\begin_inset Formula $X$
\end_inset

 is complete, we need to show that the only function satisfying this equality
 for all 
\begin_inset Formula $p$
\end_inset

 in the parameter space is the function which is identically zero.
 The sample space consists of the two points 
\begin_inset Formula $X=0$
\end_inset

 and 
\begin_inset Formula $X=1$
\end_inset

, so we need to show that this implies 
\begin_inset Formula $g\left(0\right)=g\left(1\right)=0$
\end_inset

.
\end_layout

\begin_layout Example
The expected value of 
\begin_inset Formula $g\left(X\right)$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
\mbox{E}\left[g\left(X\right)\right] & =\sum_{x=0}^{1}g\left(x\right)\cdot p_{X}\left(x\right)\\
 & =\sum_{x=0}^{1}g\left(x\right)\cdot p^{x}\left(1-p\right)^{1-x}\\
 & =g\left(0\right)\cdot p^{0}\left(1-p\right)^{1-0}+g\left(1\right)\cdot p^{1}\left(1-p\right)^{1-1}\\
 & =\left(1-p\right)g\left(0\right)+pg\left(1\right)
\end{flalign*}

\end_inset

so that if 
\begin_inset Formula $p=1/4$
\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
0 & =\mbox{E}_{p=1/4}\left[g\left(X\right)\right]\\
 & =\frac{3}{4}g\left(0\right)+\frac{1}{4}g\left(1\right)
\end{flalign*}

\end_inset

and if 
\begin_inset Formula $p=3/4$
\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
0 & =\mbox{E}_{p=3/4}\left[g\left(X\right)\right]\\
 & =\frac{1}{4}g\left(0\right)+\frac{3}{4}g\left(1\right).
\end{flalign*}

\end_inset

So, we have 
\begin_inset Formula $g\left(1\right)=-3g\left(0\right)$
\end_inset

, which gives
\begin_inset Formula 
\begin{flalign*}
0 & =\frac{1}{4}g\left(0\right)+\frac{3}{4}g\left(1\right)\\
 & =\frac{1}{4}g\left(0\right)+\frac{3}{4}\left(-3g\left(0\right)\right)\\
 & =-2g\left(0\right)\\
\Leftrightarrow0 & =g\left(0\right)
\end{flalign*}

\end_inset

and thus 
\begin_inset Formula $g\left(1\right)=-3\left(0\right)=0$
\end_inset

.
 Thus, the only solution is 
\begin_inset Formula $g\left(1\right)=g\left(0\right)=0$
\end_inset

, and with just two points in the parameter space we have that the family
 of distributions is complete.
\end_layout

\end_deeper
\begin_layout --Separator--

\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim\mbox{Bernoulli}\left(p\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pmf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
p_{X}\left(x\right) & =p^{x}\left(1-p\right)^{1-x}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left\{ 0,1\right\} $
\end_inset

 and 
\begin_inset Formula $p_{X}\left(x\right)=0$
\end_inset

 otherwise.
 Show that 
\begin_inset Formula $T_{1}=X_{2}-X_{1}$
\end_inset

 is not a complete statistic.
\begin_inset CommandInset label
LatexCommand label
name "exa:complete-stat-bernoulli-part-a"

\end_inset


\end_layout

\begin_layout Example
By definition, 
\begin_inset Formula $T_{1}$
\end_inset

 will be a complete statistic if 
\begin_inset Formula $\mbox{E}\left[g\left(T_{1}\right)\right]=0$
\end_inset

 for all 
\begin_inset Formula $p$
\end_inset

 implies 
\begin_inset Formula $P\left(\left\{ g\left(T_{1}\right)=0\right\} \right)=1$
\end_inset

 for all 
\begin_inset Formula $p$
\end_inset

.
 Suppose that 
\begin_inset Formula $g\left(T_{1}\right)=T_{1}$
\end_inset

.
 Then, we have
\begin_inset Formula 
\begin{flalign*}
\mbox{E}\left[g\left(T_{1}\right)\right] & =\mbox{E}\left[T_{1}\right]\\
 & =\mbox{E}\left[X_{2}-X_{1}\right]\\
 & =\mbox{E}\left[X_{2}\right]-\mbox{E}\left[X_{1}\right]\\
 & =\sum_{x_{2}=0}^{1}\left[x_{2}\cdot p^{x_{2}}\left(1-p\right)^{1-x_{2}}\right]-\sum_{x_{1}=0}^{1}\left[x_{1}\cdot p^{x_{1}}\left(1-p\right)^{1-x_{1}}\right]\\
 & =\left[0\cdot p^{0}\left(1-p\right)^{1-0}+1\cdot p^{1}\left(1-p\right)^{1-1}\right]-\left[0\cdot p^{0}\left(1-p\right)^{1-0}+1\cdot p^{1}\left(1-p\right)^{1-1}\right]\\
 & =\left[0+p\right]-\left[0+p\right]\\
 & =0.
\end{flalign*}

\end_inset

So, this choice of 
\begin_inset Formula $g$
\end_inset

 satisfies 
\begin_inset Formula $\mbox{E}\left[g\left(T_{1}\right)\right]=0$
\end_inset

 for all 
\begin_inset Formula $p$
\end_inset

.
 Then, we have
\begin_inset Formula 
\begin{flalign*}
P\left(\left\{ g\left(T_{1}\right)=0\right\} \right) & =P\left(\left\{ T_{1}=0\right\} \right)\\
 & =P\left(\left\{ X_{2}-X_{1}=0\right\} \right).
\end{flalign*}

\end_inset

This probability will be equal to 1 if and only if 
\begin_inset Formula $X_{1}=X_{2}$
\end_inset

, but this will not always be the case, e.g., suppose that 
\begin_inset Formula $X_{1}=0$
\end_inset

 and 
\begin_inset Formula $X_{2}=1$
\end_inset

.
 Even though our choice of 
\begin_inset Formula $g$
\end_inset

satisfies 
\begin_inset Formula $\mbox{E}\left[g\left(T_{1}\right)\right]=0$
\end_inset

 for all 
\begin_inset Formula $p$
\end_inset

, it does not imply 
\begin_inset Formula $P\left(\left\{ g\left(T_{1}\right)=0\right\} \right)=1$
\end_inset

 for all 
\begin_inset Formula $p$
\end_inset

.
 The condition of completeness applies to all functions (all choices of
 
\begin_inset Formula $g$
\end_inset

), so it follows that 
\begin_inset Formula $T_{1}$
\end_inset

 is not complete.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 be as in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:complete-stat-bernoulli-part-a"

\end_inset

.
 Show that 
\begin_inset Formula $T_{2}=\sum_{i=1}^{n}X_{i}$
\end_inset

 is a complete statistic.
 (This is example 6.2.22 from Casella & Berger.)
\end_layout

\begin_layout Example
\begin_inset Formula $T_{2}$
\end_inset

 is the sum of 
\begin_inset Formula $n$
\end_inset

 independent Bernoulli random variables each having the same success probability
 
\begin_inset Formula $p$
\end_inset

.
 It follows that 
\begin_inset Formula $T_{2}\sim\mbox{Binomial}\left(n,p\right)$
\end_inset

, so that the pmf of 
\begin_inset Formula $T_{2}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{T_{2}}\left(t\right) & =\binom{n}{t}p^{t}\left(1-p\right)^{n-t}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $t\in\left\{ 0,1,2,\ldots,n\right\} $
\end_inset

 and 
\begin_inset Formula $p_{T_{2}}\left(t\right)=0$
\end_inset

 otherwise.
 Suppose 
\begin_inset Formula $g\left(T_{2}\right)$
\end_inset

 is a function satisfying 
\begin_inset Formula $\mbox{E}\left[g\left(T_{2}\right)\right]=0$
\end_inset

, so that we have
\begin_inset Formula 
\begin{flalign*}
0 & =\mbox{E}\left[g\left(T_{2}\right)\right]\\
 & =\sum_{k=0}^{n}\left[g\left(k\right)\cdot p_{T_{2}}\left(k\right)\right]\\
 & =\sum_{k=0}^{n}\left[g\left(k\right)\cdot\binom{n}{k}p^{k}\left(1-p\right)^{n-k}\right]\\
 & =\left(1-p\right)^{n}\sum_{k=0}^{n}\left[g\left(k\right)\cdot\binom{n}{k}p^{k}\left(1-p\right)^{-k}\right]\\
 & =\left(1-p\right)^{n}\sum_{k=0}^{n}\left[g\left(k\right)\cdot\binom{n}{k}\left(\frac{p}{1-p}\right)^{k}\right].
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $p\in\left(0,1\right)$
\end_inset

, so that 
\begin_inset Formula $\left(1-p\right)^{n}>0$
\end_inset

 for all 
\begin_inset Formula $p$
\end_inset

.
 It follows that this expression will be equal to zero if and only if 
\begin_inset Formula 
\[
\sum_{k=0}^{n}\left[g\left(k\right)\cdot\binom{n}{k}\left(\frac{p}{1-p}\right)^{k}\right]=0.
\]

\end_inset

Let 
\begin_inset Formula $r=\left(p/\left(1-p\right)\right)$
\end_inset

.
 Then, this sum is a polynomial function of 
\begin_inset Formula $r$
\end_inset

, i.e., 
\begin_inset Formula 
\begin{flalign*}
\sum_{k=0}^{n}\left[g\left(k\right)\cdot\binom{n}{k}r^{k}\right] & =g\left(0\right)\cdot\binom{n}{0}r^{0}+\cdots+g\left(n\right)\cdot\binom{n}{n}r^{n}\\
 & =g\left(0\right)+g\left(1\right)\cdot nr^{1}+g\left(2\right)\binom{n}{2}r^{2}+\cdots+g\left(n-1\right)\cdot nr^{n-1}+g\left(n\right)r^{n}.
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $n>0$
\end_inset

 and 
\begin_inset Formula $r=p/\left(1-p\right)>0$
\end_inset

, so that for the 
\begin_inset Formula $k\mbox{th}$
\end_inset

 term, we will have 
\begin_inset Formula $\binom{n}{k}>0$
\end_inset

 and 
\begin_inset Formula $r^{k}>0$
\end_inset

.
 It follows that this sum is equal to zero if and only if 
\begin_inset Formula $g\left(k\right)=0$
\end_inset

 for 
\begin_inset Formula $k=\left\{ 0,1,\ldots,n\right\} $
\end_inset

.
 
\begin_inset Formula $T_{2}$
\end_inset

 takes on the values 
\begin_inset Formula $0,1,\ldots,n$
\end_inset

 with probability 1 (recall that 
\begin_inset Formula $T_{2}$
\end_inset

 represents the probability of 
\begin_inset Formula $k$
\end_inset

 successes in 
\begin_inset Formula $n$
\end_inset

trials), so that 
\begin_inset Formula $P\left(\left\{ g\left(T_{2}\right)=0\right\} \right)=1$
\end_inset

 for all 
\begin_inset Formula $p$
\end_inset

.
 It follows that 
\begin_inset Formula $T_{2}$
\end_inset

 is a complete statistic.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim\mbox{Poisson}\left(\lambda\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pmf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
p_{X}\left(x\right) & =\frac{e^{-\lambda}\lambda^{x}}{x!}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left\{ 0,1,2,\ldots\right\} $
\end_inset

 and 
\begin_inset Formula $p_{X}\left(x\right)=0$
\end_inset

 otherwise.
 Show that 
\begin_inset Formula $T\left(\mathbf{X}\right)=\sum_{i=1}^{n}X_{i}$
\end_inset

 is a complete statistic.
\end_layout

\begin_layout Example
It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:dist-of-sum-of-poisson-rv"

\end_inset

 that 
\begin_inset Formula $X_{1}+X_{2}\sim\mbox{Poisson}\left(\lambda+\lambda\right)=\mbox{Poisson}\left(2\lambda\right)$
\end_inset

, that 
\begin_inset Formula $\left(X_{1}+X_{2}\right)+X_{3}\sim\mbox{Poisson}\left(2\lambda+\lambda\right)=\mbox{Poisson}\left(3\lambda\right)$
\end_inset

, and therefore that 
\begin_inset Formula 
\[
T\left(\mathbf{X}\right)=\sum_{i=1}^{n}X_{i}\sim\mbox{Poisson}\left(n\lambda\right),
\]

\end_inset

so that the pmf of 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{T\left(\mathbf{X}\right)}\left(t\right) & =\frac{e^{-n\lambda}\left(n\lambda\right)^{t}}{t!}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $t\in\left\{ 0,1,2,\ldots\right\} $
\end_inset

 and 
\begin_inset Formula $p_{T\left(\mathbf{X}\right)}\left(t\right)=0$
\end_inset

 otherwise.
 Suppose that 
\begin_inset Formula $g\left(T\right)$
\end_inset

 is a function satisfying 
\begin_inset Formula $\mbox{E}\left[g\left(T\right)\right]=0$
\end_inset

, so that we have
\begin_inset Formula 
\begin{flalign*}
0 & =\mbox{E}\left[g\left(T\right)\right]\\
 & =\sum_{t=0}^{\infty}\left[g\left(t\right)\cdot\frac{e^{-n\lambda}\left(n\lambda\right)^{t}}{t!}\right]\\
 & =e^{-n\lambda}\sum_{t=0}^{\infty}g\left(t\right)\cdot\frac{\left(n\lambda\right)^{t}}{t!}.
\end{flalign*}

\end_inset

We will have 
\begin_inset Formula $e^{-n\lambda}>0$
\end_inset

 for all 
\begin_inset Formula $n$
\end_inset

 and all 
\begin_inset Formula $\lambda\geq0$
\end_inset

.
 It follows that this expression will be equal to zero if and only if
\begin_inset Formula 
\[
\sum_{t=0}^{\infty}g\left(t\right)\cdot\frac{\left(n\lambda\right)^{t}}{t!}=0.
\]

\end_inset

This sum is a polynomial function of 
\begin_inset Formula $\left(n\lambda\right)$
\end_inset

.
 For the sum to be equal to zero, the coefficient 
\begin_inset Formula $g\left(t\right)/t!$
\end_inset

 must be equal to zero for all 
\begin_inset Formula $t$
\end_inset

.
 Because 
\begin_inset Formula $t!\geq1$
\end_inset

, it follows that 
\begin_inset Formula $g\left(t\right)=0$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

.
 Thus, we have 
\begin_inset Formula 
\[
\mbox{E}\left[g\left(T\right)\right]=0\quad\forall\lambda\quad\Rightarrow\quad P\left(\left\{ g\left(T\right)=0\right\} \right)=1\quad\forall\lambda,
\]

\end_inset

so by definition 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a complete statistic.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim U\left(0,\theta\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pdf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x\right) & =\frac{1}{\theta}I_{\left\{ 0<x<\theta\right\} }.
\end{flalign*}

\end_inset

Show that 
\begin_inset Formula $T\left(\mathbf{X}\right)=X_{\left(n\right)}$
\end_inset

 is a complete statistic.
 (This is example 6.2.23 from Casella & Berger.)
\end_layout

\begin_layout Example
From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:suff-statistic-uniform"

\end_inset

, the cdf of 
\begin_inset Formula $X$
\end_inset

 is given by 
\begin_inset Formula $F_{X}\left(x\right)=x/\theta$
\end_inset

.
 From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:order-stat-continuous"

\end_inset

, the pdf of 
\begin_inset Formula $X_{\left(n\right)}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{X_{\left(n\right)}}\left(x\right) & =\frac{n!}{\left(n-1\right)!\left(n-n\right)!}f_{X}\left(x\right)\left[F_{X}\left(x\right)\right]^{n-1}\left[1-F_{X}\left(x\right)\right]^{n-n}\\
 & =\frac{n!}{\left(n-1\right)!0!}\left(\frac{1}{\theta}\right)\left(\frac{x}{\theta}\right)^{n-1}\left(1-\frac{x}{\theta}\right)^{0}I_{\left\{ 0<x<\theta\right\} }\\
 & =n\left(\frac{\left(n-1\right)!}{\left(n-1\right)!}\right)\left(\frac{1}{\theta}\right)\left(\frac{x^{n-1}}{\theta^{n-1}}\right)I_{\left\{ 0<x<\theta\right\} }\\
 & =\frac{nx^{n-1}}{\theta^{n}}I_{\left\{ 0<x<\theta\right\} }.
\end{flalign*}

\end_inset

Suppose 
\begin_inset Formula $g\left(T\right)$
\end_inset

 is a function satisfying 
\begin_inset Formula $\mbox{E}\left[g\left(T\right)\right]=0$
\end_inset

 for all 
\begin_inset Formula $\theta$
\end_inset

, so that we have
\begin_inset Formula 
\begin{flalign*}
0 & =\mbox{E}\left[g\left(T\right)\right]\\
 & =\int_{0}^{\theta}g\left(t\right)\cdot f_{X_{\left(n\right)}}\left(t\right)\mbox{d}t\\
 & =\int_{0}^{\theta}g\left(t\right)\cdot nt^{n-1}\theta^{-n}\mbox{d}t.
\end{flalign*}

\end_inset

By assumption, 
\begin_inset Formula $\mbox{E}\left[g\left(T\right)\right]=0$
\end_inset

, i.e., it is constant as a function of 
\begin_inset Formula $\theta$
\end_inset

, so that its derivative with respect to 
\begin_inset Formula $\theta$
\end_inset

 is zero.
 Then, we have
\begin_inset Formula 
\begin{flalign}
0 & =\frac{\mbox{d}}{\mbox{d}\theta}\left[\int_{0}^{\theta}g\left(t\right)\cdot nt^{n-1}\theta^{-n}\mbox{d}t\right]\\
 & =\frac{\mbox{d}}{\mbox{d}\theta}\left[n\theta^{-n}\int_{0}^{\theta}g\left(t\right)\cdot t^{n-1}\mbox{d}t\right]\\
 & =n\theta^{-n}\frac{\mbox{d}}{\mbox{d}\theta}\left[\int_{0}^{\theta}g\left(t\right)\cdot t^{n-1}\mbox{d}t\right]+\left(\frac{\mbox{d}}{\mbox{d}\theta}n\theta^{-n}\right)\int_{0}^{\theta}g\left(t\right)\cdot t^{n-1}\mbox{d}t\\
 & =n\theta^{-n}\left[g\left(\theta\right)\cdot\theta^{n-1}-g\left(0\right)\cdot0^{n-1}\right]+n\left(-n\theta^{-n-1}\right)\int_{0}^{\theta}g\left(t\right)\cdot t^{n-1}\mbox{d}t\\
 & =n\theta^{-1}g\left(\theta\right)+\left[-n\theta^{-1}\int_{0}^{\theta}g\left(t\right)\cdot nt^{n-1}\theta^{-n}\mbox{d}t\right]\\
 & =n\theta^{-1}g\left(\theta\right)+\left(-n\theta^{-1}\cdot0\right)\\
 & =n\theta^{-1}g\left(\theta\right).
\end{flalign}

\end_inset

(2) follows from algebra.
 (3) follows from the product rule for differentiation.
 (4) the first term follows from the Fundamental Theorem of Calculus.
 We rearrange terms in (5) so that (6) follows from our assumption that
 
\begin_inset Formula $\mbox{E}\left[g\left(T\right)\right]=0$
\end_inset

.
 (7) follows from algebra.
\end_layout

\begin_layout Example
We have 
\begin_inset Formula $n>0$
\end_inset

 and 
\begin_inset Formula $\theta>0,$
\end_inset

 so that 
\begin_inset Formula $\theta^{-1}>0$
\end_inset

.
 It follows that 
\begin_inset Formula $n\theta^{-1}g\left(\theta\right)$
\end_inset

 is equal to zero if and only if 
\begin_inset Formula $g\left(\theta\right)=0$
\end_inset

, which is true for for all 
\begin_inset Formula $\theta>0$
\end_inset

.
 Noting that we will always have 
\begin_inset Formula $T\left(\mathbf{X}\right)=X_{\left(n\right)}>0$
\end_inset

, it follows that 
\begin_inset Formula $P\left(\left\{ g\left(T\right)=0\right\} \right)=1$
\end_inset

, and thus that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a complete statistic.
\end_layout

\begin_layout Remark
The Fundamental Theorem of Calculus applies only to functions that are Riemann-i
ntegrable.
 Thus, the equation 
\begin_inset Formula 
\begin{flalign*}
\frac{\mbox{d}}{\mbox{d}\theta}\int_{0}^{\theta}g\left(t\right)\mbox{d}t & =g\left(\theta\right)
\end{flalign*}

\end_inset

is valid only at points of continuity of Riemann-integrable 
\begin_inset Formula $g$
\end_inset

.
 The condition of completeness applies to all functions, not just Riemann-integr
able ones, so the argument above does not, strictly speaking, show that
 
\begin_inset Formula $T$
\end_inset

 is a complete statistic.
 From a more practical view, though, this distinction is not of concern
 since the condition of Riemann-integrability is so general that it includes
 virtually any function we could think of.
\end_layout

\begin_layout Theorem
\begin_inset ERT
status open

\begin_layout Plain Layout

[Basu's Theorem]
\end_layout

\end_inset

If 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a complete and minimal sufficient statistic, then 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is independent of every ancillary statistic.
 (This is Theorem 6.2.24 from Casella & Berger.)
\begin_inset CommandInset label
LatexCommand label
name "thm:basu"

\end_inset


\end_layout

\begin_layout Proof
[proof goes here]
\end_layout

\begin_layout Standard
That is, if 
\begin_inset Formula $T$
\end_inset

 depends on some ancillary statistic and 
\begin_inset Formula $T$
\end_inset

 is minimal sufficient, then 
\begin_inset Formula $T$
\end_inset

 cannot be complete.
 Basu's Theorem allows us to deduce the independence of two statistics without
 finding their joint distribution.
 To use Basu's Theorem, we need to show that a statistic is complete.
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim\mbox{Exp}\left(\theta\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pdf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x|\theta\right) & =\theta e^{-\theta x}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\geq0$
\end_inset

, so that the joint pdf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\theta\right) & =\prod_{i=1}^{n}f_{X_{i}}\left(x_{i}|\theta\right)\\
 & =\prod_{i=1}^{n}\theta e^{-\theta x_{i}}\\
 & =\theta^{n}e^{\sum_{i=1}^{n}-\theta x_{i}}\\
 & =\theta^{n}e^{-\theta\sum_{i=1}^{n}x_{i}}.
\end{flalign*}

\end_inset

Show that 
\begin_inset Formula $T\left(\mathbf{X}\right)=\sum_{i=1}^{n}X_{i}$
\end_inset

 is independent of 
\begin_inset Formula $Y=X_{n}/\sum_{i=1}^{n}X_{i}$
\end_inset

.
\end_layout

\begin_layout Example
We showed in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:minimal-sufficient-exp-rv"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a minimal sufficient statistic for 
\begin_inset Formula $\theta$
\end_inset

.
 We can express 
\begin_inset Formula $f_{\mathbf{X}}\left(\mathbf{x}|\theta\right)$
\end_inset

 in exponential family form as
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\theta\right) & =\underbrace{\theta^{n}}_{c\left(\theta\right)}\exp\left\{ \underbrace{-\theta}_{\omega_{1}\left(\theta\right)}\underbrace{\sum_{i=1}^{n}x_{i}}_{t_{1}\left(\mathbf{x}\right)}\right\} 
\end{flalign*}

\end_inset

with 
\begin_inset Formula $h\left(\mathbf{x}\right)=1$
\end_inset

.
 The parameter space for this distribution is given by 
\begin_inset Formula $\left\{ \omega_{1}\left(\theta\right)=-\theta:\theta>0\right\} $
\end_inset

, i.e., 
\begin_inset Formula $k=1$
\end_inset

.
 The representation of this parameter space in 
\begin_inset Formula $\mathbb{R}^{1}$
\end_inset

 is the interval 
\begin_inset Formula $\left(-\infty,0\right)$
\end_inset

, which has positive length, i.e., it is an open set, so it follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:complete-stat-exp-family"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is complete.
\end_layout

\begin_layout Example
The cdf of 
\begin_inset Formula $Y$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
P\left(\left\{ Y\leq y\right\} \right) & =P\left(\left\{ \frac{X_{n}}{\sum_{i=1}^{n}X_{i}}\leq y\right\} \right).
\end{flalign*}

\end_inset

Let 
\begin_inset Formula $Z_{1},\ldots,Z_{n}$
\end_inset

 be iid observations from 
\begin_inset Formula $F_{Y}\left(y\right)$
\end_inset

 (corresponding to 
\begin_inset Formula $\theta=1$
\end_inset

) with 
\begin_inset Formula $X_{i}=\theta Z_{i}$
\end_inset

, so that we have
\begin_inset Formula 
\begin{flalign*}
P\left(\left\{ Y\leq y\right\} \right) & =P\left(\left\{ \frac{\theta Z_{n}}{\sum_{i=1}^{n}\theta Z_{i}}\leq y\right\} \right)\\
 & =P\left(\left\{ \frac{Z_{n}}{\sum_{i=1}^{n}Z_{i}}\leq y\right\} \right).
\end{flalign*}

\end_inset

This expression does not depend on 
\begin_inset Formula $\theta$
\end_inset

, so it follows that 
\begin_inset Formula $Y$
\end_inset

 is an ancillary statistic.
 Because 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a complete and minimal sufficient statistic, it follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:basu"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are independent.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim U\left(\theta,\theta+1\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid.
 Is 
\begin_inset Formula $T\left(\mathbf{X}\right)=\left(X_{\left(1\right)},X_{\left(n\right)}\right)$
\end_inset

 a complete statistic?
\end_layout

\begin_layout Example
Any one-to-one function of a minimal sufficient statistic is also minimal
 sufficient, so it follows that 
\begin_inset Formula $\left(X_{\left(1\right)},X_{\left(n\right)}-X_{\left(1\right)}\right)$
\end_inset

 is also minimal sufficient.
 We showed in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:ancillary-stat-uniform-range"

\end_inset

 that the range statistic 
\begin_inset Formula $R=X_{\left(n\right)}-X_{\left(1\right)}$
\end_inset

 is an ancillary statistic for a uniform random variable.
 (More generally, we have 
\begin_inset Formula $X\sim U\left(\theta,\theta+1\right)$
\end_inset

.
 Suppose that 
\begin_inset Formula $Z=U\left(0,1\right)$
\end_inset

, so that 
\begin_inset Formula $X=Z+\theta$
\end_inset

.
 It follows that 
\begin_inset Formula $X\sim U\left(\theta,\theta+1\right)$
\end_inset

 is a location family, and range is ancillary for a location family.) Thus,
 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 depends on an ancillary statistic, so it follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:basu"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is not complete.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
We showed in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:exp-family-normal"

\end_inset

 that the 
\begin_inset Formula $N\left(\mu,\sigma^{2}\right)$
\end_inset

 family is an exponential family, with 
\begin_inset Formula $\omega_{1}\left(\boldsymbol{\theta}\right)=1/\sigma^{2}$
\end_inset

 and 
\begin_inset Formula $\omega_{2}\left(\boldsymbol{\theta}\right)=\mu/\sigma^{2}$
\end_inset

.
 The parameter space for this family is given by 
\begin_inset Formula $\Theta=\left\{ \left(\mu,\sigma^{2}\right):-\infty<\mu<\infty,\sigma>0\right\} $
\end_inset

, i.e., 
\begin_inset Formula $k=2$
\end_inset

.
 The representation of this parameter space in 
\begin_inset Formula $\mathbb{R}^{2}$
\end_inset

 is the set 
\begin_inset Formula 
\[
\left\{ \left(1/\sigma^{2},\mu/\sigma^{2}\right):\left(\mu,\sigma\right)\in\Theta\right\} =\left\{ \left(x,y\right):x>0,-\infty<y<\infty\right\} ,
\]

\end_inset

which clearly contains an open set, e.g., the rectangle 
\begin_inset Formula $\left\{ \left(x,y\right):1<x<2,1<y<2\right\} $
\end_inset

.
 In 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:suff-stat-normal"

\end_inset

, we found that 
\begin_inset Formula $T\left(\mathbf{X}\right)=\left(\sum_{i=1}^{n}X_{i},\sum_{i=1}^{n}X_{i}^{2}\right)$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\boldsymbol{\theta}=\left(\mu,\sigma^{2}\right)$
\end_inset

.
 It follows from 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:complete-stat-exp-family"

\end_inset

 that 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a complete statistic.
\end_layout

\begin_layout Chapter
Point estimation
\end_layout

\begin_layout Standard
Many inferential problems fall into one of three types: point estimation,
 confidence estimation, or hypothesis testing.
 Point estimation refers to providing a single 
\begin_inset Quotes eld
\end_inset

best guess
\begin_inset Quotes erd
\end_inset

 of some quantity of interest, e.g., a model parameter, a cdf 
\begin_inset Formula $F$
\end_inset

, a pdf 
\begin_inset Formula $f$
\end_inset

, a regression function, a prediction for a future value 
\begin_inset Formula $Y$
\end_inset

 of a random variable.
\end_layout

\begin_layout Definition
A 
\shape italic
point estimator
\shape default
 is any function 
\begin_inset Formula $W\left(X_{1},\ldots,X_{n}\right)$
\end_inset

 of a sample; that is, any statistic 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 is a point estimator.
 An 
\shape italic
estimate
\shape default
 
\begin_inset Formula $T\left(\mathbf{x}\right)$
\end_inset

 is the observed value of an estimator 
\begin_inset Formula $T\left(\mathbf{X}\right)$
\end_inset

 (that is, a number) that is obtained when a sample is actually taken.
\end_layout

\begin_layout Standard
Often, we are interested in estimating some function 
\begin_inset Formula $T\left(\theta\right)$
\end_inset

, e.g., if 
\begin_inset Formula $X\sim N\left(\mu,\sigma^{2}\right)$
\end_inset

, then the parameter is 
\begin_inset Formula $\boldsymbol{\theta}=\left(\mu,\sigma^{2}\right)$
\end_inset

.
 If our goal is to estimate 
\begin_inset Formula $\mu$
\end_inset

, then 
\begin_inset Formula $\mu=T\left(\boldsymbol{\theta}\right)$
\end_inset

 is called the 
\shape italic
parameter of interest
\shape default
 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

 is called a 
\shape italic
nuisance parameter
\shape default
.
\end_layout

\begin_layout Section
Method of moments estimators
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X\sim f\left(x|\theta\right)$
\end_inset

.
 The 
\begin_inset Formula $r\mbox{th}$
\end_inset

 moment of 
\begin_inset Formula $X$
\end_inset

 is denoted 
\begin_inset Formula $\mu_{r}=\mbox{E}\left[X^{r}\right]$
\end_inset

.
 Note that 
\begin_inset Formula $\mu_{r}$
\end_inset

 is a function of 
\begin_inset Formula $\theta$
\end_inset

, e.g., 
\begin_inset Formula $\mbox{E}\left[X\right]=\mu_{1}$
\end_inset

, 
\begin_inset Formula $\mbox{E}\left[X^{2}\right]=\mu_{2}$
\end_inset

, 
\begin_inset Formula $\mbox{Var}\left(X\right)=\mu_{2}-\mu_{1}^{2}$
\end_inset

.
 A method of moments estimator for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is obtained by solving
\begin_inset Formula 
\begin{flalign*}
\hat{\mu}_{r} & =\sum_{i=1}^{n}\frac{X_{i}^{r}}{n}.
\end{flalign*}

\end_inset

Moment estimators are not invariant to transformation of the data (a function
 of 
\begin_inset Formula $x$
\end_inset

) or to reparameterization of 
\begin_inset Formula $\theta$
\end_inset

 (a function of 
\begin_inset Formula $\theta$
\end_inset

).
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim\mbox{Exp}\left(\theta\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid, i.e., each has the pdf of 
\begin_inset Formula $X$
\end_inset

, which is given by
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x|\theta\right) & =\theta e^{-\theta x}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\geq0$
\end_inset

.
 Find a moment estimator for 
\begin_inset Formula $\theta$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "exa:mom-exp-rv"

\end_inset


\end_layout

\begin_layout Example
We will find 
\begin_inset Formula $\hat{\mu}_{1}=\mbox{E}\left[X\right]$
\end_inset

.
\begin_inset Formula 
\begin{flalign*}
\hat{\mu}_{1} & =\mbox{E}\left[X\right]\\
 & =\int_{0}^{\infty}x\cdot\theta e^{-\theta x}\mbox{d}x\\
 & =\lim_{t\rightarrow\infty}\int_{0}^{t}x\cdot\theta e^{-\theta x}\mbox{d}x
\end{flalign*}

\end_inset

Let 
\begin_inset Formula $u=x$
\end_inset

 and 
\begin_inset Formula $v'=\theta e^{-\theta x}$
\end_inset

, so that 
\begin_inset Formula $u'=1$
\end_inset

 and 
\begin_inset Formula $v=-e^{-\theta x}$
\end_inset

.
 Then, we have
\begin_inset Formula 
\begin{flalign*}
\int_{0}^{t}uv'\mbox{d}x & =\left[uv\right|_{0}^{t}-\int_{0}^{t}vu'\mbox{d}x\\
 & =-xe^{-\theta x}\Big\rvert_{0}^{t}-\int_{0}^{t}-e^{-\theta x}\mbox{d}x\\
 & =\left(-te^{-\theta t}-0\right)-\left(\frac{1}{\theta}e^{-\theta x}\right|_{0}^{t}\\
 & =-te^{-\theta t}-\left(\frac{1}{\theta}e^{-\theta t}-\frac{1}{\theta}e^{0}\right)\\
 & =-te^{-\theta t}-\frac{1}{\theta}\left(e^{-\theta t}-1\right)
\end{flalign*}

\end_inset

so that 
\begin_inset Formula 
\begin{flalign*}
\hat{\mu}_{1} & =\lim_{t\rightarrow\infty}\left[-te^{-\theta t}-\frac{1}{\theta}\left(e^{-\theta t}-1\right)\right]\\
 & =0-\lim_{t\rightarrow\infty}\frac{1}{\theta}\left(e^{-\theta t}-1\right)\\
 & =-\frac{1}{\theta}\lim_{t\rightarrow\infty}\left(e^{-\theta t}-1\right)\\
 & =-\frac{1}{\theta}\left(0-1\right)\\
 & =\frac{1}{\theta}.
\end{flalign*}

\end_inset

Then, we have
\begin_inset Formula 
\begin{flalign*}
\hat{\mu}_{1} & =\frac{\sum_{i=1}^{n}X_{i}}{n}\\
\Leftrightarrow\frac{1}{\theta} & =\bar{x}\\
\Leftrightarrow\hat{\theta} & =\frac{1}{\bar{x}}.
\end{flalign*}

\end_inset


\end_layout

\begin_layout Remark
Had we used the parameterization 
\begin_inset Formula $f_{X}\left(x|\theta\right)=\left(1/\theta\right)e^{-x/\theta}$
\end_inset

, we would instead have found 
\begin_inset Formula $\hat{\theta}=\bar{x}$
\end_inset

.
\end_layout

\begin_layout Example
Suppose we have a population with 
\begin_inset Formula $\theta$
\end_inset

 members labeled 
\begin_inset Formula $1,\ldots,\theta$
\end_inset

 from which we sample 
\begin_inset Formula $n$
\end_inset

 observations with replacement and record their labels 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

.
 Find a moment estimator for 
\begin_inset Formula $\theta$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "exa:mom-sampling-replacement"

\end_inset


\end_layout

\begin_layout Example
We are (randomly) sampling with replacement, so an equal-likelihood model
 is appropriate.
 Then, it follows that the pmf of 
\begin_inset Formula $X_{i}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{X_{i}}\left(x_{i}|\theta\right) & =P\left(\left\{ X_{i}=x_{i}\right\} \right)\\
 & =\frac{1}{\theta}I_{\left\{ x_{i}\in\left\{ 1,\ldots,\theta\right\} \right\} },
\end{flalign*}

\end_inset

so that the joint pmf of 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
p_{\mathbf{X}}\left(\mathbf{x}|\theta\right) & =\prod_{i=1}^{n}\left[\frac{1}{\theta}I_{\left\{ x_{i}\in\left\{ 1,\ldots,\theta\right\} \right\} }\right]\\
 & =\frac{1}{\theta^{n}}I_{\left\{ x_{\left(1\right)\geq1}\right\} }I_{\left\{ x_{\left(n\right)}\leq\theta\right\} }.
\end{flalign*}

\end_inset

Then, we have
\begin_inset Formula 
\begin{flalign*}
\hat{\mu}_{1} & =\mbox{E}\left[X\right]\\
 & =\sum_{x=1}^{\theta}x\cdot p_{X}\left(x|\theta\right)\\
 & =\sum_{x=1}^{\theta}x\cdot\frac{1}{\theta}\\
 & =\frac{1}{\theta}\sum_{x=1}^{\theta}x\\
 & =\frac{1}{\theta}\left[1+2+\cdots+\left(\theta-1\right)+\theta\right]\\
 & =\frac{1}{\theta}\left(\frac{\theta\left(\theta+1\right)}{2}\right)\\
 & =\frac{\theta+1}{2}.
\end{flalign*}

\end_inset

We must solve 
\begin_inset Formula 
\begin{flalign*}
\hat{\mu}_{1} & =\frac{\sum_{i=1}^{n}X_{i}}{n}\\
\Leftrightarrow\frac{\hat{\theta}+1}{2} & =\bar{x}\\
\Leftrightarrow\hat{\theta}+1 & =2\bar{x}\\
\Leftrightarrow\hat{\theta} & =2\bar{x}-1.
\end{flalign*}

\end_inset


\end_layout

\begin_layout Remark
The technique used above to find the sum of the first 
\begin_inset Formula $n$
\end_inset

 numbers involves taking the sums of the respective extremes, e.g., 
\begin_inset Formula $1+n$
\end_inset

, 
\begin_inset Formula $2+\left(n-1\right)=1+n$
\end_inset

, 
\begin_inset Formula $3+\left(n-2\right)=1+n$
\end_inset

, and so on.
 There are 
\begin_inset Formula $n/2$
\end_inset

 such pairs, so it follows that the sum of the first 
\begin_inset Formula $n$
\end_inset

 numbers is given by
\begin_inset Formula 
\begin{flalign*}
\sum_{x=1}^{n}x & =\frac{n\left(n+1\right)}{2}.
\end{flalign*}

\end_inset


\end_layout

\begin_layout Example
Suppose
\begin_inset Formula 
\[
X_{1},\ldots,X_{n}\sim F\left(x|\alpha,\beta\right)=\begin{cases}
0, & x<0\\
\left(x/\beta\right)^{\alpha}, & 0\leq x\leq\beta\\
1 & x>\beta
\end{cases}.
\]

\end_inset

Find moment estimators for 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

.
 
\end_layout

\begin_layout Example
We must find estimators for two parameters, so we will need two equations,
 so we will take the first and second moments.
 The pdf of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x\right) & =\frac{\mbox{d}}{\mbox{d}x}F_{X}\\
 & =\frac{\mbox{d}}{\mbox{d}x}\left(\frac{x}{\beta}\right)^{\alpha}\\
 & =\alpha\left(\frac{x}{\beta}\right)^{\alpha-1}\left(\frac{1}{\beta}\right)\\
 & =\frac{\alpha}{\beta}\left(\frac{x^{\alpha-1}}{\beta^{\alpha-1}}\right)\\
 & =\frac{\alpha x^{\alpha-1}}{\beta^{\alpha}}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\in\left[0,\beta\right]$
\end_inset

 and 
\begin_inset Formula $f_{X}\left(x\right)=0$
\end_inset

 otherwise.
 Then, the first moment of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
\mbox{E}\left[X\right] & =\int_{0}^{\beta}x\cdot f_{X}\left(x\right)\mbox{d}x\\
 & =\int_{0}^{\beta}x\cdot\frac{\alpha x^{\alpha-1}}{\beta^{\alpha}}\mbox{d}x\\
 & =\frac{\alpha}{\beta^{\alpha}}\int_{0}^{\beta}x^{\alpha}\mbox{d}x\\
 & =\frac{\alpha}{\beta^{\alpha}}\left[\frac{1}{\alpha+1}x^{\alpha+1}\right|_{0}^{\beta}\\
 & =\frac{\alpha}{\beta^{\alpha}}\left(\frac{\beta^{\alpha+1}}{\alpha+1}-\frac{0}{\alpha+1}\right)\\
 & =\frac{\alpha\beta}{\alpha+1}
\end{flalign*}

\end_inset

and the second moment is given by
\begin_inset Formula 
\begin{flalign*}
\mbox{E}\left[X^{2}\right] & =\int_{0}^{\beta}x^{2}\cdot\frac{\alpha x^{\alpha-1}}{\beta^{\alpha}}\mbox{d}x\\
 & =\frac{\alpha}{\beta^{\alpha}}\int_{0}^{\beta}x^{\alpha+1}\mbox{d}x\\
 & =\frac{\alpha}{\beta^{\alpha}}\left[\frac{1}{\alpha+2}x^{\alpha+2}\right|_{0}^{\beta}\\
 & =\frac{\alpha}{\beta^{\alpha}}\left(\frac{\beta^{\alpha+2}}{\alpha+2}-\frac{0}{\alpha+2}\right)\\
 & =\frac{\alpha\beta^{2}}{\alpha+2}.
\end{flalign*}

\end_inset

We will solve the first equation for 
\begin_inset Formula $\hat{\beta}$
\end_inset

.
 
\begin_inset Formula 
\begin{flalign*}
\frac{\hat{\alpha}\hat{\beta}}{\hat{\alpha}+1} & =\frac{1}{n}\sum_{i=1}^{n}x_{i}\\
 & =\bar{x}\\
\Leftrightarrow\hat{\alpha}\hat{\beta} & =\bar{x}\left(\hat{a}+1\right)\\
\Leftrightarrow\hat{\beta} & =\frac{\bar{x}\left(\hat{\alpha}+1\right)}{\hat{\alpha}}
\end{flalign*}

\end_inset

We will solve the section equation for 
\begin_inset Formula $\hat{\alpha}$
\end_inset

.
\begin_inset Formula 
\begin{flalign*}
\frac{\hat{\alpha}\hat{\beta}^{2}}{\hat{\alpha}+2} & =\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}\\
\Leftrightarrow\hat{\alpha}\hat{\beta}^{2} & =\left(\hat{\alpha}+2\right)\left(\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}\right)\\
\Leftrightarrow\hat{\alpha}\left(\frac{\bar{x}\left(\hat{\alpha}+1\right)}{\hat{\alpha}}\right)^{2} & =\left(\hat{\alpha}+2\right)\left(\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}\right)\\
\Leftrightarrow\frac{\bar{x}^{2}\left(\hat{\alpha}+1\right)^{2}}{\hat{\alpha}} & =\left(\hat{\alpha}+2\right)\left(\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}\right)\\
\Leftrightarrow\frac{\left(\hat{\alpha}+1\right)^{2}}{\hat{\alpha}\left(\hat{\alpha}+2\right)} & =\frac{1}{n\bar{x}^{2}}\sum_{i=1}^{n}x_{i}^{2}
\end{flalign*}

\end_inset

Let 
\begin_inset Formula $c=\left(1/n\bar{x}^{2}\right)\sum_{i=1}^{n}x_{i}^{2}$
\end_inset

, so that
\begin_inset Formula 
\begin{flalign*}
\frac{\left(\hat{\alpha}+1\right)^{2}}{\hat{\alpha}\left(\hat{\alpha}+2\right)} & =c\\
\Leftrightarrow\hat{\alpha}^{2}+2\hat{\alpha}+1 & =c\hat{\alpha}\left(\hat{\alpha}+2\right)\\
\Leftrightarrow\hat{\alpha}^{2}+2\hat{\alpha}+1 & =c\hat{\alpha}^{2}+2c\hat{\alpha}\\
\Leftrightarrow\hat{\alpha}^{2}\left(1-c\right)+\hat{\alpha}\left(2-2c\right)+1 & =0.
\end{flalign*}

\end_inset

Then, the quadratic formula gives
\begin_inset Formula 
\begin{flalign*}
x & =\frac{-b\pm\sqrt{b^{2}-4ac}}{2a}\\
\hat{\alpha} & =\frac{-\left(2-2c\right)\pm\sqrt{\left(2-2c\right)^{2}-4\left(1-c\right)\cdot1}}{2\left(1-c\right)}\\
 & =\frac{2\left(c-1\right)\pm\sqrt{\left(2\left(1-c\right)\right)^{2}-4\left(1-c\right)}}{2\left(1-c\right)}\\
 & =\frac{2\left(c-1\right)\pm\sqrt{4\left(1-c\right)^{2}-4\left(1-c\right)}}{2\left(1-c\right)}\\
 & =\frac{2\left(c-1\right)\pm\sqrt{4\left(\left(1-c\right)^{2}-\left(1-c\right)\right)}}{2\left(1-c\right)}\\
 & =\frac{2\left(c-1\right)\pm2\sqrt{1-2c+c^{2}-1+c}}{2\left(1-c\right)}\\
 & =\frac{2\left(c-1\right)\pm2\sqrt{c^{2}-c}}{2\left(1-c\right)}\\
 & =\frac{c-1\pm\sqrt{c^{2}-c}}{1-c},
\end{flalign*}

\end_inset

so that 
\begin_inset Formula 
\begin{flalign*}
\hat{\beta} & =\frac{\bar{x}\left(\hat{\alpha}+1\right)}{\hat{\alpha}}\\
 & =\frac{\bar{x}\hat{\alpha}+\bar{x}}{\hat{\alpha}}\\
 & =\bar{x}+\frac{\bar{x}}{\frac{c-1\pm\sqrt{c^{2}-c}}{1-c}}\\
 & =\bar{x}\left(1+\frac{1-c}{c-1\pm\sqrt{c^{2}-c}}\right).
\end{flalign*}

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Standard
Method of moments estimators may not be uniquely defined, as can be seen
 in the following example.
\end_layout

\begin_layout Example
Suppose 
\begin_inset Formula $X_{1},\ldots,X_{n}\sim\mbox{Poisson}\left(\lambda\right)$
\end_inset

.
 Recall that 
\begin_inset Formula $\mbox{E}\left[X\right]=\mbox{Var}\left(X\right)=\lambda$
\end_inset

.
 Then, we have
\begin_inset Formula 
\begin{flalign*}
\mbox{E}\left[X\right] & =\hat{\mu}_{1}\\
 & =\frac{1}{n}\sum_{i=1}^{n}X_{i}\\
\Leftrightarrow\hat{\lambda} & =\bar{x}
\end{flalign*}

\end_inset

and
\begin_inset Formula 
\begin{flalign*}
\mbox{Var}\left(X\right) & =\mbox{E}\left[X^{2}\right]-\mbox{E}\left[X\right]^{2}\\
 & =\mbox{E}\left[X^{2}\right]-\bar{X}^{2}\\
 & =\mbox{E}\left[X^{2}\right]-2\bar{X}\bar{X}+\bar{X}^{2}\\
 & =\mbox{E}\left[X^{2}\right]-2\bar{X}\mbox{E}\left[X\right]+\bar{X}^{2}\\
 & =\mbox{E}\left[X^{2}\right]-\mbox{E}\left[2\bar{X}X\right]+\mbox{E}\left[\bar{X}^{2}\right]\\
 & =\mbox{E}\left[X^{2}-2\bar{X}X+\bar{X}^{2}\right]\\
 & =\mbox{E}\left[X-\bar{X}\right]^{2}\\
\Leftrightarrow\hat{\lambda} & =\hat{\mu}_{2}-\hat{\mu}_{1}^{2}\\
 & =\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}^{2}\right)-\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)^{2}\\
 & =\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}^{2}\right)-2\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)+\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)\left(\frac{1}{n}\sum_{i=1}^{n}X_{i}\right)\\
 & =\sum_{i=1}^{n}\frac{1}{n}X_{i}^{2}-\sum_{i=1}^{n}\frac{2\bar{X}}{n}X_{i}+\sum_{i=1}^{n}\frac{\bar{X}}{n}X_{i}\\
 & =\sum_{i=1}^{n}\left(\frac{1}{n}X_{i}^{2}-\frac{2\bar{X}}{n}X_{i}+\frac{\bar{X}}{n}X_{i}\right)\\
 & =\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}^{2}-2\bar{X}X_{i}+\bar{X}X_{i}\right)\\
 & =\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}^{2}-\bar{X}X_{i}\right)
\end{flalign*}

\end_inset


\end_layout

\begin_layout Standard
Standard method of moments may not work.
\end_layout

\begin_layout Example
Suppose 
\begin_inset Formula $X_{1},\ldots,X_{n}\sim f\left(x|\theta\right)=\theta x^{-2}$
\end_inset

, 
\begin_inset Formula $0<\theta\leq x<\infty$
\end_inset

.
 Then,
\begin_inset Formula 
\begin{flalign*}
\mbox{E}_{\theta}\left[X\right] & =\int_{\theta}^{\infty}x\frac{\theta}{x^{2}}\mbox{d}x\\
 & =\theta\int_{\theta}^{\infty}\frac{1}{x}\mbox{d}x\\
 & =\theta\lim_{c\rightarrow\infty}\int_{\theta}^{c}\frac{1}{x}\mbox{d}x\\
 & =\theta\lim_{c\rightarrow\infty}\left(\ln x\Big\rvert_{\theta}^{c}\right)\\
 & =\theta\lim_{c\rightarrow\infty}\left(\ln c-\ln\theta\right)\\
 & =\infty,
\end{flalign*}

\end_inset

so that 
\begin_inset Formula $\mu_{1}\left(\theta\right)=\hat{\mu}_{1}$
\end_inset

 has no solution.
 If we consider
\begin_inset Formula 
\begin{flalign*}
\mbox{E}_{\theta}\left[\frac{1}{X}\right] & =\int_{\theta}^{\infty}\frac{\theta}{x^{3}}\mbox{d}x\\
 & =\lim_{c\rightarrow\infty}\int_{\theta}^{c}\frac{\theta}{x^{3}}\mbox{d}x\\
 & =\lim_{c\rightarrow\infty}\left(-\theta\frac{1}{2x^{2}}\Bigr\rvert_{\theta}^{c}\right)\\
 & =\lim_{c\rightarrow\infty}\left(-\theta\frac{1}{2c^{2}}-\left(-\theta\frac{1}{2\theta^{2}}\right)\right)\\
 & =0+\frac{1}{2\theta}\\
 & =\frac{1}{2\theta},
\end{flalign*}

\end_inset

then setting 
\begin_inset Formula $u_{-1}\left(\theta\right)=\hat{\mu}_{-1}=\left(1/n\right)\sum_{i=1}^{n}1/X_{i}$
\end_inset

 gives
\begin_inset Formula 
\[
\frac{1}{2\hat{\theta}}=\frac{1}{n}\sum_{i=1}^{n}\frac{1}{X_{i}}\quad\Rightarrow\quad\hat{\theta}=\frac{n}{2\sum_{i=1}^{n}\frac{1}{X_{i}}}.
\]

\end_inset

If we consider instead
\begin_inset Formula 
\begin{flalign*}
\mbox{E}_{\theta}\left[X^{1/2}\right] & =\int_{\theta}^{\infty}x^{1/2}\frac{\theta}{x^{2}}\mbox{d}x\\
 & =\lim_{c\rightarrow\infty}\left[\theta\int_{\theta}^{c}x^{-3/2}\mbox{d}x\right]\\
 & =\lim_{c\rightarrow\infty}\left[\theta\left(-2x^{-1/2}\Bigr\rvert_{\theta}^{c}\right)\right]\\
 & =\lim_{c\rightarrow\infty}\left[\theta\left(-2c^{-1/2}-\left(-2\theta^{-1/2}\right)\right)\right]\\
 & =\theta\left(0+2\theta^{-1/2}\right)\\
 & =2\sqrt{\theta},
\end{flalign*}

\end_inset

then setting 
\begin_inset Formula $\mu_{1/2}\left(\theta\right)=\hat{\mu}_{1/2}$
\end_inset

 gives
\begin_inset Formula 
\[
2\sqrt{\theta}=\frac{1}{n}\sum_{i=1}^{n}X_{i}^{1/2}\quad\Rightarrow\quad\hat{\theta}=\frac{\left(\sum_{i=1}^{n}X_{i}^{1/2}\right)^{2}}{4n^{2}}.
\]

\end_inset


\end_layout

\begin_layout Section
Maximum likelihood estimators
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 are independent random variables from 
\begin_inset Formula $f_{i}\left(x|\theta_{1},\ldots,\theta_{k}\right)$
\end_inset

, then the likelihood function is given by
\begin_inset Formula 
\[
L\left(\theta|\mathbf{x}\right)=L\left(\theta_{1},\ldots,\theta_{k}|x_{1},\ldots,x_{n}\right)=\prod_{i=1}^{n}f_{i}\left(x_{i}|\theta_{1},\ldots,\theta_{k}\right)=f\left(\mathbf{x}|\theta\right),
\]

\end_inset

i.e., the likelihood function is just the joint density of the data, except
 that we treat it as a function of the parameter 
\begin_inset Formula $\theta$
\end_inset

.
 The likelihood function is not a density function, i.e., it does not integrate
 to 1.
 If 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is a discrete random vector, then 
\begin_inset Formula $L\left(\theta|\mathbf{x}\right)=P_{\theta}\left(\left\{ \mathbf{X}=\mathbf{x}\right\} \right)$
\end_inset

.
 If we compare the likelihood function at two parameter points and find
 that
\begin_inset Formula 
\[
P_{\theta_{1}}\left(\left\{ \mathbf{X}=\mathbf{x}\right\} \right)=L\left(\theta_{1}|\mathbf{x}\right)>L\left(\theta_{2}|\mathbf{x}\right)=P_{\theta_{2}}\left(\left\{ \mathbf{X}=\mathbf{x}\right\} \right),
\]

\end_inset

then the sample we actually observed is more likely to have occurred if
 
\begin_inset Formula $\theta=\theta_{1}$
\end_inset

 than if 
\begin_inset Formula $\theta=\theta_{2}$
\end_inset

, which can be interpreted as saying that 
\begin_inset Formula $\theta_{1}$
\end_inset

 is a more plausible value for the true value of 
\begin_inset Formula $\theta$
\end_inset

 than is 
\begin_inset Formula $\theta_{2}$
\end_inset

.
\end_layout

\begin_layout Definition
For each sample point 
\begin_inset Formula $\mathbf{x}$
\end_inset

, let 
\begin_inset Formula $\hat{\theta}\left(\mathbf{x}\right)$
\end_inset

 be a parameter value at which 
\begin_inset Formula $L\left(\theta|\mathbf{x}\right)$
\end_inset

 attains its maximum as a function of 
\begin_inset Formula $\theta$
\end_inset

, with 
\begin_inset Formula $\mathbf{x}$
\end_inset

 held fixed.
 A 
\shape italic
maximum likelihood estimator
\shape default
 (MLE) of the parameter 
\begin_inset Formula $\theta$
\end_inset

 based on a sample 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is 
\begin_inset Formula $\hat{\theta}\left(\mathbf{X}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
The MLE is the parameter point for which the observed sample is most likely.
 Let 
\begin_inset Formula $L\left(\hat{\theta}|X\right)$
\end_inset

 be the maximum of all likelihood functions evaluated at 
\begin_inset Formula $\theta$
\end_inset

, i.e.,
\begin_inset Formula 
\[
L\left(\hat{\theta}|X\right)=\max\left\{ L\left(\theta|X\right):\theta\in\Theta\right\} \Leftrightarrow\hat{\theta}\mbox{ is an MLE}.
\]

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

<<likelihood-generic, echo=FALSE, fig.height=2, fig.width=3, fig.align='center',
 fig.pos='h', fig.cap='maximizing the likelihood function'>>=
\end_layout

\begin_layout Plain Layout

x <- seq(0, 2, length = 1000)
\end_layout

\begin_layout Plain Layout

par(mgp = c(0.2,1,0), mar = c(1,2,0.1,2))
\end_layout

\begin_layout Plain Layout

plot(x, (-x^2)+2*x, type = "l", ylab = expression(paste("L(", lambda, ")")),
 xlab = expression(lambda), xaxt = "n", yaxt = "n", cex.lab = 0.75)
\end_layout

\begin_layout Plain Layout

points(x = 1, y = 1, pch = 19)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
If the likelihood is differentiable in 
\begin_inset Formula $\theta$
\end_inset

, possible candidates for 
\begin_inset Formula $\hat{\theta}$
\end_inset

 are those that solve
\begin_inset Formula 
\begin{flalign*}
\frac{\partial}{\partial\theta}\log L\left(\theta|X\right) & =0,
\end{flalign*}

\end_inset

which gives solutions that find interior extrema, some of which may be minima.
 To check whether a solution is a maximum, verify that 
\begin_inset Formula 
\begin{flalign*}
\dfrac{\partial^{2}}{\partial\theta^{2}}\log L\left(\theta|X\right) & <0,
\end{flalign*}

\end_inset

i.e., concave.
 It is often easier to work with 
\begin_inset Formula $\log L\left(\theta|X\right)$
\end_inset

 than with 
\begin_inset Formula $L\left(\theta|X\right)$
\end_inset

, and whatever maximizes the likelihood will also maximize log-likelihood.
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X\sim\mbox{Exp}\left(\lambda\right)$
\end_inset

, and let 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 be a random sample from the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the 
\begin_inset Formula $X_{i}\mbox{'s}$
\end_inset

 are iid.
 Find the MLE of 
\begin_inset Formula $\lambda$
\end_inset

 and compare it to the MOM estimator.
\end_layout

\begin_layout Example
The pdf of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x|\lambda\right) & =\frac{1}{\lambda}e^{-x/\lambda}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $x\geq0$
\end_inset

, so that the pdf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\lambda\right) & =\prod_{i=1}^{n}f_{X}\left(x_{i}|\lambda\right)\\
 & =\prod_{i=1}^{n}\frac{1}{\lambda}e^{-x_{i}/\lambda}\\
 & =\frac{1}{\lambda^{n}}e^{-\sum_{i=1}^{n}x_{i}/\lambda}.
\end{flalign*}

\end_inset

Then, we have 
\begin_inset Formula $L\left(\lambda|\mathbf{x}\right)=f_{\mathbf{X}}\left(\mathbf{x}|\lambda\right)$
\end_inset

, so that 
\begin_inset Formula 
\begin{flalign*}
\ln L\left(\lambda|\mathbf{x}\right) & =\ln\left(\frac{1}{\lambda^{n}}e^{-\sum_{i=1}^{n}x_{i}/\lambda}\right)\\
 & =\ln\left(\frac{1}{\lambda^{n}}\right)+\ln\left(e^{-\sum_{i=1}^{n}x_{i}/\lambda}\right)\\
 & =-n\ln\lambda-\frac{1}{\lambda}\sum_{i=1}^{n}x_{i}.
\end{flalign*}

\end_inset

We will take the derivative of 
\begin_inset Formula $\ln L\left(\lambda|\mathbf{x}\right)$
\end_inset

 with respect to 
\begin_inset Formula $\lambda$
\end_inset

.
\begin_inset Formula 
\begin{flalign*}
\frac{\partial}{\partial\lambda}\ln L\left(\lambda|\mathbf{x}\right) & =\frac{\partial}{\partial\lambda}\left[-n\ln\lambda-\frac{1}{\lambda}\sum_{i=1}^{n}x_{i}\right]\\
 & =-\frac{n}{\lambda}+\frac{1}{\lambda^{2}}\sum_{i=1}^{n}x_{i}.
\end{flalign*}

\end_inset

Setting this equal to zero, we have
\begin_inset Formula 
\begin{flalign*}
\frac{n}{\lambda} & =\frac{1}{\lambda^{2}}\sum_{i=1}^{n}x_{i}\\
\Leftrightarrow n\lambda^{2} & =\lambda\sum_{i=1}^{n}x_{i}\\
\Leftrightarrow\hat{\lambda} & =\frac{1}{n}\sum_{i=1}^{n}x_{i}\\
 & =\bar{x}.
\end{flalign*}

\end_inset

We will evaluate the second derivative of 
\begin_inset Formula $\ln L\left(\lambda|\mathbf{x}\right)$
\end_inset

 at 
\begin_inset Formula $\lambda=\hat{\lambda}$
\end_inset

 to verify that this is a maximum.
\begin_inset Formula 
\begin{flalign*}
\frac{\partial^{2}}{\partial\lambda^{2}}\ln L\left(\lambda|\mathbf{x}\right)\Bigr\rvert_{\lambda=\hat{\lambda}} & =\frac{\partial^{2}}{\partial\lambda^{2}}\left[-\frac{n}{\lambda}+\frac{1}{\lambda^{2}}\sum_{i=1}^{n}x_{i}\right|_{\lambda=\hat{\lambda}}\\
 & =\frac{n}{\lambda^{2}}-\frac{2}{\lambda^{3}}\sum_{i=1}^{n}x_{i}\Bigr\rvert_{\lambda=\hat{\lambda}}\\
 & =\frac{n}{\bar{x}^{2}}-\frac{2}{\bar{x}^{3}}\cdot n\bar{x}\\
 & =\frac{n}{\bar{x}^{2}}-\frac{2n}{\bar{x}^{2}}\\
 & =-\frac{n}{\bar{x}^{2}}
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $n>0$
\end_inset

 and 
\begin_inset Formula $\bar{x}^{2}>0$
\end_inset

, so it follows that 
\begin_inset Formula $-n/\bar{x}^{2}<0$
\end_inset

, therefore 
\begin_inset Formula $\hat{\lambda}=\bar{x}$
\end_inset

 is the MLE.
 In 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:mom-exp-rv"

\end_inset

, we found that 
\begin_inset Formula $\hat{\lambda}_{MOM}=\bar{x}$
\end_inset

, so the two estimators agree.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
Let's reconsider 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:mom-sampling-replacement"

\end_inset

, where we found that the pmf of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 was given by
\begin_inset Formula 
\[
p_{\mathbf{X}}\left(\mathbf{x}|\theta\right)=\frac{1}{\theta^{n}}I_{\left\{ x_{\left(1\right)\geq1}\right\} }I_{\left\{ x_{\left(n\right)}\leq\theta\right\} }.
\]

\end_inset

Find the MLE of 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Example
We have
\begin_inset Formula 
\[
L\left(\theta|\mathbf{x}\right)=\begin{cases}
\frac{1}{\theta^{n}}I_{\left\{ x_{\left(1\right)\geq1}\right\} }, & \theta\geq x_{\left(n\right)}\\
0, & \theta<x_{\left(n\right)}
\end{cases},
\]

\end_inset

whose graph is shown below.
 Clearly, the maximum value of 
\begin_inset Formula $L\left(\theta|\mathbf{x}\right)$
\end_inset

 occurs at 
\begin_inset Formula $x_{\left(n\right)}$
\end_inset

, so it follows that 
\begin_inset Formula $\hat{\theta}=X_{\left(n\right)}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<likelihood-sampling, echo=FALSE, fig.height=2, fig.width=3, fig.align='center',
 fig.pos='h'>>=
\end_layout

\begin_layout Plain Layout

par(mgp = c(1.5,0.5,0), mar = c(3,3,0.1,2))
\end_layout

\begin_layout Plain Layout

z <- seq(2, 4, length=2000) 
\end_layout

\begin_layout Plain Layout

plot(z, 1/(z^10), type="l", xlab = expression(theta), ylab=expression(paste(L,
 "(",theta,"|",bold(x),")")), yaxt="n", xaxt="n", xlim = c(1, 4), cex.lab
 = 0.75)
\end_layout

\begin_layout Plain Layout

axis(1, at=c(1,2), labels=c(expression(x[(1)]), expression(x[(n)])))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Remark*
When the support of the likelihood function depends on the parameter, it
 may not be necessary to take the derivative of 
\begin_inset Formula $L\left(\theta|\mathbf{x}\right)$
\end_inset

, e.g., the MLE may be found graphically.
\end_layout

\begin_layout Example
Suppose 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

 are sampled from a multinomial distribution with 3 categories and probabilities
, e.g., the genotypes 
\begin_inset Formula $AA$
\end_inset

, 
\begin_inset Formula $Aa$
\end_inset

, and 
\begin_inset Formula $aa$
\end_inset

, so that 
\begin_inset Formula $X_{i}$
\end_inset

 represents the category of the 
\begin_inset Formula $i\mbox{th}$
\end_inset

 observation.
 Suppose that the pmf of 
\begin_inset Formula $X_{i}$
\end_inset

 is given by 
\begin_inset Formula 
\begin{flalign*}
P\left(\left\{ X_{i}=1|\theta\right\} \right) & =\theta^{2}\\
P\left(\left\{ X_{i}=2|\theta\right\} \right) & =2\theta\left(1-\theta\right)\\
P\left(\left\{ X_{i}=3|\theta\right\} \right) & =\left(1-\theta\right)^{2}
\end{flalign*}

\end_inset

where 
\begin_inset Formula $\theta\in\left(0,1\right)$
\end_inset

.
 We observe 
\begin_inset Formula $n_{k}=\sum_{i=1}^{n}I_{\left\{ X_{i}=k\right\} }$
\end_inset

 individuals of type 
\begin_inset Formula $k\in\left\{ 1,2,3\right\} $
\end_inset

.
 Find the MLE of 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Example
Note that the pmf specified for 
\begin_inset Formula $X_{i}$
\end_inset

 is legitimate, i.e., is it non-negative and
\begin_inset Formula 
\[
\theta^{2}+2\theta\left(1-\theta\right)+\left(1-\theta\right)^{2}=\theta^{2}+2\theta-2\theta^{2}+1-2\theta+\theta^{2}=1.
\]

\end_inset

 We can write the pmf as
\begin_inset Formula 
\begin{flalign*}
p_{X_{i}}\left(x_{i}|\theta\right) & =\left(\theta^{2}\right)^{I_{\left\{ x_{i}=1\right\} }}\left[2\theta\left(1-\theta\right)\right]^{I_{\left\{ x_{i}=2\right\} }}\left[\left(1-\theta\right)^{2}\right]^{I_{\left\{ x_{i}=3\right\} }}
\end{flalign*}

\end_inset

where each 
\begin_inset Formula $I_{\left\{ x_{i}=k\right\} }$
\end_inset

 is equal to 0 or 1.
 Then, the joint pmf of 
\begin_inset Formula $\mathbf{X}=X_{i},\ldots,X_{n}$
\end_inset

 is given by 
\begin_inset Formula 
\begin{flalign*}
p_{\mathbf{X}}\left(\mathbf{x}|\theta\right) & =\prod_{i=1}^{n}p_{X_{i}}\left(x_{i}|\theta\right)\\
 & =\prod_{i=1}^{n}\left(\theta^{2}\right)^{I_{\left\{ x_{i}=1\right\} }}\left[2\theta\left(1-\theta\right)\right]^{I_{\left\{ x_{i}=2\right\} }}\left[\left(1-\theta\right)^{2}\right]^{I_{\left\{ x_{i}=3\right\} }}\\
 & =\left(\theta^{2}\right)^{\sum_{i=1}^{n}I_{\left\{ x_{i}=1\right\} }}\left[2\theta\left(1-\theta\right)\right]^{\sum_{i=1}^{n}I_{\left\{ x_{i}=2\right\} }}\left[\left(1-\theta\right)^{2}\right]^{\sum_{i=1}^{n}I_{\left\{ x_{i}=3\right\} }}
\end{flalign*}

\end_inset

so that the likelihood function is given by 
\begin_inset Formula 
\begin{flalign*}
L\left(\theta|\mathbf{x}\right) & =p_{\mathbf{X}}\left(\mathbf{x}|\theta\right)\\
 & =\left(\theta^{2}\right)^{\sum_{i=1}^{n}I_{\left\{ x_{i}=1\right\} }}\left[2\theta\left(1-\theta\right)\right]^{\sum_{i=1}^{n}I_{\left\{ x_{i}=2\right\} }}\left[\left(1-\theta\right)^{2}\right]^{\sum_{i=1}^{n}I_{\left\{ x_{i}=3\right\} }}\\
 & =\left(\theta^{2}\right)^{n_{1}}\left[2\theta\left(1-\theta\right)\right]^{n_{2}}\left[\left(1-\theta\right)^{2}\right]^{n_{3}}\\
 & =\theta^{2n_{1}}\left[2\theta\left(1-\theta\right)\right]^{n_{2}}\left(1-\theta\right)^{2n_{3}}\\
 & =2^{n_{2}}\theta^{2n_{1}+n_{2}}\left(1-\theta\right)^{n_{2}+2n_{3}}\\
\Leftrightarrow\ln L\left(\theta|\mathbf{x}\right) & =\ln\left[2^{n_{2}}\theta^{2n_{1}+n_{2}}\left(1-\theta\right)^{n_{2}+2n_{3}}\right]\\
 & =\ln2^{n_{2}}+\ln\theta^{2n_{1}+n_{2}}+\ln\left(1-\theta\right)^{n_{2}+2n_{3}}\\
 & =n_{2}\ln2+\left(2n_{1}+n_{2}\right)\ln\theta+\left(n_{2}+2n_{3}\right)\ln\left(1-\theta\right).
\end{flalign*}

\end_inset

We will take the derivative of the log-likelihood with respect to 
\begin_inset Formula $\theta$
\end_inset

.
\begin_inset Formula 
\begin{flalign*}
\frac{\partial}{\partial\theta}\ln L\left(\theta|\mathbf{x}\right) & =\frac{\partial}{\partial\theta}\left[n_{2}\ln2+\left(2n_{1}+n_{2}\right)\ln\theta+\left(n_{2}+2n_{3}\right)\ln\left(1-\theta\right)\right]\\
 & =0+\frac{2n_{1}+n_{2}}{\theta}+\frac{n_{2}+2n_{3}}{1-\theta}\cdot-1\\
 & =\frac{2n_{1}+n_{2}}{\theta}-\frac{n_{2}+2n_{3}}{1-\theta}
\end{flalign*}

\end_inset

Setting this equal to zero, we have
\begin_inset Formula 
\begin{flalign*}
\frac{2n_{1}+n_{2}}{\theta}-\frac{n_{2}+2n_{3}}{1-\theta} & =0\\
\Leftrightarrow\frac{n_{2}+2n_{3}}{1-\theta} & =\frac{2n_{1}+n_{2}}{\theta}\\
\Leftrightarrow\theta\left(n_{2}+2n_{3}\right) & =\left(1-\theta\right)\left(2n_{1}+n_{2}\right)\\
\Leftrightarrow\frac{1-\theta}{\theta} & =\frac{n_{2}+2n_{3}}{2n_{1}+n_{2}}\\
\Leftrightarrow\frac{1}{\theta}-1 & =\frac{n_{2}+2n_{3}}{2n_{1}+n_{2}}\\
\Leftrightarrow\frac{1}{\theta} & =\frac{n_{2}+2n_{3}}{2n_{1}+n_{2}}+1\\
 & =\frac{n_{2}+2n_{3}+2n_{1}+n_{2}}{2n_{1}+n_{2}}\\
 & =\frac{2\left(n_{1}+n_{2}+n_{3}\right)}{2n_{1}+n_{2}}\\
 & =\frac{2n}{2n_{1}+n_{2}}\\
\Leftrightarrow\hat{\theta} & =\frac{2n_{1}+n_{2}}{2n}.
\end{flalign*}

\end_inset

We will evaluate the second derivative of the log-likelihood at 
\begin_inset Formula $\theta=\hat{\theta}$
\end_inset

 to verify that 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is a maximum.
\begin_inset Formula 
\begin{flalign*}
\frac{\partial^{2}}{\partial\theta^{2}}\ln L\left(\theta|\mathbf{x}\right)\Bigr\rvert_{\theta=\hat{\theta}} & =\frac{\partial}{\partial\theta}\left[\frac{2n_{1}+n_{2}}{\theta}-\frac{n_{2}-2n_{3}}{1-\theta}\right|_{\theta=\hat{\theta}}\\
 & =-\frac{2n_{1}+n_{2}}{\theta^{2}}-\left(\frac{n_{2}-2n_{3}}{\left(1-\theta\right)^{2}}\cdot-1\cdot-1\right)\\
 & =-\frac{2n_{1}+n_{2}}{\theta^{2}}-\frac{n_{2}-2n_{3}}{\left(1-\theta\right)^{2}}\\
 & =-\left[\frac{2n_{1}+n_{2}}{\theta^{2}}+\frac{n_{2}-2n_{3}}{\left(1-\theta\right)^{2}}\right]
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $n_{k}\geq0$
\end_inset

 and 
\begin_inset Formula $n>0$
\end_inset

, i.e., at least one of 
\begin_inset Formula $n_{k}$
\end_inset

 is positive, and we have 
\begin_inset Formula $\theta^{2}>0$
\end_inset

 and 
\begin_inset Formula $\left(1-\theta\right)^{2}>0$
\end_inset

, so that the sum above is positive, so that the expression above is negative.
 It follows that 
\begin_inset Formula $\hat{\theta}=\left(2n_{1}+n_{2}\right)/2n$
\end_inset

 is the MLE.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X_{1},\ldots,X_{n}\stackrel{\mbox{iid}}{\sim}\mbox{Poisson}\left(\lambda\right)$
\end_inset

, where 
\begin_inset Formula $\lambda>0$
\end_inset

.
 Find the MLE of 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Example
In 
\begin_inset CommandInset ref
LatexCommand formatted
reference "exa:suff-stat-poisson"

\end_inset

, we found that the joint pmf of 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 was given by
\begin_inset Formula 
\begin{flalign*}
p_{\mathbf{X}}\left(\mathbf{x}|\lambda\right) & =\left(\prod_{i=1}^{n}\frac{1}{x_{i}!}\right)e^{-n\lambda}\lambda^{\sum_{i=1}^{n}x_{i}},
\end{flalign*}

\end_inset

so that the log-likelihood is given by
\begin_inset Formula 
\begin{flalign*}
\ln L\left(\lambda|\mathbf{x}\right) & =\ln\left[\left(\prod_{i=1}^{n}\frac{1}{x_{i}!}\right)e^{-n\lambda}\lambda^{\sum_{i=1}^{n}x_{i}}\right]\\
 & =\ln\left(\prod_{i=1}^{n}\frac{1}{x_{i}!}\right)+\ln e^{-n\lambda}+\ln\lambda^{\sum_{i=1}^{n}x_{i}}\\
 & =\left(\ln\frac{1}{x_{1}!}+\cdots+\ln\frac{1}{x_{n}!}\right)-n\lambda+\left(\sum_{i=1}^{n}x_{i}\right)\ln\lambda\\
 & =\left[\left(\ln1-\ln x_{1}!\right)+\cdots+\left(\ln1-\ln x_{n}!\right)\right]-n\lambda+\left(\sum_{i=1}^{n}x_{i}\right)\ln\lambda\\
 & =\left[\left(0-\ln x_{1}!\right)+\cdots+\left(0-\ln x_{n}!\right)\right]-n\lambda+\ln\lambda\left(\sum_{i=1}^{n}x_{i}\right)\\
 & =\sum_{i=1}^{n}-\ln x_{i}!-n\lambda+\ln\lambda\left(\sum_{i=1}^{n}x_{i}\right)\\
 & =-n\lambda+\ln\lambda\left(\sum_{i=1}^{n}x_{i}\right)-\sum_{i=1}^{n}\ln x_{i}!.
\end{flalign*}

\end_inset

We will take the derivative of the log-likelihood with respect to 
\begin_inset Formula $\lambda$
\end_inset

.
\begin_inset Formula 
\begin{flalign*}
\frac{\partial}{\partial\lambda}\ln L\left(\lambda|\mathbf{x}\right) & =\frac{\partial}{\partial\lambda}\left[-n\lambda+\ln\lambda\left(\sum_{i=1}^{n}x_{i}\right)-\sum_{i=1}^{n}\ln x_{i}!\right]\\
 & =-n+\frac{1}{\lambda}\sum_{i=1}^{n}x_{i}
\end{flalign*}

\end_inset

Setting this equal to zero, we have
\begin_inset Formula 
\begin{flalign*}
-n+\frac{1}{\lambda}\sum_{i=1}^{n}x_{i} & =0\\
\Leftrightarrow\frac{1}{\lambda}\sum_{i=1}^{n}x_{i} & =n\\
\Leftrightarrow\hat{\lambda} & =\frac{1}{n}\sum_{i=1}^{n}x_{i}\\
 & =\bar{x}.
\end{flalign*}

\end_inset

We will evaluate the second derivative of the log-likelihood at 
\begin_inset Formula $\lambda=\hat{\lambda}$
\end_inset

 to verify that 
\begin_inset Formula $\hat{\lambda}$
\end_inset

 is a maximum.
\begin_inset Formula 
\begin{flalign*}
\frac{\partial^{2}}{\partial\lambda^{2}}\ln L\left(\lambda|\mathbf{x}\right)\Bigr\rvert_{\lambda=\hat{\lambda}} & =\frac{\partial}{\partial\lambda}\left[-n+\frac{1}{\lambda}\sum_{i=1}^{n}x_{i}\right|_{\lambda=\hat{\lambda}}\\
 & =-\frac{1}{\lambda^{2}}\sum_{i=1}^{n}x_{i}\Bigr\rvert_{\lambda=\hat{\lambda}}\\
 & =-\frac{1}{\bar{x}^{2}}\sum_{i=1}^{n}x_{i}\\
 & =-\frac{1}{\bar{x}^{2}}n\bar{x}\\
 & =-\frac{n}{\bar{x}}
\end{flalign*}

\end_inset

We have 
\begin_inset Formula $n>0$
\end_inset

 and 
\begin_inset Formula $\bar{x}\geq0$
\end_inset

 (because the 
\begin_inset Formula $x_{i}\mbox{'s}$
\end_inset

 are each non-negative), so that 
\begin_inset Formula $-n/\bar{x}<0$
\end_inset

 (assuming that 
\begin_inset Formula $\bar{x}>0$
\end_inset

).
 It follows that 
\begin_inset Formula $\hat{\lambda}=\bar{x}$
\end_inset

 is the MLE.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X_{1},\ldots,X_{n}\stackrel{\mbox{iid}}{\sim}U\left(\theta-\frac{1}{2},\theta+\frac{1}{2}\right)$
\end_inset

.
 Find the MLE of 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Example
The pdf of 
\begin_inset Formula $X_{i}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{X_{i}}\left(x_{i}\right) & =\frac{1}{\left(\theta+\frac{1}{2}\right)-\left(\theta-\frac{1}{2}\right)}I_{\left\{ \theta-\frac{1}{2}<x_{i}<\theta+\frac{1}{2}\right\} }\\
 & =\frac{1}{1}I_{\left\{ \theta-\frac{1}{2}<x_{i}<\theta+\frac{1}{2}\right\} }\\
 & =I_{\left\{ \theta-\frac{1}{2}<x_{i}<\theta+\frac{1}{2}\right\} },
\end{flalign*}

\end_inset

so that the joint pdf of 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\theta\right) & =\prod_{i=1}^{n}I_{\left\{ \theta-\frac{1}{2}<x_{i}<\theta+\frac{1}{2}\right\} }\\
 & =I_{\left\{ \theta-\frac{1}{2}<x_{1}<\theta+\frac{1}{2}\right\} }\cdot\ldots\cdot I_{\left\{ \theta-\frac{1}{2}<x_{n}<\theta+\frac{1}{2}\right\} }\\
 & =I_{\left\{ x_{\left(1\right)}>\theta-\frac{1}{2}\right\} }I_{\left\{ x_{\left(n\right)}<\theta+\frac{1}{2}\right\} }.
\end{flalign*}

\end_inset

Then, the likelihood function is given by 
\begin_inset Formula 
\begin{flalign*}
L\left(\theta|\mathbf{x}\right) & =\begin{cases}
1, & x_{\left(n\right)}-\frac{1}{2}<\theta<x_{\left(1\right)}+\frac{1}{2}\\
0, & \mbox{otherwise}
\end{cases},
\end{flalign*}

\end_inset

and its graph is shown below.
 Clearly, 
\begin_inset Formula $L\left(\theta|\mathbf{x}\right)$
\end_inset

 is constant between 
\begin_inset Formula $x_{\left(n\right)}-\frac{1}{2}$
\end_inset

 and 
\begin_inset Formula $x_{\left(1\right)}+\frac{1}{2}$
\end_inset

 and 0 elsewhere, so that the MLE 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is given by any point in the interval 
\begin_inset Formula $\left(x_{\left(n\right)}-\frac{1}{2},x_{\left(1\right)}+\frac{1}{2}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<likelihood-uniform, echo=FALSE, fig.height=2, fig.width=3, fig.align='center',
 fig.pos='h'>>=
\end_layout

\begin_layout Plain Layout

par(mgp = c(1.5,1,0), mar = c(3,3,0.1,2))
\end_layout

\begin_layout Plain Layout

z <- seq(1, 2, length=1000) 
\end_layout

\begin_layout Plain Layout

plot(z, rep(1,1000), type="l", xlab = expression(theta), ylab=expression(paste(L
, "(",theta,"|",bold(x),")")), yaxt="n", xaxt="n", xlim = c(0, 3), cex.lab
 = 0.75)
\end_layout

\begin_layout Plain Layout

axis(1, at=c(1,2), labels=c(expression(x[(n)]-frac(1,2)), expression(x[(1)]+frac
(1,2))), cex.axis=0.75)
\end_layout

\begin_layout Plain Layout

axis(2, at=1, labels=1, cex.axis=0.75, las=2)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X_{1},\ldots X_{n}\stackrel{\mbox{iid}}{\sim}f\left(x|\theta\right)=\theta/x^{2}$
\end_inset

, 
\begin_inset Formula $0<\theta\leq x<\infty$
\end_inset

.
 Find the MLE of 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Example
The support of 
\begin_inset Formula $X$
\end_inset

 depends on the parameter 
\begin_inset Formula $\theta$
\end_inset

, so we will rewrite the pdf of 
\begin_inset Formula $X$
\end_inset

 as
\begin_inset Formula 
\begin{flalign*}
f_{X}\left(x|\theta\right) & =\frac{\theta}{x^{2}}I_{\left\{ x\geq\theta\right\} }.
\end{flalign*}

\end_inset

Then, the joint pdf of 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\theta\right) & =\prod_{i=1}^{n}f_{X_{i}}\left(x_{i}|\theta\right)\\
 & =\prod_{i=1}^{n}\frac{\theta}{x_{i}^{2}}I_{\left\{ x_{i}\geq\theta\right\} }\\
 & =\frac{\theta^{n}}{\prod_{i=1}^{n}x_{i}^{2}}I_{\left\{ x_{\left(1\right)}\geq\theta\right\} },
\end{flalign*}

\end_inset

so that the likelihood function is given by
\begin_inset Formula 
\begin{flalign*}
L\left(\theta|\mathbf{x}\right) & =\begin{cases}
\theta^{n}/\prod_{i=1}^{n}x_{i}^{2}, & \theta\leq x_{\left(1\right)}\\
0, & \theta>x_{\left(1\right)}
\end{cases}.
\end{flalign*}

\end_inset

The graph of the likelihood function is shown below.
 Clearly, the maximum value of 
\begin_inset Formula $L\left(\theta|\mathbf{x}\right)$
\end_inset

 occurs at 
\begin_inset Formula $x_{\left(1\right)}$
\end_inset

, so it follows that 
\begin_inset Formula $\hat{\theta}=X_{\left(1\right)}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=2, fig.width=3, fig.align='center', fig.pos='h'>>=
\end_layout

\begin_layout Plain Layout

par(mgp = c(1.5,0.5,0), mar = c(3,3,0.1,2))
\end_layout

\begin_layout Plain Layout

z <- seq(0, 1, length=1000) 
\end_layout

\begin_layout Plain Layout

plot(z, z^3, type="l", xlab = expression(theta), ylab=expression(paste(L,
 "(",theta,"|",bold(x),")")), yaxt="n", xaxt="n", xlim = c(0, 2), cex.lab
 = 0.75)
\end_layout

\begin_layout Plain Layout

axis(1, at = 1, labels = expression(x[(1)]), cex.axis=0.75)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X_{1},\ldots,X_{n}\stackrel{\mbox{iid}}{\sim}U\left(\mu-\sqrt{3}\sigma,\mu+\sqrt{3}\sigma\right)$
\end_inset

.
 Find the MLEs of 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

.
\end_layout

\begin_layout Example
The pdf of 
\begin_inset Formula $X_{i}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{X_{i}}\left(x_{i}|\mu,\sigma\right) & =\frac{1}{\left(\mu+\sqrt{3}\sigma\right)-\left(\mu-\sqrt{3}\sigma\right)}I_{\left\{ \mu-\sqrt{3}\sigma<x_{i}<\mu+\sqrt{3}\sigma\right\} }\\
 & =\frac{1}{2\sqrt{3}\sigma}I_{\left\{ \mu-\sqrt{3}\sigma<x_{i}<\mu+\sqrt{3}\sigma\right\} },
\end{flalign*}

\end_inset

so that the joint pdf of 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 is given by 
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\mu,\sigma\right) & =\prod_{i=1}^{n}f_{X_{i}}\left(x_{i}|\mu,\sigma\right)\\
 & =\prod_{i=1}^{n}\frac{1}{2\sqrt{3}\sigma}I_{\left\{ \mu-\sqrt{3}\sigma<x_{i}<\mu+\sqrt{3}\sigma\right\} }\\
 & =\left(2\sqrt{3}\sigma\right)^{-n}I_{\left\{ x_{\left(1\right)}>\mu-\sqrt{3}\sigma\right\} }I_{\left\{ x_{\left(n\right)}<\mu+\sqrt{3}\sigma\right\} }.
\end{flalign*}

\end_inset

To maximize 
\begin_inset Formula $L$
\end_inset

, we note that 
\begin_inset Formula $\left(2\sqrt{3}\sigma\right)^{-n}$
\end_inset

 increases as 
\begin_inset Formula $\sigma$
\end_inset

 decreases.
 Thus, we must find the minimum value of 
\begin_inset Formula $\sigma$
\end_inset

 such that 
\begin_inset Formula $L$
\end_inset

 is positive, which is true when 
\begin_inset Formula $\sigma>\left(\mu-x_{\left(1\right)}\right)/\sqrt{3}$
\end_inset

 and 
\begin_inset Formula $\sigma>\left(x_{\left(n\right)}-\mu\right)/\sqrt{3}$
\end_inset

.
 In the graph below, the region of positivity of 
\begin_inset Formula $L$
\end_inset

 is shaded.
 The minimum value of 
\begin_inset Formula $\sigma$
\end_inset

 such that 
\begin_inset Formula $L$
\end_inset

 is positive occurs precisely when the two lines intersect, i.e., when
\begin_inset Formula 
\begin{flalign*}
\frac{\mu-x_{\left(1\right)}}{\sqrt{3}} & =\frac{x_{\left(n\right)}-\mu}{\sqrt{3}}\\
\Leftrightarrow\mu-x_{\left(1\right)} & =x_{\left(n\right)}-\mu\\
\Leftrightarrow2\mu & =x_{\left(n\right)}+x_{\left(1\right)}\\
\Leftrightarrow\hat{\mu} & =\frac{x_{\left(n\right)}+x_{\left(1\right)}}{2}.
\end{flalign*}

\end_inset

We substitute into one of the line equations to find 
\begin_inset Formula $\hat{\sigma}$
\end_inset

.
\begin_inset Formula 
\begin{flalign*}
\hat{\sigma} & =\frac{\hat{\mu}-x_{\left(1\right)}}{\sqrt{3}}\\
 & =\frac{\frac{1}{2}\left(x_{\left(n\right)}+x_{\left(1\right)}\right)-x_{\left(1\right)}}{\sqrt{3}}\\
 & =\frac{x_{\left(n\right)}+x_{\left(1\right)}-2x_{\left(1\right)}}{2\sqrt{3}}\\
 & =\frac{x_{\left(n\right)}-x_{\left(1\right)}}{2\sqrt{3}}
\end{flalign*}

\end_inset

Thus, the MLEs for 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 are given by 
\begin_inset Formula $\hat{\mu}=\left(x_{\left(n\right)}+x_{\left(1\right)}\right)/2$
\end_inset

 and 
\begin_inset Formula $\hat{\sigma}=\left(x_{\left(n\right)}-x_{\left(1\right)}\right)/2\sqrt{3}$
\end_inset

, respectively.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=2, fig.width=3.5, fig.align='center', fig.pos='h'>>=
\end_layout

\begin_layout Plain Layout

par(mgp = c(1.5,0.5,0), mar = c(3,4,0.1,4))
\end_layout

\begin_layout Plain Layout

z <- seq(-1, 3, length=2000) 
\end_layout

\begin_layout Plain Layout

# set yaxs="i" to remove the default 4% padding beyond the ylim
\end_layout

\begin_layout Plain Layout

plot(z, (2-z)/sqrt(3), type = "l", xlab = expression(mu), ylab = expression(sigm
a), yaxt = "n", xaxt = "n", yaxs = "i", xlim = c(0, 3), ylim = c(0,1.5),
 cex.lab = 0.75)
\end_layout

\begin_layout Plain Layout

lines(z, (z-1)/sqrt(3), type="l")
\end_layout

\begin_layout Plain Layout

polygon(c(-1, 1.5, 4), c(3/sqrt(3), 1/(2*sqrt(3)), 3/sqrt(3)), density=20,
 angle=0)
\end_layout

\begin_layout Plain Layout

axis(1, at = c(1,2), labels = c(expression(x[(1)]), expression(x[(n)])),
 cex.axis=0.75)
\end_layout

\begin_layout Plain Layout

# use las to rotate the strings and padj to move them along the axis
\end_layout

\begin_layout Plain Layout

mtext(expression(sigma == frac(mu-x[(1)], sqrt(3))), side=4, line=0.5, las=2,
 padj=-1, cex=0.75)
\end_layout

\begin_layout Plain Layout

mtext(expression(sigma == frac(x[(n)]-mu, sqrt(3))), side=2, line=0.5, las=2,
 padj=-1, cex=0.75)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Example
Supose that 
\begin_inset Formula $X_{i}$
\end_inset

 and 
\begin_inset Formula $Y_{i}$
\end_inset

 are independent for 
\begin_inset Formula $i=1,\ldots,n$
\end_inset

, where 
\begin_inset Formula $X_{i}\sim f\left(x|\lambda\right)=\left(1/\lambda\right)e^{-x/\lambda}$
\end_inset

 and 
\begin_inset Formula $Y_{i}\sim f\left(y|\mu\right)=\left(1/\mu\right)e^{-y/\mu}$
\end_inset

.
 We observe 
\begin_inset Formula 
\[
Z_{i}=\min\left(X_{i},Y_{i}\right)\quad\mbox{and}\quad W_{i}=\begin{cases}
1, & \mbox{if }Z_{i}=X_{i}\\
0, & \mbox{if }Z_{i}=Y_{i}
\end{cases}.
\]

\end_inset

Find the MLEs of 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Example
WRITE THIS UP
\end_layout

\begin_layout Theorem
\begin_inset ERT
status open

\begin_layout Plain Layout

[Invariance property of MLEs]
\end_layout

\end_inset

If 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is the MLE of 
\begin_inset Formula $\theta$
\end_inset

, then for any function 
\begin_inset Formula $\tau\left(\theta\right)$
\end_inset

, the MLE of 
\begin_inset Formula $\tau\left(\theta\right)$
\end_inset

 is 
\begin_inset Formula $\tau\left(\hat{\theta}\right)$
\end_inset

.
 (This is Theorem 7.2.10 from Casella & Berger; the following proof is given
 there.)
\begin_inset CommandInset label
LatexCommand label
name "thm:invariance-mle"

\end_inset


\end_layout

\begin_layout Proof
proof goes here
\end_layout

\begin_layout Example
Suppose that 
\begin_inset Formula $X_{1},\ldots,X_{n}\stackrel{\mbox{iid}}{\sim}\mbox{Exp}\left(\lambda\right)$
\end_inset

, so that the pdf of 
\begin_inset Formula $X_{i}$
\end_inset

 is given by 
\begin_inset Formula $f_{X_{i}}\left(x|\lambda\right)=\lambda e^{-\lambda x}$
\end_inset

, and the MLE of 
\begin_inset Formula $\lambda$
\end_inset

 is 
\begin_inset Formula $\hat{\lambda}=1/\bar{X}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Enumerate
Find the MLE of 
\begin_inset Formula $P\left(\left\{ X>a\right\} \right)$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Standard
Let 
\begin_inset Formula $\eta=P\left(\left\{ X>a\right\} \right)$
\end_inset

, so that we have 
\begin_inset Formula 
\begin{flalign*}
\eta & =P\left(\left\{ X>a\right\} \right)\\
 & =\int_{a}^{\infty}f_{X}\left(x|\lambda\right)\mbox{d}x\\
 & =\lim_{c\rightarrow\infty}\int_{a}^{c}\lambda e^{-\lambda x}\mbox{d}x\\
 & =\lim_{c\rightarrow\infty}\left[-e^{-\lambda x}\right|_{a}^{c}\\
 & =\lim_{c\rightarrow\infty}\left(-e^{-\lambda c}-\left(-e^{-\lambda a}\right)\right)\\
 & =\lim_{c\rightarrow\infty}\left(-e^{-\lambda c}+e^{-\lambda a}\right)\\
 & =0+e^{-\lambda a}\\
 & =e^{-\lambda a}.
\end{flalign*}

\end_inset

Then, by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:invariance-mle"

\end_inset

, we have 
\begin_inset Formula $\hat{\eta}=e^{-\left(1/\bar{x}\right)a}=e^{-a/\bar{x}}$
\end_inset

.
 Note that 
\begin_inset Formula 
\begin{flalign*}
\ln\eta & =\ln e^{-\lambda a}\\
\Leftrightarrow-\lambda a & =\ln\eta\\
\Leftrightarrow\lambda & =-\frac{\ln\eta}{a},
\end{flalign*}

\end_inset

so that
\begin_inset Formula 
\begin{flalign*}
f_{X_{i}}\left(x|\eta\right) & =\left(-\frac{\ln\eta}{a}\right)e^{-\left(-\ln\eta/a\right)x}\\
 & =\left(-\frac{\ln\eta}{a}\right)e^{\left(x\ln\eta\right)/a}.
\end{flalign*}

\end_inset

Then, the joint pdf of 
\begin_inset Formula $\mathbf{X}=X_{1},\ldots,X_{n}$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
f_{\mathbf{X}}\left(\mathbf{x}|\eta\right) & =\prod_{i=1}^{n}f_{X_{i}}\left(x|\eta\right)\\
 & =\prod_{i=1}^{n}\left(-\frac{\ln\eta}{a}\right)e^{\left(x_{i}\ln\eta\right)/a}\\
 & =\left(-\frac{\ln\eta}{a}\right)^{n}e^{\sum_{i=1}^{n}\left(x_{i}\ln\eta\right)/a},
\end{flalign*}

\end_inset

so that the log-likelihood function is given by
\begin_inset Formula 
\begin{flalign*}
\ln L\left(\eta|\mathbf{x}\right) & =\ln\left[\left(-\frac{\ln\eta}{a}\right)^{n}e^{\sum_{i=1}^{n}\left(x_{i}\ln\eta\right)/a}\right]\\
 & =\ln\left[\left(-\frac{\ln\eta}{a}\right)^{n}\right]+\ln\left[e^{\sum_{i=1}^{n}\left(x_{i}\ln\eta\right)/a}\right]\\
 & =n\ln\left(-\frac{\ln\eta}{a}\right)+\sum_{i=1}^{n}\left(\frac{x_{i}\ln\eta}{a}\right)\\
 & =n\ln\left(-\frac{\ln\eta}{a}\right)+\frac{\ln\eta}{a}\sum_{i=1}^{n}x_{i}.
\end{flalign*}

\end_inset

Taking the derivative with respect to 
\begin_inset Formula $\eta$
\end_inset

, we have
\begin_inset Formula 
\begin{flalign*}
\frac{\partial}{\partial\eta}\ln L\left(\eta|\mathbf{x}\right) & =\frac{\partial}{\partial\eta}\left[n\ln\left(-\frac{\ln\eta}{a}\right)+\ln\eta\left(a\sum_{i=1}^{n}x_{i}\right)\right]\\
 & =\frac{n}{-\frac{\ln\eta}{a}}\left(-\frac{1}{\eta a}\right)+\frac{1}{\eta a}\sum_{i=1}^{n}x_{i}\\
 & =\frac{n}{\eta\ln\eta}+\frac{1}{\eta a}\sum_{i=1}^{n}x_{i}.
\end{flalign*}

\end_inset

Setting this equal to zero, we have
\begin_inset Formula 
\begin{flalign*}
\frac{n}{\hat{\eta}\ln\hat{\eta}}+\frac{1}{\hat{\eta}a}\sum_{i=1}^{n}x_{i} & =0\\
\Leftrightarrow\frac{n}{\hat{\eta}\ln\hat{\eta}} & =-\frac{1}{\hat{\eta}a}\sum_{i=1}^{n}x_{i}\\
\Leftrightarrow\hat{\eta}\ln\hat{\eta}\sum_{i=1}^{n}x_{i} & =-n\hat{\eta}a\\
\Leftrightarrow\ln\hat{\eta} & =-\frac{na}{\sum_{i=1}^{n}x_{i}}\\
\Leftrightarrow\ln\hat{\eta} & =-\frac{a}{\bar{x}}\\
\Leftrightarrow\hat{\eta} & =e^{-a/\bar{x}},
\end{flalign*}

\end_inset

which agrees with the result obtained from the theorem.
\end_layout

\end_deeper
\begin_layout Enumerate
Find the MLE of 
\begin_inset Formula $\mbox{median}\left(X_{1},\ldots,X_{n}\right)$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Standard
The median of a distribution is a value 
\begin_inset Formula $m$
\end_inset

 such that 
\begin_inset Formula $P\left(\left\{ Y\leq m\right\} \right)\geq\frac{1}{2}$
\end_inset

 and 
\begin_inset Formula $P\left(\left\{ Y\geq m\right\} \right)\geq\frac{1}{2}.$
\end_inset

 If 
\begin_inset Formula $Y$
\end_inset

 is continuous, 
\begin_inset Formula $m$
\end_inset

 satisfies 
\begin_inset Formula 
\[
\int_{-\infty}^{m}f\left(y\right)\mbox{d}y=\int_{m}^{\infty}f\left(y\right)\mbox{d}y=\frac{1}{2}.
\]

\end_inset


\begin_inset Formula $X$
\end_inset

 is continuous, so it follows that 
\begin_inset Formula 
\begin{flalign*}
\frac{1}{2} & =P\left(\left\{ X\leq m\right\} \right)\\
 & =F_{X}\left(m\right).
\end{flalign*}

\end_inset

The cdf of 
\begin_inset Formula $X$
\end_inset

 is given by
\begin_inset Formula 
\begin{flalign*}
F_{X}\left(x\right) & =\int_{0}^{x}f_{X}\left(x\right)\mbox{d}x\\
 & =\int_{0}^{x}\lambda e^{-\lambda x}\mbox{d}x\\
 & =-e^{-\lambda x}\Big\rvert_{0}^{x}\\
 & =-e^{-\lambda x}-\left(-e^{0}\right)\\
 & =1-e^{-\lambda x},
\end{flalign*}

\end_inset

so it follows that 
\begin_inset Formula 
\begin{flalign*}
F_{X}\left(m\right) & =1-e^{-\lambda m}\\
 & =\frac{1}{2}\\
\Leftrightarrow e^{-\lambda m} & =\frac{1}{2}\\
\Leftrightarrow-\lambda m & =\ln\left(2^{-1}\right)\\
\Leftrightarrow-\lambda m & =-\ln2\\
\Leftrightarrow m & =\frac{\ln2}{\lambda}.
\end{flalign*}

\end_inset

Then, by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:invariance-mle"

\end_inset

, we have 
\begin_inset Formula 
\begin{flalign*}
\hat{m} & =\frac{\ln2}{\hat{\lambda}}\\
\Leftrightarrow\hat{m} & =\frac{\ln2}{\frac{1}{\bar{x}}}\\
 & =\bar{x}\ln2.
\end{flalign*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_body
\end_document
